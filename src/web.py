#!/usr/bin/env python3
"""
Redriva Web Interface - Interface web simple pour Redriva
Maintenu via Claude/Copilot - Architecture Flask minimaliste
"""

from flask import Flask, render_template, request, jsonify, redirect, url_for, flash
import sqlite3
import asyncio
import threading
import time
import os
import sys
import json
import logging
import requests
import urllib.parse
import uuid
import signal
import traceback
import aiohttp
from datetime import datetime

# Import des fonctions existantes
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# Configuration basique du logging et logger global
logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s %(name)s: %(message)s')
logger = logging.getLogger(__name__)

# Import du gestionnaire de configuration
from config_manager import get_config, load_token, get_database_path

from main import (
    sync_smart, sync_all_v2, sync_torrents_only,
    show_stats, diagnose_errors, get_db_stats, format_size, get_status_emoji,
    create_tables, sync_details_only, ACTIVE_STATUSES, ERROR_STATUSES, COMPLETED_STATUSES,
    fetch_torrent_detail, upsert_torrent_detail, log_event, get_db_path
)

# Utilisation de la configuration centralis√©e - DB_PATH sera dynamique
def get_current_db_path():
    """R√©cup√®re le chemin actuel de la base de donn√©es"""
    return get_database_path()

# Pour compatibilit√©, DB_PATH pointe vers le r√©sultat de la fonction
DB_PATH = get_current_db_path()

# INITIALISATION AUTOMATIQUE DE LA BASE DE DONN√âES
def init_database_if_needed():
    """Initialise la base de donn√©es si elle n'existe pas ou est incompl√®te"""
    try:
        db_path = get_db_path()
        print("üîß V√©rification de la base de donn√©es...")
        log_event('DB_CHECK_START', path=db_path)

        # V√©rifier si la base existe
        if not os.path.exists(db_path):
            print("üìÇ Base de donn√©es non trouv√©e, cr√©ation en cours...")
            create_tables()
            print("‚úÖ Base de donn√©es cr√©√©e avec succ√®s")
            log_event('DB_CHECK_END', status='created')
            return

        # V√©rifier l'int√©grit√© des tables
        try:
            import sqlite3
            with sqlite3.connect(db_path) as conn:
                c = conn.cursor()

                # V√©rifier que les tables principales existent
                c.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='torrents'")
                if not c.fetchone():
                    print("üîß Table 'torrents' manquante, recr√©ation...")
                    create_tables()
                    print("‚úÖ Tables recr√©√©es avec succ√®s")
                    return

                c.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='torrent_details'")
                if not c.fetchone():
                    print("üîß Table 'torrent_details' manquante, recr√©ation...")
                    create_tables()
                    print("‚úÖ Tables recr√©√©es avec succ√®s")
                    return

                # V√©rifier que la colonne health_error existe
                c.execute("PRAGMA table_info(torrent_details)")
                columns = [column[1] for column in c.fetchall()]
                if 'health_error' not in columns:
                    print("üîß Colonne 'health_error' manquante, ajout en cours...")
                    c.execute("ALTER TABLE torrent_details ADD COLUMN health_error TEXT")
                    conn.commit()
                    print("‚úÖ Colonne 'health_error' ajout√©e avec succ√®s")

                print("‚úÖ Base de donn√©es v√©rifi√©e et √† jour")
                log_event('DB_CHECK_END', status='ok')

        except Exception as db_error:
            print(f"‚ö†Ô∏è Probl√®me avec la base existante: {db_error}")
            print("üîß Recr√©ation compl√®te de la base de donn√©es...")
            # Sauvegarder l'ancienne base si elle existe
            if os.path.exists(DB_PATH):
                backup_path = f"{DB_PATH}.backup"
                import shutil
                shutil.copy2(DB_PATH, backup_path)
                print(f"üíæ Ancienne base sauvegard√©e: {backup_path}")

            create_tables()
            print("‚úÖ Base de donn√©es recr√©√©e avec succ√®s")
            log_event('DB_CHECK_END', status='recreated')

    except Exception as e:
        print(f"‚ùå Erreur lors de l'initialisation de la base: {e}")
        log_event('DB_CHECK_END', status='error', error=str(e))
        print(f"   Chemin de la base: {DB_PATH}")
        raise

# Initialiser la base au d√©marrage de l'application
print("üöÄ Initialisation de Redriva...")
init_database_if_needed()

# Import du nouveau module symlink avec gestion d'erreur
try:
    from symlink_tool import register_symlink_routes, init_symlink_database
    SYMLINK_AVAILABLE = True
    print("‚úÖ Module symlink_tool import√© avec succ√®s")
except ImportError as e:
    print(f"‚ö†Ô∏è Module symlink_tool non disponible: {e}")
    SYMLINK_AVAILABLE = False
    # Fonctions de fallback
    def register_symlink_routes(app):
        @app.route('/symlink')
        def symlink_unavailable():
            return "Symlink Manager non disponible", 503
    def init_symlink_database():
        pass

# Import du module de surveillance Arr avec gestion d'erreur
try:
    from arr_monitor import get_arr_monitor
    ARR_MONITOR_AVAILABLE = True
    print("‚úÖ Module arr_monitor import√© avec succ√®s")
except ImportError as e:
    print(f"‚ö†Ô∏è Module arr_monitor non disponible: {e}")
    ARR_MONITOR_AVAILABLE = False

app = Flask(__name__)
app.secret_key = os.urandom(24)

# Initialisation du moniteur Arr en arri√®re-plan
if ARR_MONITOR_AVAILABLE:
    try:
        config_manager = get_config()
        arr_monitor = get_arr_monitor(config_manager)
        
        # D√©marrer automatiquement si des applications Arr sont configur√©es
        if config_manager.get('sonarr.enabled', False) or config_manager.get('radarr.enabled', False):
            # D√©marrer avec un intervalle par d√©faut de 5 minutes
            auto_start_interval = config_manager.get('arr_monitor.interval', 300)
            if arr_monitor.start_monitoring(auto_start_interval):
                print(f"üîß Surveillance Arr d√©marr√©e automatiquement (intervalle: {auto_start_interval}s)")
            else:
                print("‚ö†Ô∏è √âchec du d√©marrage automatique de la surveillance Arr")
        else:
            print("‚ÑπÔ∏è Surveillance Arr disponible mais aucune application configur√©e")
    except Exception as e:
        print(f"‚ùå Erreur initialisation surveillance Arr: {e}")
        import traceback
        traceback.print_exc()
else:
    print("‚ö†Ô∏è Module de surveillance Arr d√©sactiv√© - module non disponible")


# API pour d√©clencher manuellement un cycle Arr (utilis√© par l'UI)
@app.route('/api/arr/run', methods=['POST'])
def api_arr_run():
    if not ARR_MONITOR_AVAILABLE:
        return jsonify({'success': False, 'message': 'Arr monitor not available'}), 503

    try:
        # Obtenir une instance via get_arr_monitor (d√©j√† initialis√©e plus haut)
        # arr_monitor variable a √©t√© cr√©√©e lors de l'initialisation globale
        res = arr_monitor.run_cycle()
        # Construire des messages sommaires pour le frontend
        messages = []
        for app_name, count in res.items():
            messages.append({'app': app_name, 'actions': count, 'message': f'{count} actions ex√©cut√©es sur {app_name}'})

        return jsonify({'success': True, 'results': res, 'messages': messages})
    except Exception as e:
        logger.exception(f"API arr run failed: {e}")
        return jsonify({'success': False, 'message': str(e)}), 500


@app.route('/api/arr/start', methods=['POST'])
def api_arr_start():
    if not ARR_MONITOR_AVAILABLE:
        return jsonify({'success': False, 'message': 'Arr monitor not available'}), 503
    try:
        data = request.get_json() or {}
        interval = int(data.get('interval', 300))
        started = arr_monitor.start_monitoring(interval)
        return jsonify({'success': bool(started), 'started': bool(started), 'interval': interval})
    except Exception as e:
        logger.exception(f"API arr start failed: {e}")
        return jsonify({'success': False, 'message': str(e)}), 500


@app.route('/api/arr/stop', methods=['POST'])
def api_arr_stop():
    if not ARR_MONITOR_AVAILABLE:
        return jsonify({'success': False, 'message': 'Arr monitor not available'}), 503
    try:
        stopped = arr_monitor.stop_monitoring()
        return jsonify({'success': bool(stopped), 'stopped': bool(stopped)})
    except Exception as e:
        logger.exception(f"API arr stop failed: {e}")
        return jsonify({'success': False, 'message': str(e)}), 500


@app.route('/api/arr/diagnose/<app_name>', methods=['GET'])
def api_arr_diagnose(app_name: str):
    if not ARR_MONITOR_AVAILABLE:
        return jsonify({'success': False, 'message': 'Arr monitor not available'}), 503
    try:
        # utiliser la m√©thode diagnose_queue pour obtenir les items d√©tect√©s
        res = arr_monitor.diagnose_queue(app_name)
        return jsonify({'success': True, 'diagnose': res})
    except Exception as e:
        logger.exception(f"API arr diagnose failed: {e}")
        return jsonify({'success': False, 'message': str(e)}), 500


@app.route('/api/arr/item_action', methods=['POST'])
def api_arr_item_action():
    if not ARR_MONITOR_AVAILABLE:
        return jsonify({'success': False, 'message': 'Arr monitor not available'}), 503
    try:
        data = request.get_json() or {}
        app_name = data.get('app')
        item = data.get('item')
        if not app_name or not item:
            return jsonify({'success': False, 'message': 'app and item required'}), 400

        # determine config and download id
        if app_name.lower().startswith('sonarr'):
            cfg = arr_monitor.get_sonarr_config()
        else:
            cfg = arr_monitor.get_radarr_config()

        if not cfg:
            return jsonify({'success': False, 'message': 'configuration missing'}), 400

        download_id = item.get('id') or item.get('downloadId') or item.get('releaseId')
        if not download_id:
            return jsonify({'success': False, 'message': 'download id not found in item'}), 400

        result = arr_monitor.blocklist_and_search(app_name, cfg['url'], cfg['api_key'], download_id)
        # Normalize response
        if isinstance(result, dict):
            success = result.get('status') == 'ok'
            message = result.get('message')
        else:
            success = bool(result)
            message = None

        return jsonify({'success': success, 'message': message or ('action executed' if success else 'action failed'), 'raw': result})
    except Exception as e:
        logger.exception(f"API arr item_action failed: {e}")
        return jsonify({'success': False, 'message': str(e)}), 500

# Variables globales pour le statut des t√¢ches (d√©finies avant les gestionnaires d'erreur)
task_status = {
    "running": False, 
    "progress": "", 
    "result": "",
    "last_update": None
}

# Variable globale pour les op√©rations de suppression en masse
batch_operations = {}

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# INITIALISATION SYMLINK MANAGER (au niveau module pour Gunicorn)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

if SYMLINK_AVAILABLE:
    try:
        # Initialiser la base de donn√©es symlink
        init_symlink_database()
        print("‚úÖ Base de donn√©es Symlink initialis√©e")
        
        # Enregistrer les routes symlink
        register_symlink_routes(app)
        print("üîó Routes Symlink Manager enregistr√©es")
        
    except Exception as e:
        print(f"‚ùå Erreur initialisation Symlink Manager: {e}")
        import traceback
        traceback.print_exc()
else:
    print("‚ö†Ô∏è Symlink Manager d√©sactiv√© - module non disponible")

# Configuration adapt√©e pour Docker et environnements locaux
# Configuration Flask depuis le gestionnaire centralis√©
flask_config = get_config().get_flask_config()
app.config['HOST'] = flask_config['host']
app.config['PORT'] = flask_config['port']
app.config['DEBUG'] = flask_config['debug']

# ROUTES DE SETUP INITIAL
@app.before_request
def check_setup():
    """V√©rifie si l'application n√©cessite un setup initial"""
    config = get_config()
    
    # Ignorer les routes de setup et les assets
    if request.endpoint in ['setup_page', 'setup_save', 'static'] or request.path.startswith('/assets'):
        return
    
    # Rediriger vers setup si n√©cessaire
    if config.needs_setup():
        return redirect('/setup')

@app.route('/setup')
def setup_page():
    """Page de configuration initiale"""
    return render_template('setup.html')

@app.route('/setup', methods=['POST'])
def setup_save():
    """Sauvegarde de la configuration initiale"""
    try:
        config = get_config()
        
        # Debug - afficher les donn√©es re√ßues (sans les tokens)
        print(f"üîß Donn√©es du formulaire re√ßues :")
        for key, value in request.form.items():
            print(f"   {key}: {'[HIDDEN]' if 'token' in key or 'key' in key else value}")
        
        # ‚ö†Ô∏è S√âCURIT√â : Ne jamais logger les tokens/cl√©s
        setup_data = {
            'rd_token': request.form.get('rd_token', '').strip(),
            'sonarr_url': request.form.get('sonarr_url', '').strip(),
            'sonarr_api_key': request.form.get('sonarr_api_key', '').strip(),
            'radarr_url': request.form.get('radarr_url', '').strip(),
            'radarr_api_key': request.form.get('radarr_api_key', '').strip(),
        }
        
        # Validation du token obligatoire
        if not setup_data['rd_token']:
            flash('‚ùå Le token Real-Debrid est obligatoire', 'error')
            return render_template('setup.html')
        
        print(f"üîß Tentative de sauvegarde de la configuration...")
        print(f"üîí RAPPEL S√âCURIT√â : Tokens stock√©s localement et exclus de Git")
        
        # Sauvegarder la configuration
        if config.save_setup_config(setup_data):
            print(f"‚úÖ Configuration sauvegard√©e avec succ√®s")
            flash('‚úÖ Configuration sauvegard√©e avec succ√®s !', 'success')
            return redirect('/')
        else:
            print(f"‚ùå √âchec de la sauvegarde")
            flash('‚ùå Erreur lors de la sauvegarde', 'error')
            return render_template('setup.html')
            
    except Exception as e:
        logger.error(f"‚ùå Erreur setup : {e}")
        print(f"‚ùå Exception dans setup_save : {e}")
        traceback.print_exc()
        flash(f'‚ùå Erreur : {e}', 'error')
        return render_template('setup.html')

# Ajout de gestionnaires d'erreur pour diagnostiquer le probl√®me
@app.errorhandler(403)
def forbidden_error(error):
    """Gestionnaire d'erreur 403 pour diagnostiquer le probl√®me"""
    # Log d√©taill√© pour faciliter le debug (remote_addr, endpoint, host, referer)
    remote = request.remote_addr
    endpoint = request.endpoint
    host = request.headers.get('Host')
    referer = request.headers.get('Referer')
    logger.warning(f"‚ùå Erreur 403 intercept√©e: {error} - url={request.url} method={request.method} remote={remote} endpoint={endpoint} host={host} referer={referer}")
    # Ne pas exposer tous les headers en production - garder un sous-ensemble utile
    debug_info = {
        'url': request.url,
        'method': request.method,
        'path': request.path,
        'remote_addr': remote,
        'endpoint': endpoint,
        'host': host,
        'referer': referer
    }

    if request.path.startswith('/api/'):
        # R√©ponse JSON pour les appels API - inclure debug_info pour faciliter le debug en dev
        return jsonify({
            'success': False,
            'error': 'Acc√®s refus√© - V√©rifiez votre configuration',
            'debug_info': debug_info
        }), 403

    # Pour les pages HTML, afficher un message utilisateur et rendre la page torrents vide
    flash('Erreur 403: Acc√®s refus√© - V√©rifiez votre configuration', 'error')
    return render_template('torrents.html',
                         torrents=[],
                         pagination={'page': 1, 'total_pages': 1, 'total': 0},
                         available_statuses=[],
                         total_count=0,
                         coverage=0,
                         error_403=True), 403

@app.errorhandler(500)
def internal_error(error):
    """Gestionnaire d'erreur 500 pour diagnostiquer les erreurs internes"""
    print(f"‚ùå Erreur 500 intercept√©e: {error}")
    print(f"   URL demand√©e: {request.url}")
    
    if request.path.startswith('/api/'):
        return jsonify({
            'success': False, 
            'error': 'Erreur interne du serveur',
            'debug_info': str(error)
        }), 500
    
    flash('Erreur interne du serveur - Consultez les logs', 'error')
    return render_template('torrents.html', 
                         torrents=[], 
                         pagination={'page': 1, 'total_pages': 1, 'total': 0},
                         available_statuses=[],
                         total_count=0,
                         coverage=0,
                         error_500=True), 500

def get_db_connection():
    """Cr√©e et retourne une connexion √† la base de donn√©es SQLite."""
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row  # Permet d'acc√©der aux colonnes par nom
    return conn

def format_download_link(direct_link):
    """Transforme un lien direct en lien downloader Real-Debrid"""
    if not direct_link or not direct_link.startswith('https://real-debrid.com/d/'):
        return direct_link
    
    # URL encoder le lien complet
    encoded_link = urllib.parse.quote(direct_link, safe='')
    return f"https://real-debrid.com/downloader?links={encoded_link}"

def cleanup_deleted_torrents():
    """
    Supprime d√©finitivement de la base de donn√©es tous les torrents 
    marqu√©s comme 'deleted' dans les tables torrents et torrent_details.
    Retourne le nombre d'√©l√©ments supprim√©s.
    """
    try:
        log_event('CLEAN_START', scope='deleted_torrents')
        with sqlite3.connect(DB_PATH) as conn:
            c = conn.cursor()
            
            # R√©cup√©rer les IDs des torrents marqu√©s comme deleted dans la table torrents
            c.execute("SELECT id FROM torrents WHERE status = 'deleted'")
            deleted_torrent_ids = [row[0] for row in c.fetchall()]
            
            # R√©cup√©rer les IDs des torrents marqu√©s comme deleted dans la table torrent_details
            c.execute("SELECT id FROM torrent_details WHERE status = 'deleted'")
            deleted_detail_ids = [row[0] for row in c.fetchall()]
            
            # Fusionner les deux listes pour obtenir tous les IDs √† supprimer
            all_deleted_ids = list(set(deleted_torrent_ids + deleted_detail_ids))
            
            if not all_deleted_ids:
                print("‚ÑπÔ∏è Aucun torrent marqu√© comme supprim√© trouv√©")
                log_event('CLEAN_END', scope='deleted_torrents', deleted=0, status='nothing')
                return {
                    'success': True,
                    'deleted_count': 0,
                    'message': 'Aucun torrent √† nettoyer'
                }
            
            # Supprimer de la table torrent_details
            placeholders = ','.join('?' for _ in all_deleted_ids)
            c.execute(f"DELETE FROM torrent_details WHERE id IN ({placeholders})", all_deleted_ids)
            details_deleted = c.rowcount
            
            # Supprimer de la table torrents
            c.execute(f"DELETE FROM torrents WHERE id IN ({placeholders})", all_deleted_ids)
            torrents_deleted = c.rowcount
            
            conn.commit()
            
            total_deleted = len(all_deleted_ids)
            print(f"‚úÖ Nettoyage termin√© : {total_deleted} torrents supprim√©s ({torrents_deleted} de torrents, {details_deleted} de torrent_details)")
            log_event('CLEAN_END', scope='deleted_torrents', deleted=total_deleted, torrents=torrents_deleted, details=details_deleted, status='success')
            
            return {
                'success': True,
                'deleted_count': total_deleted,
                'torrents_deleted': torrents_deleted,
                'details_deleted': details_deleted,
                'message': f'{total_deleted} torrent(s) supprim√©(s) d√©finitivement'
            }
            
    except Exception as e:
        print(f"‚ùå Erreur lors du nettoyage des torrents supprim√©s: {e}")
        log_event('CLEAN_END', scope='deleted_torrents', status='error', error=str(e))
        return {
            'success': False,
            'error': str(e),
            'deleted_count': 0
        }

def run_sync_task(task_name, token, task_func, *args):
    """Version simplifi√©e sans capture d'output"""
    def execute_task():
        import time
        task_id = str(uuid.uuid4())[:8]
        log_event('ASYNC_TASK_START', name=task_name.replace(' ', '_'), task_id=task_id)
        
        try:
            task_status["running"] = True
            task_status["progress"] = f"üöÄ D√©marrage de {task_name}..."
            task_status["result"] = ""
            task_status["last_update"] = time.time()
            
            # Ex√©cution de la synchronisation
            if args:
                result = task_func(token, *args)
            else:
                result = task_func(token)
            
            task_status["result"] = f"‚úÖ {task_name} termin√©e avec succ√®s"
            task_status["running"] = False
            task_status["last_update"] = time.time()
            log_event('ASYNC_TASK_END', name=task_name.replace(' ', '_'), task_id=task_id, status='success')
            
        except Exception as e:
            task_status["result"] = f"‚ùå Erreur dans {task_name}: {str(e)}"
            task_status["running"] = False
            task_status["last_update"] = time.time()
            log_event('ASYNC_TASK_END', name=task_name.replace(' ', '_'), task_id=task_id, status='error', error=str(e))
    
    # Lancer la t√¢che en arri√®re-plan
    thread = threading.Thread(target=execute_task)
    thread.daemon = True
    thread.start()
    
    return thread

def run_health_check_task(token):
    """Lance la v√©rification de sant√© en arri√®re-plan"""
    def execute_health_check():
        task_id = str(uuid.uuid4())[:8]
        log_event('HEALTH_CHECK_START', task_id=task_id)
        
        try:
            task_status["running"] = True
            task_status["progress"] = "Initialisation de la v√©rification de sant√©..."
            task_status["result"] = ""
            task_status["last_update"] = time.time()
            
            # R√©cup√©rer la liste des torrents √† v√©rifier
            with sqlite3.connect(DB_PATH) as conn:
                c = conn.cursor()
                c.execute("""
                    SELECT t.id, t.filename 
                    FROM torrents t
                    LEFT JOIN torrent_details td ON t.id = td.id
                    WHERE t.status != 'deleted'
                    AND t.status != 'error'
                    ORDER BY t.added_on DESC
                """)
                torrents_to_check = c.fetchall()
            
            if not torrents_to_check:
                task_status["result"] = "Aucun torrent √† v√©rifier"
                task_status["progress"] = "Termin√© - Aucun torrent trouv√©"
                log_event('HEALTH_CHECK_END', checked=0, errors=0, status='nothing')
                return
            
            task_status["progress"] = f"D√©marrage de la v√©rification de {len(torrents_to_check)} torrents..."
            
            # Ex√©cuter la v√©rification asynchrone
            total_checked, errors_503_count, completion_status = asyncio.run(
                health_check_async_worker(token, torrents_to_check)
            )
            
            # R√©sultat final
            duration_minutes = (time.time() - task_status["last_update"]) / 60
            task_status["result"] = f"‚úÖ V√©rification {completion_status}: {errors_503_count} erreurs 503 trouv√©es sur {total_checked} torrents en {duration_minutes:.1f}min"
            task_status["progress"] = f"Termin√© - {total_checked}/{len(torrents_to_check)} torrents v√©rifi√©s"
            
            log_event('HEALTH_CHECK_END', checked=total_checked, errors=errors_503_count, 
                     duration=f"{duration_minutes:.1f}min", status=completion_status)
            
        except Exception as e:
            error_msg = f"Erreur lors de la v√©rification: {str(e)}"
            task_status["result"] = f"‚ùå {error_msg}"
            task_status["progress"] = "Erreur"
            log_event('HEALTH_CHECK_END', status='error', error=str(e))
            logging.error(f"Erreur health check: {e}")
        finally:
            task_status["running"] = False
            task_status["last_update"] = time.time()
    
    # Lancer la t√¢che en arri√®re-plan
    thread = threading.Thread(target=execute_health_check)
    thread.daemon = True
    thread.start()
    
    return thread

    return thread

async def health_check_async_worker(token, torrents_to_check):
    """Worker asynchrone pour la v√©rification de sant√© - Version compl√®te sans limite de temps"""
    
    async def check_torrent_health_async(session, torrent_id):
        """V√©rifie la sant√© d'un torrent via l'endpoint stream (le plus rapide)"""
        try:
            url = f'https://api.real-debrid.com/rest/1.0/torrents/info/{torrent_id}'
            headers = {"Authorization": f"Bearer {token}"}
            
            async with session.get(url, headers=headers, timeout=8) as response:
                if response.status == 404:
                    return torrent_id, "Torrent non trouv√©", None
                elif response.status != 200:
                    return torrent_id, f"Erreur HTTP {response.status}", None
                
                torrent_info = await response.json()
                download_links = torrent_info.get('links', [])
                
                if not download_links:
                    return torrent_id, "Aucun lien disponible", None
                
                # Tester seulement le premier lien (optimisation)
                first_link = download_links[0]
                
                # D√©brider pour tester la disponibilit√©
                unrestrict_data = {'link': first_link}
                async with session.post(
                    'https://api.real-debrid.com/rest/1.0/unrestrict/link',
                    headers=headers,
                    data=unrestrict_data,
                    timeout=6
                ) as unrestrict_response:
                    
                    if unrestrict_response.status == 503:
                        return torrent_id, "Erreur 503 - Fichier indisponible", "503"
                    elif unrestrict_response.status == 200:
                        return torrent_id, "Fichier disponible", "OK"
                    else:
                        return torrent_id, f"Status d√©bridage: {unrestrict_response.status}", None
                        
        except asyncio.TimeoutError:
            return torrent_id, "Timeout lors de la v√©rification", None
        except Exception as e:
            return torrent_id, f"Erreur: {str(e)}", None

    # === TRAITEMENT PRINCIPAL ===
    errors_503_count = 0
    total_checked = 0
    start_process_time = time.time()
    
    logging.info(f"üöÄ D√©marrage du traitement parall√®le adaptatif de {len(torrents_to_check)} torrents...")
    
    # Optimisation: Connexion unique avec pool adaptatif
    connector = aiohttp.TCPConnector(limit=50, limit_per_host=25)
    timeout = aiohttp.ClientTimeout(total=12, connect=3)
    
    async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:
        
        # Configuration dynamique des batches - OPTIMIS√âE POUR R√âCUP√âRATION RAPIDE
        batch_size = 5  # Taille initiale plus agressive
        min_batch_size = 1  # Descendre jusqu'√† 1 si n√©cessaire
        max_batch_size = 25  # Augmenter le maximum
        consecutive_successes = 0
        consecutive_errors = 0
        consecutive_429_errors = 0
        api_delay = 1.5  # D√©lai initial plus agressif
        recovery_mode = False  # Mode r√©cup√©ration rapide
        
        i = 0
        batch_num = 0
        
        while i < len(torrents_to_check):
            batch_num += 1
            batch_start_time = time.time()
            
            # D√©terminer la taille du batch actuel
            actual_batch_size = min(batch_size, len(torrents_to_check) - i)
            batch_torrents = torrents_to_check[i:i+actual_batch_size]
            
            # Mettre √† jour le statut de la t√¢che
            progress_pct = (i / len(torrents_to_check)) * 100
            task_status["progress"] = f"Batch {batch_num}: {i}/{len(torrents_to_check)} torrents ({progress_pct:.1f}%) - {errors_503_count} erreurs 503 trouv√©es"
            task_status["last_update"] = time.time()
            
            logging.info(f"üîÑ BATCH {batch_num}: Traitement de {actual_batch_size} torrents avec batch_size={batch_size}")
            
            # Cr√©er les t√¢ches pour ce batch
            tasks = [
                check_torrent_health_async(session, torrent_id) 
                for torrent_id, filename in batch_torrents
            ]
            
            # Ex√©cuter le batch en parall√®le avec gestion d'erreurs
            try:
                batch_results = await asyncio.gather(*tasks, return_exceptions=True)
                batch_success = True
            except Exception as batch_error:
                logging.error(f"‚ùå Erreur critique dans le batch {batch_num}: {batch_error}")
                batch_success = False
                batch_results = [batch_error] * len(tasks)
            
            batch_end_time = time.time()
            batch_duration = batch_end_time - batch_start_time
            batch_rate = actual_batch_size / batch_duration if batch_duration > 0 else 0
            
            # Analyser les r√©sultats et compter les erreurs API
            batch_updates = []
            batch_503_count = 0
            batch_api_errors = 0
            batch_timeouts = 0
            batch_success_count = 0
            
            for result in batch_results:
                if isinstance(result, Exception):
                    logging.error(f"‚ùå Exception dans le batch: {result}")
                    batch_api_errors += 1
                    continue
                    
                torrent_id, message, status = result
                total_checked += 1
                
                if status == "503":
                    batch_503_count += 1
                    errors_503_count += 1
                    logging.warning(f"üö® ERREUR 503 D√âTECT√âE pour torrent {torrent_id}: {message}")
                    batch_updates.append((message, torrent_id))
                elif status == "OK":
                    batch_success_count += 1
                    logging.debug(f"‚úÖ Torrent {torrent_id} en bonne sant√©")
                    batch_updates.append((None, torrent_id))
                elif "Timeout" in message or "timeout" in message.lower():
                    batch_timeouts += 1
                    logging.info(f"‚è±Ô∏è Torrent {torrent_id}: {message}")
                elif "Erreur HTTP" in message:
                    batch_api_errors += 1
                    logging.info(f"‚ö†Ô∏è Torrent {torrent_id}: {message}")
                elif "429" in message:
                    batch_api_errors += 1
                    logging.warning(f"üö® Torrent {torrent_id}: Rate limiting (429) - {message}")
                else:
                    logging.info(f"‚ö†Ô∏è Torrent {torrent_id}: {message}")
            
            # LOGIQUE D'ADAPTATION DYNAMIQUE avec gestion sp√©ciale des 429
            batch_error_rate = (batch_api_errors + batch_timeouts) / actual_batch_size if actual_batch_size > 0 else 0
            
            # D√©tecter sp√©cifiquement les erreurs 429 (Rate Limiting)
            batch_429_errors = sum(1 for result in batch_results 
                                 if not isinstance(result, Exception) and "429" in result[1])
            
            # Log d√©taill√© des erreurs d√©tect√©es dans ce batch
            if batch_429_errors > 0 or batch_503_count > 0 or batch_api_errors > 0:
                logging.info(f"üìù Batch {batch_num} ANALYSE: {batch_503_count} erreurs 503, {batch_api_errors} erreurs API, {batch_timeouts} timeouts, {batch_success_count} succ√®s, {batch_429_errors} erreurs 429")
                logging.info(f"üìä Batch {batch_num} PERF: {batch_duration:.2f}s, rate: {batch_rate:.1f}/s, erreur_rate: {batch_error_rate:.1%}")
            else:
                logging.debug(f"üìù Batch {batch_num}: {batch_success_count} succ√®s, {batch_duration:.2f}s, {batch_rate:.1f}/s")
            batch_429_errors = sum(1 for result in batch_results 
                                 if not isinstance(result, Exception) and "429" in result[1])
            
            if batch_429_errors > 0:  # Erreurs de rate limiting d√©tect√©es
                consecutive_429_errors += 1
                consecutive_errors += 1
                consecutive_successes = 0
                recovery_mode = True  # Activer le mode r√©cup√©ration
                
                # RALENTISSEMENT MOD√âR√â pour les erreurs 429 (moins drastique)
                old_batch_size = batch_size
                old_delay = api_delay
                
                if consecutive_429_errors >= 3:
                    # Mode ralenti apr√®s 3 batches cons√©cutifs avec 429
                    batch_size = min_batch_size  # Descendre au minimum (1)
                    api_delay = min(api_delay + 3.0, 8.0)  # Max 8s au lieu de 15s
                else:
                    batch_size = max(min_batch_size, batch_size // 2)  # Diviser par 2
                    api_delay = min(api_delay + 2.0, 6.0)  # Max 6s au lieu de 10s
                
                logging.warning(f"üö® RATE LIMITING (429): {batch_429_errors} erreurs, cons√©cutives: {consecutive_429_errors}")
                logging.warning(f"üîª RALENTISSEMENT MOD√âR√â: batch_size: {old_batch_size}‚Üí{batch_size}, d√©lai: {old_delay:.1f}s‚Üí{api_delay:.1f}s")
                
            elif batch_error_rate > 0.3:  # Plus de 30% d'erreurs (non-429)
                consecutive_errors += 1
                consecutive_successes = 0
                consecutive_429_errors = 0  # Reset car pas de 429
                
                # R√©duire mod√©r√©ment la taille du batch
                old_batch_size = batch_size
                batch_size = max(min_batch_size, batch_size - 2)
                api_delay = min(api_delay + 1.0, 5.0)  # R√©duire le max
                
                logging.warning(f"üîª RALENTISSEMENT: {batch_error_rate:.1%} erreurs ‚Üí batch_size: {old_batch_size}‚Üí{batch_size}, d√©lai: {api_delay:.1f}s")
                
            elif batch_error_rate < 0.05:  # Moins de 5% d'erreurs - R√âCUP√âRATION RAPIDE
                consecutive_successes += 1
                consecutive_errors = max(0, consecutive_errors - 1)
                consecutive_429_errors = max(0, consecutive_429_errors - 1)
                
                # R√âCUP√âRATION RAPIDE EN MODE RECOVERY
                if recovery_mode and consecutive_successes >= 2:  # Seulement 2 batches parfaits
                    old_batch_size = batch_size
                    old_delay = api_delay
                    
                    # R√©cup√©ration agressive
                    if batch_size < 5:
                        batch_size = min(max_batch_size, batch_size + 2)  # +2 au lieu de +1
                    else:
                        batch_size = min(max_batch_size, batch_size + 3)  # +3 pour r√©cup√©ration rapide
                    
                    api_delay = max(api_delay - 1.0, 1.0)  # R√©duction plus rapide
                    
                    logging.info(f"üöÄ R√âCUP√âRATION RAPIDE: {batch_error_rate:.1%} erreurs ‚Üí batch_size: {old_batch_size}‚Üí{batch_size}, d√©lai: {old_delay:.1f}s‚Üí{api_delay:.1f}s")
                    
                    # Sortir du mode r√©cup√©ration si on retrouve une bonne taille
                    if batch_size >= 10:
                        recovery_mode = False
                        logging.info(f"‚úÖ SORTIE MODE R√âCUP√âRATION: batch_size={batch_size}")
                        
                # ACC√âL√âRATION NORMALE (hors mode r√©cup√©ration)
                elif not recovery_mode and consecutive_successes >= 3 and batch_size < max_batch_size:  # 3 au lieu de 5
                    old_batch_size = batch_size
                    batch_size = min(max_batch_size, batch_size + 2)  # +2 au lieu de +1
                    api_delay = max(api_delay - 0.2, 1.0)  # R√©duction plus rapide
                    
                    logging.info(f"üî∫ ACC√âL√âRATION NORMALE: {batch_error_rate:.1%} erreurs, {batch_rate:.1f}/s ‚Üí batch_size: {old_batch_size}‚Üí{batch_size}, d√©lai: {api_delay:.1f}s")
            else:
                # Maintenir le rythme actuel mais d√©crementer les compteurs plus rapidement
                consecutive_errors = max(0, consecutive_errors - 1)
                consecutive_successes = max(0, consecutive_successes - 1)
                consecutive_429_errors = max(0, consecutive_429_errors - 1)
            
            # Ex√©cuter toutes les mises √† jour de base en une seule transaction
            if batch_updates:
                with sqlite3.connect(DB_PATH) as conn:
                    cursor = conn.cursor()
                    for health_error, torrent_id in batch_updates:
                        cursor.execute("INSERT OR IGNORE INTO torrent_details (id) VALUES (?)", (torrent_id,))
                        cursor.execute("""
                            UPDATE torrent_details 
                            SET health_error = ?
                            WHERE id = ?
                        """, (health_error, torrent_id))
                    conn.commit()
            
            # Avancer √† la position suivante
            i += actual_batch_size
            
            # Pause adaptative entre batches - TOUJOURS respecter le d√©lai
            if i < len(torrents_to_check):
                await asyncio.sleep(api_delay)
            
            # Log p√©riodique pour le monitoring
            if batch_num % 10 == 0:
                elapsed_total = time.time() - start_process_time
                logging.info(f"üìä Checkpoint: {i}/{len(torrents_to_check)} torrents, {errors_503_count} erreurs 503, {elapsed_total/60:.1f}min √©coul√©es")
    
    final_elapsed = time.time() - start_process_time
    completion_status = "COMPLET"  # Toujours complet maintenant
    
    logging.info(f"üéâ V√âRIFICATION {completion_status}! Total: {total_checked}, erreurs 503: {errors_503_count}")
    logging.info(f"‚è±Ô∏è Dur√©e totale: {final_elapsed/60:.1f} minutes ({final_elapsed:.1f}s)")
    
    return total_checked, errors_503_count, completion_status

@app.route('/')
@app.route('/torrents', endpoint='torrents')
def torrents_list():
    """Liste des torrents avec pagination et filtres natifs"""
    # Param√®tres de pagination et filtres
    page = max(1, int(request.args.get('page', 1)))
    status_filter = request.args.get('status', '')
    search = request.args.get('search', '')
    sort_by = request.args.get('sort', 'added_on')
    sort_dir = request.args.get('dir', 'desc')
    per_page = min(10000, max(1, int(request.args.get('per_page', 25))))  # Limite max de s√©curit√©
    offset = (page - 1) * per_page
    
    # Validation des param√®tres de tri
    valid_sorts = {
        'id': 't.id',
        'filename': 'display_name',
        'status': 'current_status', 
        'bytes': 't.bytes',
        'added_on': 't.added_on',
        'progress': 'progress'
    }
    sort_column = valid_sorts.get(sort_by, 't.added_on')
    if sort_dir not in ['asc', 'desc']:
        sort_dir = 'desc'
    
    with sqlite3.connect(DB_PATH) as conn:
        c = conn.cursor()
        
        # Construction de la requ√™te de base - exclure les supprim√©s SAUF si on filtre sp√©cifiquement sur 'deleted'
        base_query = """
            SELECT t.id, t.filename, t.status, t.bytes, t.added_on,
                   COALESCE(td.name, t.filename) as display_name,
                   COALESCE(td.status, t.status) as current_status,
                   COALESCE(td.progress, 0) as progress,
                   td.host, td.error, td.health_error
            FROM torrents t
            LEFT JOIN torrent_details td ON t.id = td.id
        """
        
        # Conditions et param√®tres
        conditions = []
        params = []
        
        # Si on ne filtre PAS sp√©cifiquement sur "deleted", exclure les supprim√©s
        if status_filter != 'deleted':
            conditions.append("t.status != 'deleted'")
        
        if status_filter:
            if status_filter == 'deleted':
                # Pour les torrents supprim√©s, chercher sp√©cifiquement ce statut
                conditions.append("(t.status = 'deleted' OR td.status = 'deleted')")
            elif status_filter == 'error':
                conditions.append("(t.status = 'error' OR td.status = 'error')")
            elif status_filter == 'unavailable':
                # Nouveau filtre pour fichiers indisponibles (r√©utilise la logique existante)
                conditions.append("(td.error LIKE '%503%' OR td.error LIKE '%404%' OR td.error LIKE '%24%' OR td.error LIKE '%unavailable_file%' OR td.error LIKE '%rd_error_%' OR td.error LIKE '%health_check_error%' OR td.error LIKE '%health_503_error%' OR td.error LIKE '%http_error_%')")
            elif status_filter == 'health_error':
                # Nouveau filtre sp√©cifique pour les erreurs de sant√© 503
                conditions.append("td.health_error IS NOT NULL")
            elif status_filter == 'incomplete':
                # Nouveau filtre pour torrents avec d√©tails manquants
                conditions.append("td.id IS NULL")
            else:
                conditions.append("(t.status = ? OR td.status = ?)")
                params.extend([status_filter, status_filter])
        
        if search:
            # D√©tecter si la recherche est un ID Real-Debrid ou un nom de fichier
            search_stripped = search.strip()
            
            # Les IDs Real-Debrid sont g√©n√©ralement :
            # - 13 caract√®res alphanum√©riques en majuscules
            # - Ou peuvent √™tre des IDs num√©riques purs
            is_probable_id = (
                (len(search_stripped) == 13 and search_stripped.isalnum() and search_stripped.isupper()) or
                search_stripped.isdigit() or
                (len(search_stripped) >= 8 and search_stripped.isalnum() and not ' ' in search_stripped)
            )
            
            if is_probable_id:
                # Recherche par ID exact (insensible √† la casse)
                conditions.append("(UPPER(t.id) = UPPER(?))")
                params.extend([search_stripped])
            else:
                # Recherche par nom de fichier (comportement existant)
                conditions.append("(t.filename LIKE ? OR td.name LIKE ?)")
                params.extend([f"%{search}%", f"%{search}%"])
        
        # Ajout des conditions WHERE
        if conditions:
            base_query += " WHERE " + " AND ".join(conditions)
        
        # Requ√™te pour le total
        count_query = f"SELECT COUNT(*) FROM ({base_query})"
        c.execute(count_query, params)
        total_count = c.fetchone()[0]
        
        # Ajout du tri et pagination
        base_query += f" ORDER BY {sort_column} {sort_dir.upper()} LIMIT ? OFFSET ?"
        params.extend([per_page, offset])
        
        # Ex√©cution de la requ√™te principale
        c.execute(base_query, params)
        torrents_data = c.fetchall()
        
        # R√©cup√©ration des statuts disponibles pour les filtres
        c.execute("""
            SELECT status, COUNT(*) as count
            FROM (
                SELECT COALESCE(td.status, t.status) as status
                FROM torrents t
                LEFT JOIN torrent_details td ON t.id = td.id
            ) sub
            WHERE status IS NOT NULL
            GROUP BY status
            ORDER BY count DESC
        """)
        available_statuses = c.fetchall()
        
        # Ajout du count pour les torrents sans d√©tails
        c.execute("""
            SELECT COUNT(*) 
            FROM torrents t
            LEFT JOIN torrent_details td ON t.id = td.id
            WHERE td.id IS NULL
        """)
        incomplete_count = c.fetchone()[0]
        
        # Ajout du count pour les erreurs de sant√© 503
        c.execute("""
            SELECT COUNT(*) 
            FROM torrent_details td
            WHERE td.health_error IS NOT NULL
        """)
        health_error_count = c.fetchone()[0]
        
        # Ajout des options "incomplete" et "health_error" si elles n'existent pas d√©j√†
        available_statuses = list(available_statuses)
        if incomplete_count > 0:
            available_statuses.append(('incomplete', incomplete_count))
        if health_error_count > 0:
            available_statuses.append(('health_error', health_error_count))
        available_statuses = tuple(available_statuses)
    
    # Calcul de la pagination
    total_pages = (total_count + per_page - 1) // per_page
    has_prev = page > 1
    has_next = page < total_pages
    
    # Formatage des donn√©es pour le template
    torrents = []
    for row in torrents_data:
        torrent = {
            'id': row[0],
            'filename': row[1],
            'status': row[2],
            'bytes': row[3],
            'added_on': row[4],
            'display_name': row[5],
            'current_status': row[6],
            'progress': row[7],
            'host': row[8],
            'error': row[9],
            'health_error': row[10],  # Nouveau champ
            'size_formatted': format_size(row[3]) if row[3] else 'N/A',
            'status_emoji': get_status_emoji(row[6]),
            'added_date': row[4][:10] if row[4] else 'N/A'
        }
        torrents.append(torrent)
    
    # Donn√©es de pagination pour le template
    pagination = {
        'page': page,
        'per_page': per_page,
        'total': total_count,
        'total_pages': total_pages,
        'has_prev': has_prev,
        'has_next': has_next,
        'prev_page': page - 1 if has_prev else None,
        'next_page': page + 1 if has_next else None,
        'start_item': offset + 1,
        'end_item': min(offset + per_page, total_count)
    }
    
    # Calcul de la couverture des d√©tails
    try:
        # Exclure les torrents supprim√©s uniquement de la table torrents
        c.execute("SELECT COUNT(*) FROM torrents WHERE status != 'deleted'")
        total_torrents = c.fetchone()[0]
        
        # Compter tous les d√©tails disponibles (pas de filtrage par status car torrent_details n'a pas cette colonne)
        c.execute("SELECT COUNT(*) FROM torrent_details")
        total_details = c.fetchone()[0]
        
        coverage = (total_details / total_torrents * 100) if total_torrents > 0 else 0
        print(f"üìä Calcul couverture torrents: {total_torrents} torrents, {total_details} d√©tails = {coverage:.1f}%")
    except Exception as e:
        print(f"‚ùå Erreur calcul couverture: {e}")
        coverage = 0
    
    return render_template('torrents.html', 
                         torrents=torrents,
                         pagination=pagination,
                         status_filter=status_filter,
                         search=search,
                         sort_by=sort_by,
                         sort_dir=sort_dir,
                         available_statuses=available_statuses,
                         total_count=total_count,
                         coverage=round(coverage, 1))

@app.route('/settings')
def settings():
    """Page des param√®tres de configuration"""
    try:
        # V√©rifier la disponibilit√© du module symlink
        symlink_available = SYMLINK_AVAILABLE
        
        # R√©cup√©rer la configuration pour pr√©-remplir les champs
        config_manager = get_config()
        
        settings_data = {
            'RD_TOKEN': load_token(),
            'sonarr': {
                'enabled': config_manager.get('sonarr.enabled', False),
                'url': config_manager.get('sonarr.url', ''),
                'api_key': config_manager.get('sonarr.api_key', '')
            },
            'radarr': {
                'enabled': config_manager.get('radarr.enabled', False),
                'url': config_manager.get('radarr.url', ''),
                'api_key': config_manager.get('radarr.api_key', '')
            }
        }
        
        return render_template('settings.html', 
                             symlink_available=symlink_available,
                             config=settings_data)
    except Exception as e:
        print(f"‚ùå Erreur page settings: {e}")
        flash("Erreur lors du chargement des param√®tres", 'error')
        return redirect(url_for('torrents'))

@app.route('/api-test')
def api_test():
    """Page de test API Real-Debrid"""
    try:
        # R√©cup√©rer toute la configuration depuis ConfigManager
        config_manager = get_config()
        
        test_config = {
            'RD_TOKEN': config_manager.get_token(),
            'api_limit': config_manager.get('realdebrid.api_limit', 100),
            'max_concurrent': config_manager.get('realdebrid.max_concurrent', 50),
            'batch_size': config_manager.get('realdebrid.batch_size', 250),
            'sonarr_enabled': config_manager.get('sonarr.enabled', False),
            'sonarr_url': config_manager.get('sonarr.url', ''),
            'radarr_enabled': config_manager.get('radarr.enabled', False),
            'radarr_url': config_manager.get('radarr.url', ''),
            'symlink_enabled': config_manager.get('symlink.enabled', False),
            'symlink_workers': config_manager.get('symlink.workers', 4),
            'db_path': config_manager.get_db_path(),
            'media_path': config_manager.get_media_path(),
            'version': config_manager.get('version', '2.0'),
            'setup_completed': config_manager.get('setup_completed', False)
        }
        
        return render_template('api_test.html', config=test_config)
    except Exception as e:
        print(f"‚ùå Erreur page API test: {e}")
        flash("Erreur lors du chargement de la page de test API", 'error')
        return redirect(url_for('settings'))

@app.route('/sync/<action>', methods=['GET', 'POST'])
def sync_action(action):
    """Lance une action de synchronisation"""
    
    if task_status["running"]:
        if request.method == 'POST':
            # Pour les requ√™tes AJAX, retourner une erreur JSON
            return jsonify({'success': False, 'error': 'Une t√¢che est d√©j√† en cours'}), 400
        else:
            flash("Une t√¢che est d√©j√† en cours d'ex√©cution", 'warning')
            return redirect(request.referrer or url_for('torrents'))
    
    try:
        token = load_token()
    except:
        if request.method == 'POST':
            return jsonify({'success': False, 'error': 'Token Real-Debrid non configur√©'}), 401
        else:
            flash("Token Real-Debrid non configur√©", 'error')
            return redirect(request.referrer or url_for('torrents'))
    
    # Lancer la synchronisation
    if action == 'smart':
        run_sync_task("Sync intelligent", token, sync_smart)
        action_name = "Synchronisation intelligente"
        log_event('SYNC_TRIGGER', mode='smart', source='web')
    elif action == 'fast':
        run_sync_task("Sync complet", token, sync_all_v2)
        action_name = "Synchronisation compl√®te"
        log_event('SYNC_TRIGGER', mode='fast', source='web')
    elif action == 'torrents':
        run_sync_task("Vue d'ensemble", token, sync_torrents_only)
        action_name = "Vue d'ensemble"
        log_event('SYNC_TRIGGER', mode='torrents_only', source='web')
    else:
        if request.method == 'POST':
            return jsonify({'success': False, 'error': 'Action inconnue'}), 400
        else:
            flash("Action inconnue", 'error')
            return redirect(request.referrer or url_for('torrents'))
    
    if request.method == 'POST':
        # Pour les requ√™tes AJAX, retourner succ√®s avec message descriptif
        return jsonify({'success': True, 'message': f'{action_name} d√©marr√©e avec succ√®s'})
    else:
        # Pour les requ√™tes GET (liens directs), pas de flash automatique et redirection conditionnelle
        referrer = request.referrer
        if referrer and '/torrents' in referrer:
            return redirect('/torrents')
        else:
            return redirect(url_for('torrents'))

@app.route('/api/task_status')
def api_task_status():
    """API de statut simplifi√©e"""
    import time
    
    response = {
        "running": task_status["running"],
        "progress": task_status.get("progress", ""),
        "result": task_status.get("result", ""),
        "last_update": task_status.get("last_update"),
        "timestamp": time.time()
    }
    
    return jsonify(response)

@app.route('/api/health')
def api_health():
    """Route de sant√© pour tester la connectivit√©"""
    import time
    return jsonify({
        "status": "ok",
        "timestamp": time.time(),
        "server": "Redriva Web Interface",
        "version": "2.0"
    })

@app.route('/api/torrents/error_ids', methods=['GET'])
def get_error_torrent_ids():
    """API pour r√©cup√©rer tous les IDs des torrents en erreur"""
    try:
        search = request.args.get('search', '')
        
        with sqlite3.connect(DB_PATH) as conn:
            c = conn.cursor()
            
            # Requ√™te pour r√©cup√©rer tous les IDs des torrents en erreur
            base_query = """
                SELECT t.id
                FROM torrents t
                LEFT JOIN torrent_details td ON t.id = td.id
                WHERE t.status != 'deleted'
                AND (t.status = 'error' OR td.status = 'error')
            """
            
            params = []
            
            # Ajouter la recherche si pr√©sente
            if search:
                search_stripped = search.strip()
                is_probable_id = (
                    (len(search_stripped) == 13 and search_stripped.isalnum() and search_stripped.isupper()) or
                    search_stripped.isdigit() or
                    (len(search_stripped) >= 8 and search_stripped.isalnum() and not ' ' in search_stripped)
                )
                
                if is_probable_id:
                    base_query += " AND (UPPER(t.id) = UPPER(?))"
                    params.append(search_stripped)
                else:
                    base_query += " AND (COALESCE(td.name, t.filename) LIKE ?)"
                    params.append(f'%{search}%')
            
            c.execute(base_query, params)
            torrent_ids = [row[0] for row in c.fetchall()]
            
            return jsonify({
                'success': True,
                'torrent_ids': torrent_ids,
                'count': len(torrent_ids)
            })
            
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/api/torrents/health_error_ids', methods=['GET'])
def get_health_error_torrent_ids():
    """API pour r√©cup√©rer tous les IDs des torrents ayant health_error renseign√© (erreur 503 d√©tect√©e)."""
    try:
        search = request.args.get('search', '')
        with sqlite3.connect(DB_PATH) as conn:
            c = conn.cursor()

            base_query = """
                SELECT td.id
                FROM torrent_details td
                LEFT JOIN torrents t ON td.id = t.id
                WHERE td.health_error IS NOT NULL
                AND (t.status IS NULL OR t.status != 'deleted')
            """

            params = []

            if search:
                search_stripped = search.strip()
                is_probable_id = (
                    (len(search_stripped) == 13 and search_stripped.isalnum() and search_stripped.isupper()) or
                    search_stripped.isdigit() or
                    (len(search_stripped) >= 8 and search_stripped.isalnum() and not ' ' in search_stripped)
                )

                if is_probable_id:
                    base_query += " AND (UPPER(td.id) = UPPER(?))"
                    params.append(search_stripped)
                else:
                    base_query += " AND (COALESCE(td.name, t.filename) LIKE ?)"
                    params.append(f'%{search}%')

            c.execute(base_query, params)
            torrent_ids = [row[0] for row in c.fetchall()]

            return jsonify({
                'success': True,
                'torrent_ids': torrent_ids,
                'count': len(torrent_ids)
            })

    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/torrents/delete_health_errors', methods=['POST'])
def delete_health_error_torrents():
    """R√©cup√®re les IDs des torrents avec health_error et lance leur suppression via Real-Debrid (batch).

    Fonctionne comme `/api/torrents/delete_batch` mais cible uniquement les torrents dont
    `torrent_details.health_error` est renseign√© (erreurs 503 d√©tect√©es). L'UI peut appeler
    d'abord `/api/torrents/health_error_ids` pour afficher/s√©lectionner, puis poster ici pour supprimer.
    """
    try:
        # Charger le token Real-Debrid (obligatoire pour suppression r√©elle)
        token = load_token()
        if not token:
            return jsonify({'success': False, 'error': 'Token Real-Debrid non configur√©'}), 401

        # Supporter un param√®tre de recherche facultatif (dans le corps JSON ou querystring)
        data = request.get_json(silent=True) or {}
        search = data.get('search') if data.get('search') is not None else request.args.get('search', '')

        # R√©cup√©rer les IDs concern√©s
        with sqlite3.connect(DB_PATH) as conn:
            c = conn.cursor()
            base_query = """
                SELECT td.id
                FROM torrent_details td
                LEFT JOIN torrents t ON td.id = t.id
                WHERE td.health_error IS NOT NULL
                AND (t.status IS NULL OR t.status != 'deleted')
            """
            params = []

            if search:
                search_stripped = search.strip()
                is_probable_id = (
                    (len(search_stripped) == 13 and search_stripped.isalnum() and search_stripped.isupper()) or
                    search_stripped.isdigit() or
                    (len(search_stripped) >= 8 and search_stripped.isalnum() and not ' ' in search_stripped)
                )

                if is_probable_id:
                    base_query += " AND (UPPER(td.id) = UPPER(?))"
                    params.append(search_stripped)
                else:
                    base_query += " AND (COALESCE(td.name, t.filename) LIKE ?)"
                    params.append(f'%{search}%')

            c.execute(base_query, params)
            torrent_ids = [row[0] for row in c.fetchall()]

        if not torrent_ids:
            return jsonify({'success': True, 'message': 'Aucun torrent avec health_error √† supprimer', 'total': 0})

        # Lancer la suppression par batch (process_batch_deletion g√®re l'appel RD et la MAJ locale)
        result = process_batch_deletion(token, torrent_ids)

        return jsonify({
            'success': True,
            'message': f'Suppression de {len(torrent_ids)} torrents avec health_error d√©marr√©e',
            'batch_id': result.get('batch_id'),
            'total': len(torrent_ids)
        })

    except Exception as e:
        logging.exception('Erreur delete_health_error_torrents')
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/api/rd/select_files', methods=['POST'])
def api_rd_select_files():
    """S√©lection automatique des fichiers vid√©os d'un torrent via Real-Debrid.

    Re√ßoit JSON { "torrent_id": "..." } et appelle l'API Real-Debrid pour
    lister les fichiers du torrent, appliquer une heuristique de s√©lection
    (extensions vid√©os, filtrage 'sample'/'trailer'...) puis appelle
    l'endpoint de s√©lection de Real-Debrid.
    """
    try:
        payload = request.get_json() or {}
        torrent_id = payload.get('torrent_id')
        if not torrent_id:
            return jsonify({'success': False, 'error': 'torrent_id manquant'}), 400

        token = load_token()
        if not token:
            return jsonify({'success': False, 'error': 'Token Real-Debrid non configur√©'}), 401

        # Helper: r√©cup√©rer les fichiers depuis RD
        def _rd_get_torrent_files(token: str, torrent_id: str):
            url = f'https://api.real-debrid.com/rest/1.0/torrents/files/{torrent_id}'
            headers = {"Authorization": f"Bearer {token}"}
            resp = requests.get(url, headers=headers, timeout=15)
            resp.raise_for_status()
            return resp.json()

        # Helper: appeler l'endpoint selectFiles
        def _rd_select_files(token: str, torrent_id: str, file_indexes: list):
            url = 'https://api.real-debrid.com/rest/1.0/torrents/selectFiles'
            headers = {"Authorization": f"Bearer {token}"}
            data = {"id": torrent_id, "files": ",".join(map(str, file_indexes))}
            resp = requests.post(url, headers=headers, data=data, timeout=15)
            resp.raise_for_status()
            return resp

        files_obj = _rd_get_torrent_files(token, torrent_id)
        files = files_obj.get('files') or {}

        # Heuristique: extensions vid√©os et blacklist simple
        video_exts = ('.mkv', '.mp4', '.avi', '.mov', '.m4v', '.webm')
        blacklist = ('sample', 'trailer', '.srt', 'subtitle', 'subs', 'preview')

        selected_indexes = []
        for idx, info in files.items():
            path = info.get('path', '').lower()
            # ignorer si match blacklist
            if any(b in path for b in blacklist):
                continue
            if any(path.endswith(ext) for ext in video_exts):
                try:
                    selected_indexes.append(int(idx))
                except Exception:
                    # dans le doute, tenter de caster
                    pass

        if not selected_indexes:
            return jsonify({'success': False, 'error': 'Aucun fichier vid√©o d√©tect√©'}), 404

        # Appel √† Real-Debrid pour s√©lectionner
        _rd_select_files(token, torrent_id, selected_indexes)

        logging.info(f"Selected files for torrent {torrent_id}: {selected_indexes}")
        # Optionnel: mettre √† jour la base de donn√©es locale ou journaliser

        return jsonify({'success': True, 'selected': selected_indexes})

    except requests.HTTPError as e:
        logging.exception('Erreur API Real-Debrid')
        try:
            detail = e.response.text
        except Exception:
            detail = str(e)
        return jsonify({'success': False, 'error': 'Erreur Real-Debrid', 'detail': detail}), 502
    except Exception as e:
        logging.exception('Erreur interne s√©lection fichiers RD')
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/torrents/delete_batch', methods=['POST'])
def delete_torrents_batch():
    """Suppression en masse avec traitement automatique par lots"""
    data = request.get_json()
    torrent_ids = data.get('torrent_ids', [])
    
    if not torrent_ids or len(torrent_ids) == 0:
        return jsonify({'success': False, 'error': 'Aucun torrent s√©lectionn√©'}), 400
    
    # Plus de limite fixe - traitement automatique par lots
    total_torrents = len(torrent_ids)
    
    try:
        token = load_token()
        if not token:
            return jsonify({'success': False, 'error': 'Token Real-Debrid non configur√©'}), 401
        
        # D√©marrer le traitement en arri√®re-plan
        result = process_batch_deletion(token, torrent_ids)
        
        # Message adapt√© selon le nombre
        if total_torrents <= 50:
            message = f'Suppression de {total_torrents} torrents d√©marr√©e'
        else:
            message = f'Suppression de {total_torrents} torrents d√©marr√©e (traitement par lots automatique)'
        
        return jsonify({
            'success': True,
            'message': message,
            'batch_id': result['batch_id'],
            'total': total_torrents
        })
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

def process_batch_deletion(token, torrent_ids):
    """Traite la suppression par batch avec gestion d'erreurs"""
    import time
    
    batch_id = str(uuid.uuid4())[:8]
    logging.info(f"üöÄ D√©marrage suppression batch {batch_id}: {len(torrent_ids)} torrents")
    log_event('BATCH_DELETE_START', batch_id=batch_id, total=len(torrent_ids))
    
    # Structure pour suivre les r√©sultats
    batch_results = {
        'batch_id': batch_id,
        'total': len(torrent_ids),
        'processed': 0,
        'success': 0,
        'failed': 0,
        'errors': [],
        'status': 'running',
        'start_time': time.time()
    }
    
    # Stocker dans la variable globale pour le suivi
    batch_operations[batch_id] = batch_results
    
    # Traitement asynchrone
    def deletion_worker():
        # Param√®tres adaptatifs selon le volume
        total = len(torrent_ids)
        if total <= 50:
            batch_size = 10  # Batches plus gros pour petits volumes
            api_delay = 1    # D√©lai plus court
        elif total <= 200:
            batch_size = 8   # Taille interm√©diaire
            api_delay = 1.5
        else:
            batch_size = 5   # Plus conservateur pour gros volumes
            api_delay = 2
            
        max_retries = 3
        
        logging.info(f"üìä Traitement par lots: {total} torrents, taille de lot: {batch_size}, d√©lai: {api_delay}s")
        
        for i in range(0, len(torrent_ids), batch_size):
            if batch_results['status'] == 'cancelled':
                break
                
            batch_torrent_ids = torrent_ids[i:i + batch_size]
            current_batch = (i // batch_size) + 1
            total_batches = (len(torrent_ids) + batch_size - 1) // batch_size
            
            logging.info(f"üîÑ Traitement lot {current_batch}/{total_batches}: {len(batch_torrent_ids)} torrents")
            
            # Traitement du batch actuel
            for torrent_id in batch_torrent_ids:
                success = False
                last_error = None
                
                # Retry avec backoff exponentiel
                for attempt in range(max_retries):
                    try:
                        response = requests.delete(
                            f'https://api.real-debrid.com/rest/1.0/torrents/delete/{torrent_id}',
                            headers={'Authorization': f'Bearer {token}'},
                            timeout=10
                        )
                        
                        if response.status_code == 204:
                            # Succ√®s - Mettre √† jour la DB locale
                            update_torrent_status_deleted(torrent_id)
                            batch_results['success'] += 1
                            success = True
                            break
                            
                        elif response.status_code == 404:
                            # Torrent d√©j√† supprim√© - Consid√©rer comme succ√®s
                            update_torrent_status_deleted(torrent_id)
                            batch_results['success'] += 1
                            success = True
                            break
                            
                        elif response.status_code == 429:
                            # Rate limit - Attendre plus longtemps
                            wait_time = api_delay * (2 ** attempt)
                            logging.warning(f"Rate limit atteint, attente {wait_time}s")
                            time.sleep(wait_time)
                            continue
                            
                        else:
                            last_error = f"HTTP {response.status_code}: {response.text}"
                            
                    except requests.exceptions.Timeout:
                        last_error = "Timeout lors de la suppression"
                        time.sleep(1 * (attempt + 1))  # Pause progressive
                        
                    except requests.exceptions.RequestException as e:
                        last_error = f"Erreur r√©seau: {str(e)}"
                        time.sleep(1 * (attempt + 1))
                        
                    except Exception as e:
                        last_error = f"Erreur inattendue: {str(e)}"
                        break  # Erreur non r√©cup√©rable
                
                # Mise √† jour des r√©sultats
                batch_results['processed'] += 1
                
                if not success:
                    batch_results['failed'] += 1
                    batch_results['errors'].append({
                        'torrent_id': torrent_id,
                        'error': last_error,
                        'attempts': max_retries
                    })
                    logging.error(f"√âchec suppression {torrent_id}: {last_error}")
                # Progress event
                log_event('BATCH_DELETE_PROGRESS', batch_id=batch_id, processed=batch_results['processed'], success=batch_results['success'], failed=batch_results['failed'])
                
                # Pause entre suppressions individuelles
                time.sleep(0.5)
            
            # Pause entre les batches
            if i + batch_size < len(torrent_ids):
                logging.info(f"Pause {api_delay}s avant le prochain batch...")
                time.sleep(api_delay)
        
    # Finalisation
    batch_results['status'] = 'completed'
    batch_results['end_time'] = time.time()
    batch_results['duration'] = batch_results['end_time'] - batch_results['start_time']
    logging.info(f"Suppression termin√©e: {batch_results['success']}/{batch_results['total']} succ√®s")
    log_event('BATCH_DELETE_END', batch_id=batch_id, success=batch_results['success'], failed=batch_results['failed'], duration=f"{batch_results['duration']:.2f}s")
    
    # Lancer le worker en arri√®re-plan
    threading.Thread(target=deletion_worker, daemon=True).start()
    
    return batch_results

@app.route('/api/fix_deleted_status')
def fix_deleted_status():
    """Synchronise les statuts supprim√©s entre les tables torrents et torrent_details"""
    try:
        with sqlite3.connect(DB_PATH) as conn:
            cursor = conn.cursor()
            
            # Trouver les torrents marqu√©s supprim√©s dans 'torrents' mais pas dans 'torrent_details'
            cursor.execute("""
                UPDATE torrent_details 
                SET status = 'deleted' 
                WHERE id IN (
                    SELECT t.id FROM torrents t 
                    WHERE t.status = 'deleted' 
                    AND EXISTS (SELECT 1 FROM torrent_details td WHERE td.id = t.id AND td.status != 'deleted')
                )
            """)
            
            fixed_count = cursor.rowcount
            conn.commit()
            
            print(f"‚úÖ Corrig√© le statut de {fixed_count} torrents dans torrent_details")
            
            return jsonify({
                'success': True,
                'fixed_count': fixed_count,
                'message': f'{fixed_count} torrents corrig√©s'
            })
            
    except Exception as e:
        print(f"‚ùå Erreur lors de la correction des statuts: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

def update_torrent_status_deleted(torrent_id):
    """Marque un torrent comme supprim√© dans la DB locale"""
    try:
        with sqlite3.connect(DB_PATH) as conn:
            cursor = conn.cursor()
            # Mettre √† jour les deux tables
            cursor.execute("""
                UPDATE torrents 
                SET status = 'deleted' 
                WHERE id = ?
            """, (torrent_id,))
            cursor.execute("""
                UPDATE torrent_details 
                SET status = 'deleted' 
                WHERE id = ?
            """, (torrent_id,))
            conn.commit()
            print(f"‚úÖ Torrent {torrent_id} marqu√© comme supprim√© dans les deux tables")
    except Exception as e:
        logging.error(f"Erreur mise √† jour DB pour {torrent_id}: {e}")
        print(f"‚ùå Erreur mise √† jour DB pour {torrent_id}: {e}")

@app.route('/api/batch_status/<batch_id>')
def get_batch_status(batch_id):
    """R√©cup√®re le statut d'une op√©ration par batch avec gestion d'erreurs"""
    try:
        if batch_id not in batch_operations:
            return jsonify({
                'success': False, 
                'error': f'Batch {batch_id} non trouv√© ou expir√©'
            }), 404
        
        batch_data = batch_operations[batch_id]
        
        # Ajouter des informations de debug
        batch_data['last_check'] = time.time()
        
        return jsonify({
            'success': True,
            'batch': batch_data
        })
        
    except Exception as e:
        logging.error(f"Erreur r√©cup√©ration statut batch {batch_id}: {e}")
        return jsonify({
            'success': False, 
            'error': f'Erreur serveur: {str(e)}'
        }), 500

@app.route('/api/torrent/<torrent_id>')
def api_torrent_detail(torrent_id):
    """API pour r√©cup√©rer les d√©tails d'un torrent avec rafra√Æchissement depuis Real-Debrid"""
    try:
        log_event('TORRENT_DETAIL_START', torrent_id=torrent_id)
        token = load_token()
        if not token:
            return get_cached_torrent_data(torrent_id, error_msg="Token Real-Debrid non configur√©")

        async def refresh_torrent_data():
            async with aiohttp.ClientSession() as session:
                result = await fetch_torrent_detail(session, token, torrent_id)
                return result is not None

        try:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            refreshed = loop.run_until_complete(asyncio.wait_for(refresh_torrent_data(), timeout=30.0))
            loop.close()
        except asyncio.TimeoutError:
            logging.warning(f"Timeout lors du rafra√Æchissement du torrent {torrent_id}")
            return get_cached_torrent_data(torrent_id, error_msg="Timeout lors de la r√©cup√©ration des donn√©es fra√Æches", refreshed=False)
        except Exception as e:
            logging.error(f"Erreur lors du rafra√Æchissement du torrent {torrent_id}: {e}")
            return get_cached_torrent_data(torrent_id, error_msg=f"Erreur API: {str(e)}", refreshed=False)

        response = get_cached_torrent_data(torrent_id, refreshed=refreshed)
        log_event('TORRENT_DETAIL_END', torrent_id=torrent_id, refreshed=refreshed)
        return response
    except Exception as e:
        logging.error(f"Erreur dans api_torrent_detail: {e}")
        log_event('TORRENT_DETAIL_END', torrent_id=torrent_id, status='error', error=str(e))
        return jsonify({'success': False, 'error': str(e)}), 500


def get_cached_torrent_data(torrent_id, error_msg=None, refreshed=True):
    """R√©cup√®re les donn√©es du torrent depuis la base locale"""
    try:
        with sqlite3.connect(DB_PATH) as conn:
            c = conn.cursor()
            
            # Informations de base avec les liens de streaming
            c.execute("""
                SELECT t.id, t.filename, t.status, t.bytes, t.added_on,
                       td.name, td.status, td.size, td.files_count, td.progress,
                       td.links, td.streaming_links, td.hash, td.host, td.error, td.added
                FROM torrents t
                LEFT JOIN torrent_details td ON t.id = td.id
                WHERE t.id = ?
            """, (torrent_id,))
            
            torrent = c.fetchone()
            
            if not torrent:
                return jsonify({'success': False, 'error': 'Torrent non trouv√©'}), 404

        # Traitement des liens
        raw_download_links = torrent[10].split(',') if torrent[10] else []
        raw_streaming_links = torrent[11].split(',') if torrent[11] else []
        
        # Formatter les liens de t√©l√©chargement pour le downloader
        formatted_links = []
        for raw_link in raw_download_links:
            if raw_link.strip():
                download_link = format_download_link(raw_link.strip())
                formatted_links.append(download_link)
        
        # Utiliser les vrais liens de streaming depuis la base de donn√©es
        streaming_links = []
        for raw_streaming_link in raw_streaming_links:
            if raw_streaming_link.strip():
                streaming_links.append(raw_streaming_link.strip())
            else:
                streaming_links.append(None)  # Pas de lien streaming pour ce fichier

        # Construire la r√©ponse avec indicateur de fra√Æcheur
        torrent_data = {
            'success': True,
            'torrent': {
                'id': torrent[0],
                'filename': torrent[1],
                'status': torrent[2],
                'bytes': torrent[3],
                'added_on': torrent[4],
                'name': torrent[5],
                'detail_status': torrent[6],
                'size': torrent[7],
                'files_count': torrent[8],
                'progress': torrent[9],
                'links': formatted_links,  # Liens format√©s pour le downloader
                'streaming_links': streaming_links,  # Vrais liens de streaming depuis l'API
                'hash': torrent[12],
                'host': torrent[13],
                'error': torrent[14],
                'added_detail': torrent[15],
                'size_formatted': format_size(torrent[3]) if torrent[3] else format_size(torrent[7]) if torrent[7] else 'N/A',
                'status_emoji': get_status_emoji(torrent[6] or torrent[2]),
                'last_updated': datetime.now().strftime("%H:%M:%S") if refreshed else "Donn√©es en cache"
            },
            'refreshed': refreshed,
            'timestamp': datetime.now().isoformat()
        }
        
        if error_msg and not refreshed:
            torrent_data['warning'] = error_msg
            
        return jsonify(torrent_data)
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e), 'cached_data': None}), 500

@app.route('/api/torrent/delete/<torrent_id>', methods=['POST'])
def delete_torrent(torrent_id):
    """Supprimer un torrent de Real-Debrid"""
    try:
        token = load_token()
        if not token:
            return jsonify({'success': False, 'error': 'Token Real-Debrid non configur√©'})
        
        # Appel API Real-Debrid pour supprimer le torrent
        log_event('TORRENT_DELETE_START', torrent_id=torrent_id)
        response = requests.delete(
            f'https://api.real-debrid.com/rest/1.0/torrents/delete/{torrent_id}',
            headers={'Authorization': f'Bearer {token}'}
        )
        
        if response.status_code == 204:
            # Marquer le torrent comme supprim√© dans la DB locale
            conn = sqlite3.connect(DB_PATH)
            cursor = conn.cursor()
            cursor.execute("""
                UPDATE torrents 
                SET status = 'deleted' 
                WHERE id = ?
            """, (torrent_id,))
            conn.commit()
            conn.close()
            
            log_event('TORRENT_DELETE_END', torrent_id=torrent_id, status='success')
            return jsonify({'success': True, 'message': 'Torrent supprim√© avec succ√®s'})
        else:
            log_event('TORRENT_DELETE_END', torrent_id=torrent_id, status='api_error', http=response.status_code)
            return jsonify({'success': False, 'error': f'Erreur API Real-Debrid: {response.status_code}'})
            
    except Exception as e:
        log_event('TORRENT_DELETE_END', torrent_id=torrent_id, status='error', error=str(e))
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/torrent/reinsert/<torrent_id>', methods=['POST'])
def reinsert_torrent(torrent_id):
    """R√©ins√©rer un torrent dans Real-Debrid"""
    try:
        token = load_token()
        if not token:
            return jsonify({'success': False, 'error': 'Token Real-Debrid non configur√©'})
        
        # R√©cup√©rer les infos du torrent depuis la DB
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        cursor.execute("""
            SELECT t.filename, td.hash 
            FROM torrents t 
            LEFT JOIN torrent_details td ON t.id = td.id 
            WHERE t.id = ?
        """, (torrent_id,))
        torrent_data = cursor.fetchone()
        conn.close()
        
        if not torrent_data or not torrent_data[1]:
            return jsonify({'success': False, 'error': 'Torrent non trouv√© ou hash manquant'})
        
        filename, torrent_hash = torrent_data
        
        # R√©ins√©rer via l'API Real-Debrid
        log_event('TORRENT_REINSERT_START', torrent_id=torrent_id)
        response = requests.post(
            'https://api.real-debrid.com/rest/1.0/torrents/addMagnet',
            headers={'Authorization': f'Bearer {token}'},
            data={'magnet': f'magnet:?xt=urn:btih:{torrent_hash}&dn={filename}'}
        )
        
        if response.status_code == 201:
            result = response.json()
            new_id = result.get('id')
            
            # Mettre √† jour la DB locale
            conn = sqlite3.connect(DB_PATH)
            cursor = conn.cursor()
            cursor.execute("""
                UPDATE torrents 
                SET id = ?, status = 'magnet_error' 
                WHERE id = ?
            """, (new_id, torrent_id))
            conn.commit()
            conn.close()
            
            log_event('TORRENT_REINSERT_END', torrent_id=torrent_id, new_id=new_id, status='success')
            return jsonify({'success': True, 'message': 'Torrent r√©ins√©r√© avec succ√®s', 'new_id': new_id})
        else:
            log_event('TORRENT_REINSERT_END', torrent_id=torrent_id, status='api_error', http=response.status_code)
            return jsonify({'success': False, 'error': f'Erreur API Real-Debrid: {response.status_code}'})
            
    except Exception as e:
        log_event('TORRENT_REINSERT_END', torrent_id=torrent_id, status='error', error=str(e))
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/media_info/<file_id>')
def get_media_info(file_id):
    """
    R√©cup√®re les informations d√©taill√©es d'un fichier via /streaming/mediaInfos.
    L'ID est celui obtenu apr√®s un appel √† /unrestrict/link.
    """
    token = load_token()
    if not token:
        return jsonify({'success': False, 'error': 'Token non configur√©'}), 401

    url = f"https://api.real-debrid.com/rest/1.0/streaming/mediaInfos/{file_id}"
    headers = {"Authorization": f"Bearer {token}"}
    
    try:
        response = requests.get(url, headers=headers, timeout=15)
        response.raise_for_status()  # L√®ve une exception pour les codes 4xx/5xx
        
        media_data = response.json()
        
        # Simplifions la structure pour le front-end
        details = media_data.get('details', {})
        
        # V√©rifier le type des donn√©es pour √©viter l'erreur 'list' object has no attribute 'values'
        video_data = details.get('video', {})
        audio_data = details.get('audio', {})
        subtitles_data = details.get('subtitles', {})
        
        # Si c'est d√©j√† une liste, l'utiliser directement, sinon extraire les valeurs du dict
        if isinstance(video_data, list):
            video_streams = video_data
        else:
            video_streams = list(video_data.values()) if video_data else []
            
        if isinstance(audio_data, list):
            audio_streams = audio_data
        else:
            audio_streams = list(audio_data.values()) if audio_data else []
            
        if isinstance(subtitles_data, list):
            subtitle_streams = subtitles_data
        else:
            subtitle_streams = list(subtitles_data.values()) if subtitles_data else []

        return jsonify({
            'success': True,
            'filename': media_data.get('filename'),
            'type': media_data.get('type'),
            'duration': media_data.get('duration'),
            'size': media_data.get('size'),
            'video': video_streams,
            'audio': audio_streams,
            'subtitles': subtitle_streams,
            'poster': media_data.get('poster_path'),
            'backdrop': media_data.get('backdrop_path')
        })

    except requests.exceptions.HTTPError as e:
        error_msg = f"Erreur API Real-Debrid: {e.response.status_code}"
        try:
            error_details = e.response.json()
            error_msg += f" - {error_details.get('error', e.response.text)}"
        except ValueError:
            pass
        return jsonify({'success': False, 'error': error_msg}), e.response.status_code
    except Exception as e:
        logging.error(f"Erreur dans get_media_info: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/torrent/stream/<torrent_id>', methods=['GET'])
def get_stream_links(torrent_id):
    """
    R√©cup√©rer les liens de streaming et download pour un torrent
    Bas√© sur l'analyse de l'API Real-Debrid : 
    - Download : liens directs depuis torrent_info.links
    - Streaming : file_id obtenu via d√©bridage + construction du lien streaming
    """
    try:
        token = load_token()
        if not token:
            return jsonify({'success': False, 'error': 'Token Real-Debrid non configur√©'})
        
        # R√©cup√©rer les infos du torrent depuis Real-Debrid avec timeout augment√©
        try:
            response = requests.get(
                f'https://api.real-debrid.com/rest/1.0/torrents/info/{torrent_id}',
                headers={'Authorization': f'Bearer {token}'},
                timeout=30  # Timeout de 30 secondes (augment√©)
            )
            logging.debug(f"R√©ponse torrent info: {response.status_code}")
        except requests.exceptions.Timeout:
            print(f"‚è±Ô∏è Timeout lors de la r√©cup√©ration des infos torrent {torrent_id}")
            return jsonify({'success': False, 'error': 'Timeout lors de la r√©cup√©ration des informations du torrent'})
        except requests.exceptions.RequestException as e:
            print(f"‚ùå Erreur r√©seau torrent info: {e}")
            return jsonify({'success': False, 'error': f'Erreur r√©seau: {str(e)}'})
        
        if response.status_code == 404:
            return jsonify({'success': False, 'error': 'Torrent non trouv√© sur Real-Debrid'})
        elif response.status_code != 200:
            return jsonify({'success': False, 'error': f'Erreur API Real-Debrid: {response.status_code}'})
        
        torrent_info = response.json()
        
        # R√©cup√©rer les liens directs de download depuis la structure
        download_links = torrent_info.get('links', [])
        files_info = torrent_info.get('files', [])
        
        if not download_links:
            print("‚ö†Ô∏è Aucun lien de t√©l√©chargement trouv√©")
            return jsonify({
                'success': True,
                'torrent_info': {
                    'id': torrent_id,
                    'filename': torrent_info.get('filename', 'Unknown'),
                    'status': torrent_info.get('status', 'unknown'),
                    'progress': torrent_info.get('progress', 0)
                },
                'files': [],
                'total_files': 0,
                'message': 'Aucun lien de t√©l√©chargement disponible'
            })
        
        # G√©n√©rer les donn√©es compl√®tes pour chaque fichier avec traitement parall√®le am√©lior√©
        file_data = []
        
        for i, download_link in enumerate(download_links):
            try:
                # Informations du fichier (si disponibles)
                file_info = files_info[i] if i < len(files_info) else {}
                filename = file_info.get('path', f'Fichier {i+1}')
                file_size = file_info.get('bytes', 0)
                selected = file_info.get('selected', 1)  # R√©cup√©rer la propri√©t√© selected (1 pour vid√©o, 0 pour NFO)
                
                print(f"üîÑ Traitement fichier {i+1}: {filename}")
                
                # √âtape 1: D√©brider le lien pour obtenir le file_id avec timeout augment√©
                try:
                    unrestrict_response = requests.post(
                        'https://api.real-debrid.com/rest/1.0/unrestrict/link',
                        headers={'Authorization': f'Bearer {token}'},
                        data={'link': download_link},
                        timeout=20  # Timeout de 20 secondes pour d√©bridage (augment√©)
                    )
                    logging.debug(f"D√©bridage fichier {i+1}: {unrestrict_response.status_code}")
                except requests.exceptions.Timeout:
                    print(f"‚è±Ô∏è Timeout lors du d√©bridage fichier {i+1}")
                    formatted_download = format_download_link(download_link)
                    file_data.append({
                        'index': i,
                        'filename': filename,
                        'size': file_size,
                        'selected': selected,  # Ajouter la propri√©t√© selected pour le filtrage
                        'download_link': formatted_download,
                        'direct_download': download_link,
                        'streaming_link': None,
                        'file_id': None,
                        'mime_type': 'unknown',
                        'error': 'Timeout lors du d√©bridage'
                    })
                    continue
                except requests.exceptions.RequestException as e:
                    print(f"‚ùå Erreur r√©seau d√©bridage fichier {i+1}: {e}")
                    formatted_download = format_download_link(download_link)
                    file_data.append({
                        'index': i,
                        'filename': filename,
                        'size': file_size,
                        'selected': selected,  # Ajouter la propri√©t√© selected pour le filtrage
                        'download_link': formatted_download,
                        'direct_download': download_link,
                        'streaming_link': None,
                        'file_id': None,
                        'mime_type': 'unknown',
                        'error': f'Erreur r√©seau: {str(e)}'
                    })
                    continue
                
                if unrestrict_response.status_code == 200:
                    unrestrict_data = unrestrict_response.json()
                    file_id = unrestrict_data.get('id')
                    direct_download = unrestrict_data.get('download', download_link)
                    
                    # √âtape 2: Construire le lien streaming
                    streaming_link = f"https://real-debrid.com/streaming-{file_id}" if file_id else None
                    
                    print(f"‚úÖ Fichier {i+1} d√©brid√©: file_id={file_id}")
                    
                    # Formater le lien de t√©l√©chargement pour le downloader
                    formatted_download = format_download_link(direct_download)
                    
                    file_data.append({
                        'index': i,
                        'filename': filename,
                        'size': file_size,
                        'selected': selected,  # Ajouter la propri√©t√© selected pour le filtrage
                        'download_link': formatted_download,  # Lien format√© pour le downloader Real-Debrid  
                        'direct_download': direct_download,  # Lien direct brut
                        'streaming_link': streaming_link,  # Lien de streaming construit
                        'file_id': file_id,  # ID pour r√©cup√©rer les m√©tadonn√©es
                        'mime_type': unrestrict_data.get('mimeType', 'unknown')
                    })
                else:
                    # En cas d'√©chec du d√©bridage, garder au moins le lien de base format√©
                    print(f"‚ö†Ô∏è √âchec d√©bridage fichier {i+1}: {unrestrict_response.status_code}")
                    formatted_download = format_download_link(download_link)
                    file_data.append({
                        'index': i,
                        'filename': filename,
                        'size': file_size,
                        'selected': selected,  # Ajouter la propri√©t√© selected pour le filtrage
                        'download_link': formatted_download,
                        'direct_download': download_link,
                        'streaming_link': None,
                        'file_id': None,
                        'mime_type': 'unknown',
                        'error': f'√âchec d√©bridage: {unrestrict_response.status_code}'
                    })
                        
            except Exception as file_error:
                # Log l'erreur mais continue avec les autres fichiers
                print(f"‚ùå Erreur traitement fichier {i}: {file_error}")
                formatted_download = format_download_link(download_link)
                file_data.append({
                    'index': i,
                    'filename': f'Fichier {i+1}',
                    'size': 0,
                    'selected': 1,  # Par d√©faut, consid√©rer comme s√©lectionn√© si erreur
                    'download_link': formatted_download,
                    'direct_download': download_link,
                    'streaming_link': None,
                    'file_id': None,
                    'mime_type': 'unknown',
                    'error': str(file_error)
                })
        
        return jsonify({
            'success': True, 
            'torrent_info': {
                'id': torrent_id,
                'filename': torrent_info.get('filename', 'Unknown'),
                'status': torrent_info.get('status', 'unknown'),
                'progress': torrent_info.get('progress', 0)
            },
            'files': file_data,
            'total_files': len(file_data)
        })
            
    except Exception as e:
        print(f"‚ùå Erreur critique dans get_stream_links: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'error': f'Erreur interne: {str(e)}'})

@app.route('/api/torrent/files/<torrent_id>', methods=['GET'])
def get_torrent_files(torrent_id):
    """
    R√©cup√©rer uniquement la liste des fichiers avec propri√©t√© selected (sans d√©bridage)
    API rapide pour filtrage NFO vs vid√©o
    """
    try:
        token = load_token()
        if not token:
            return jsonify({'success': False, 'error': 'Token Real-Debrid non configur√©'})
        
        # R√©cup√©rer uniquement les infos des fichiers depuis Real-Debrid
        response = requests.get(
            f'https://api.real-debrid.com/rest/1.0/torrents/info/{torrent_id}',
            headers={'Authorization': f'Bearer {token}'},
            timeout=10  # Timeout court car pas de d√©bridage
        )
        
        if response.status_code == 404:
            return jsonify({'success': False, 'error': 'Torrent non trouv√© sur Real-Debrid'})
        elif response.status_code != 200:
            return jsonify({'success': False, 'error': f'Erreur API Real-Debrid: {response.status_code}'})
        
        torrent_info = response.json()
        files_info = torrent_info.get('files', [])
        
        # Formater les fichiers avec leurs propri√©t√©s selected
        files_data = []
        for i, file_info in enumerate(files_info):
            files_data.append({
                'index': i,
                'filename': file_info.get('path', f'Fichier {i+1}'),
                'size': file_info.get('bytes', 0),
                'selected': file_info.get('selected', 1),  # selected: 1 pour vid√©o, 0 pour NFO
            })
        
        return jsonify({
            'success': True,
            'torrent_info': {
                'id': torrent_id,
                'filename': torrent_info.get('filename', 'Unknown'),
                'status': torrent_info.get('status', 'unknown'),
                'progress': torrent_info.get('progress', 0)
            },
            'files': files_data,
            'total_files': len(files_data)
        })
            
    except Exception as e:
        print(f"‚ùå Erreur dans get_torrent_files: {e}")
        return jsonify({'success': False, 'error': f'Erreur interne: {str(e)}'})

@app.route('/api/refresh_stats')
def refresh_stats():
    """Recalcule et retourne les statistiques de la base de donn√©es avec nettoyage des torrents supprim√©s."""
    try:
        log_event('STATS_REFRESH_START')
        # √âtape 1: Nettoyer les torrents marqu√©s comme "deleted"
        cleanup_result = cleanup_deleted_torrents()
        
        if not cleanup_result['success']:
            return jsonify({
                "success": False, 
                "error": f"Erreur lors du nettoyage: {cleanup_result.get('error', 'Erreur inconnue')}"
            }), 500
        
        deleted_count = cleanup_result['deleted_count']
        
        # √âtape 2: Recalculer les statistiques sur la base nettoy√©e
        with sqlite3.connect(DB_PATH) as conn:
            c = conn.cursor()
            
            # Statistiques de base (plus besoin d'exclure les 'deleted' car ils ont √©t√© supprim√©s)
            c.execute("SELECT COUNT(*) FROM torrents")
            total_torrents = c.fetchone()[0]
            
            c.execute("SELECT COUNT(*) FROM torrent_details")
            total_details = c.fetchone()[0]
            
            coverage = (total_details / total_torrents * 100) if total_torrents > 0 else 0
            
            # Erreurs
            error_count = 0
            if ERROR_STATUSES:
                placeholders = ','.join('?' * len(ERROR_STATUSES))
                c.execute(f"""
                    SELECT COUNT(DISTINCT t.id) 
                    FROM torrents t
                    LEFT JOIN torrent_details td ON t.id = td.id
                    WHERE COALESCE(t.status, td.status) IN ({placeholders})
                """, ERROR_STATUSES)
                error_count = c.fetchone()[0] or 0
            
            # T√©l√©charg√©s
            c.execute("SELECT COUNT(*) FROM torrent_details WHERE status = 'downloaded'")
            downloaded_count = c.fetchone()[0] or 0
            
            # Fichiers indisponibles
            c.execute("""
                SELECT COUNT(DISTINCT td.id) 
                FROM torrent_details td
                WHERE (td.error LIKE '%503%' OR td.error LIKE '%404%' OR td.error LIKE '%24%' 
                       OR td.error LIKE '%unavailable_file%' OR td.error LIKE '%rd_error_%'
                       OR td.error LIKE '%health_check_error%' OR td.error LIKE '%http_error_%')
            """)
            unavailable_files = c.fetchone()[0] or 0
            
            # Actifs
            active_count = 0
            if ACTIVE_STATUSES:
                placeholders = ','.join('?' * len(ACTIVE_STATUSES))
                c.execute(f"""
                    SELECT COUNT(DISTINCT t.id) 
                    FROM torrents t
                    LEFT JOIN torrent_details td ON t.id = td.id
                    WHERE COALESCE(t.status, td.status) IN ({placeholders})
                """, ACTIVE_STATUSES)
                active_count = c.fetchone()[0] or 0

        response = jsonify({
            "success": True,
            "message": f"{deleted_count} torrent(s) supprim√©(s). Statistiques mises √† jour.",
            "deleted_count": deleted_count,
            "cleanup_details": {
                "torrents_deleted": cleanup_result.get('torrents_deleted', 0),
                "details_deleted": cleanup_result.get('details_deleted', 0)
            },
            "stats": {
                "total_torrents": total_torrents,
                "total_details": total_details,
                "coverage": round(coverage, 1),
                "error_count": error_count,
                "downloaded_count": downloaded_count,
                "active_count": active_count,
                "unavailable_files": unavailable_files
            }
        })
        log_event('STATS_REFRESH_END', torrents=total_torrents, details=total_details, coverage=round(coverage,1), errors=error_count, active=active_count, deleted=deleted_count)
        return response
        
    except Exception as e:
        print(f"‚ùå Erreur dans refresh_stats: {e}")
        log_event('STATS_REFRESH_END', status='error', error=str(e))
        import traceback
        traceback.print_exc()
        return jsonify({"success": False, "error": str(e)}), 500

@app.route('/api/cleanup_deleted', methods=['POST'])
def api_cleanup_deleted():
    """API pour nettoyer les torrents marqu√©s comme supprim√©s"""
    try:
        log_event('CLEAN_TRIGGER', source='api')
        result = cleanup_deleted_torrents()
        
        if result['success']:
            log_event('CLEAN_RETURN', deleted=result.get('deleted_count',0), status='success')
            return jsonify(result)
        else:
            log_event('CLEAN_RETURN', status='error', error=result.get('error'))
            return jsonify(result), 500
            
    except Exception as e:
        print(f"‚ùå Erreur dans api_cleanup_deleted: {e}")
        log_event('CLEAN_RETURN', status='error', error=str(e))
        return jsonify({
            "success": False, 
            "error": str(e),
            "deleted_count": 0
        }), 500


@app.route('/api/health/check/<torrent_id>', methods=['GET', 'POST'])
def check_single_torrent_health(torrent_id):
    """API pour v√©rifier la sant√© d'un torrent sp√©cifique via api/torrent/stream"""
    try:
        log_event('HEALTH_SINGLE_START', torrent_id=torrent_id)
        token = load_token()
        
        with sqlite3.connect(DB_PATH) as conn:
            c = conn.cursor()
            
            # V√©rifier que le torrent existe
            c.execute("""
                SELECT t.id, t.filename 
                FROM torrents t
                WHERE t.id = ? AND t.status != 'deleted' AND t.status != 'error'
            """, (torrent_id,))
            torrent_info = c.fetchone()
            
            if not torrent_info:
                return jsonify({
                    'success': False,
                    'error': 'Torrent non trouv√© ou supprim√©'
                })
            
            logging.info(f"V√©rification de la sant√© du torrent {torrent_id} via stream endpoint...")
            error_503_found = False
            error_message = None
            
            try:
                # Appeler l'endpoint local /api/torrent/stream/{id}
                with app.test_client() as client:
                    response = client.get(f'/api/torrent/stream/{torrent_id}')
                    
                    if response.status_code == 200:
                        try:
                            data = response.get_json()
                            
                            # Rechercher l'erreur "√âchec d√©bridage: 503" dans la r√©ponse
                            if data and isinstance(data, dict):
                                # V√©rifier s'il y a une erreur 503 dans la r√©ponse principale
                                if 'error' in data and '503' in str(data['error']):
                                    error_503_found = True
                                    error_message = str(data['error'])
                                
                                # V√©rifier dans les fichiers si pr√©sents
                                elif 'files' in data and isinstance(data['files'], list):
                                    for file_info in data['files']:
                                        if isinstance(file_info, dict) and 'error' in file_info:
                                            if '503' in str(file_info['error']):
                                                error_503_found = True
                                                error_message = str(file_info['error'])
                                                break
                                
                                # Si erreur 503 d√©tect√©e, mettre √† jour la base de donn√©es
                                if error_503_found:
                                    # Cr√©er l'entr√©e torrent_details si elle n'existe pas
                                    c.execute("INSERT OR IGNORE INTO torrent_details (id) VALUES (?)", (torrent_id,))
                                    
                                    # Mettre √† jour seulement le champ health_error
                                    c.execute("""
                                        UPDATE torrent_details 
                                        SET health_error = ?
                                        WHERE id = ?
                                    """, (error_message, torrent_id))
                                    
                                    print(f"‚ö†Ô∏è Erreur 503 d√©tect√©e pour torrent {torrent_id}: {error_message}")
                                
                                # Si aucune erreur 503, nettoyer l'ancien champ health_error
                                else:
                                    c.execute("""
                                        UPDATE torrent_details 
                                        SET health_error = NULL
                                        WHERE id = ?
                                    """, (torrent_id,))
                            
                        except (json.JSONDecodeError, KeyError) as json_error:
                            print(f"‚ö†Ô∏è Erreur parsing JSON pour torrent {torrent_id}: {json_error}")
                            return jsonify({'success': False, 'error': f'Erreur parsing r√©ponse: {json_error}'})
                    
                    else:
                        print(f"‚ö†Ô∏è Erreur HTTP {response.status_code} pour torrent {torrent_id}")
                        return jsonify({'success': False, 'error': f'Erreur HTTP: {response.status_code}'})
                
            except Exception as torrent_error:
                print(f"‚ùå Erreur lors de la v√©rification du torrent {torrent_id}: {torrent_error}")
                return jsonify({'success': False, 'error': str(torrent_error)})
            
            conn.commit()
            
            # Construire la r√©ponse selon le r√©sultat
            if error_503_found:
                log_event('HEALTH_SINGLE_END', torrent_id=torrent_id, status='503')
                return jsonify({
                    'success': True,
                    'message': f'‚ö†Ô∏è Erreur 503 d√©tect√©e pour le torrent {torrent_id}',
                    'error_503_found': True,
                    'error_message': error_message,
                    'torrent_id': torrent_id
                })
            else:
                log_event('HEALTH_SINGLE_END', torrent_id=torrent_id, status='ok')
                return jsonify({
                    'success': True,
                    'message': f'‚úÖ Torrent {torrent_id} en bonne sant√©',
                    'error_503_found': False,
                    'torrent_id': torrent_id
                })
            
    except Exception as e:
        print(f"‚ùå Erreur lors de la v√©rification de sant√© du torrent {torrent_id}: {e}")
        log_event('HEALTH_SINGLE_END', torrent_id=torrent_id, status='error', error=str(e))
        return jsonify({'success': False, 'error': str(e)})


@app.route('/api/health/cleanup_503', methods=['GET', 'POST'])
def cleanup_health_503():
    """Nettoie (marque deleted) tous les torrents ayant un champ health_error non NULL (erreur 503 d√©tect√©e)."""
    try:
        log_event('HEALTH_503_CLEAN_START')
        token = None
        try:
            token = load_token()
        except Exception:
            # Token non obligatoire pour le nettoyage local
            token = None

        with sqlite3.connect(DB_PATH) as conn:
            c = conn.cursor()

            # R√©cup√©rer les torrents ayant health_error renseign√©
            c.execute("""
                SELECT td.id, td.name
                FROM torrent_details td
                LEFT JOIN torrents t ON td.id = t.id
                WHERE td.health_error IS NOT NULL
                AND (t.status IS NULL OR t.status != 'deleted')
            """)
            bad_torrents = c.fetchall()

            if not bad_torrents:
                log_event('HEALTH_503_CLEAN_END', cleaned=0, status='nothing')
                return jsonify({'success': True, 'message': 'Aucun torrent avec health_error trouv√©', 'cleaned': 0})

            cleaned_count = 0
            for torrent_id, name in bad_torrents:
                try:
                    c.execute("UPDATE torrents SET status = 'deleted' WHERE id = ?", (torrent_id,))
                    c.execute("UPDATE torrent_details SET status = 'deleted' WHERE id = ?", (torrent_id,))
                    cleaned_count += 1
                    logging.info(f"Nettoy√© (503): {name} ({torrent_id})")
                except Exception as e:
                    logging.error(f"Erreur nettoyage 503 pour {torrent_id}: {e}")

            conn.commit()

            log_event('HEALTH_503_CLEAN_END', cleaned=cleaned_count, status='success')

            return jsonify({'success': True, 'message': f'{cleaned_count} torrent(s) avec health_error nettoy√©s', 'cleaned': cleaned_count})

    except Exception as e:
        logging.exception('Erreur cleanup_health_503')
        log_event('HEALTH_503_CLEAN_END', status='error', error=str(e))
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/health/check_all', methods=['GET', 'POST'])
def check_all_files_health():
    """API pour v√©rifier la sant√© de tous les liens de fichiers - T√ÇCHE EN ARRI√àRE-PLAN"""
    try:
        token = load_token()
        
        if not token:
            return jsonify({
                'success': False,
                'error': 'Token Real-Debrid non configur√©'
            })
        
        # V√©rifier si une t√¢che de health check est d√©j√† en cours
        if task_status["running"]:
            return jsonify({
                'success': False,
                'error': 'Une t√¢che de synchronisation est d√©j√† en cours',
                'current_task': task_status.get("progress", "T√¢che en cours...")
            })
        
        # D√©marrer la t√¢che de health check en arri√®re-plan
        run_health_check_task(token)
        
        return jsonify({
            'success': True,
            'message': 'V√©rification de sant√© d√©marr√©e en arri√®re-plan',
            'info': 'Utilisez /api/task_status pour suivre l\'avancement',
            'estimated_duration': 'Peut prendre plusieurs heures selon le nombre de torrents'
        })
            
    except Exception as e:
        print(f"‚ùå Erreur lors du d√©marrage de la v√©rification de sant√©: {e}")
        log_event('HEALTH_CHECK_START', status='error', error=str(e))
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/health/cleanup', methods=['GET', 'POST'])
def cleanup_unavailable_files():
    """API pour nettoyer les fichiers indisponibles et notifier Sonarr/Radarr"""
    try:
        log_event('UNAVAILABLE_CLEAN_START')
        token = load_token()
        
        with sqlite3.connect(DB_PATH) as conn:
            c = conn.cursor()
            
            # Identifier les torrents avec liens indisponibles
            c.execute("""
                SELECT td.id, td.name, td.links
                FROM torrent_details td
                LEFT JOIN torrents t ON td.id = t.id
                WHERE t.status != 'deleted' 
                AND (td.error LIKE '%503%' OR td.error LIKE '%404%' OR td.error LIKE '%24%' 
                     OR td.error LIKE '%unavailable_file%' OR td.error LIKE '%rd_error_%'
                     OR td.error LIKE '%health_check_error%' OR td.error LIKE '%http_error_%')
            """)
            unavailable_torrents = c.fetchall()
            
            if not unavailable_torrents:
                return jsonify({
                    'success': True,
                    'message': 'Aucun fichier indisponible √† nettoyer',
                    'cleaned': 0
                })
            
            cleaned_count = 0
            
            # Supprimer les torrents indisponibles
            for torrent_id, name, links_json in unavailable_torrents:
                try:
                    # Marquer comme supprim√© dans la base locale
                    c.execute("UPDATE torrents SET status = 'deleted' WHERE id = ?", (torrent_id,))
                    c.execute("UPDATE torrent_details SET status = 'deleted' WHERE id = ?", (torrent_id,))
                    
                    # Optionnel: Supprimer √©galement c√¥t√© Real-Debrid si souhait√©
                    # (d√©comment√© si n√©cessaire)
                    # try:
                    #     requests.delete(
                    #         f'https://api.real-debrid.com/rest/1.0/torrents/delete/{torrent_id}',
                    #         headers={'Authorization': f'Bearer {token}'},
                    #         timeout=10
                    #     )
                    # except:
                    #     pass  # Ignorer les erreurs de suppression RD
                    
                    cleaned_count += 1
                    logging.info(f"Nettoy√©: {name}")
                    
                except Exception as cleanup_error:
                    print(f"‚ùå Erreur nettoyage {torrent_id}: {cleanup_error}")
            
            conn.commit()
            
            # Optionnel: Notification Sonarr/Radarr si module symlink disponible
            try:
                from symguard_integration import notify_arr_missing_content
                # Cette fonction devrait √™tre impl√©ment√©e pour notifier les *arr
                # notify_arr_missing_content(unavailable_torrents)
                logging.info("Notification Sonarr/Radarr envoy√©e (si configur√©)")
            except ImportError:
                logging.info("Module symlink non disponible, pas de notification *arr")
            
            response = jsonify({
                'success': True,
                'message': f'{cleaned_count} fichiers indisponibles nettoy√©s',
                'cleaned': cleaned_count
            })
            log_event('UNAVAILABLE_CLEAN_END', cleaned=cleaned_count, status='success')
            return response
            
    except Exception as e:
        print(f"‚ùå Erreur lors du nettoyage: {e}")
        log_event('UNAVAILABLE_CLEAN_END', status='error', error=str(e))
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/processing_torrents')
def get_processing_torrents():
    """API pour r√©cup√©rer le d√©tail des torrents en cours de traitement"""
    try:
        with sqlite3.connect(DB_PATH) as conn:
            c = conn.cursor()
            
            # Logique unifi√©e : une seule requ√™te avec JOIN pour √©viter les doublons
            # Priorit√© au statut depuis torrents (source de v√©rit√©, mise √† jour plus rapide)
            if ACTIVE_STATUSES:
                placeholders = ','.join('?' * len(ACTIVE_STATUSES))
                
                # Comptage unifi√© : priorit√© torrents.status, fallback sur torrent_details.status
                # Exclusion stricte des torrents supprim√©s (torrents.status = 'deleted')
                c.execute(f"""
                    SELECT COUNT(DISTINCT t.id) 
                    FROM torrents t
                    LEFT JOIN torrent_details td ON t.id = td.id
                    WHERE t.status != 'deleted' 
                    AND COALESCE(t.status, td.status) IN ({placeholders})
                """, ACTIVE_STATUSES)
                processing_count = c.fetchone()[0] or 0
                
                # D√©tail par statut avec priorit√© torrents.status
                c.execute(f"""
                    SELECT COALESCE(t.status, td.status) as final_status, COUNT(DISTINCT t.id) as count
                    FROM torrents t
                    LEFT JOIN torrent_details td ON t.id = td.id
                    WHERE t.status != 'deleted' 
                    AND COALESCE(t.status, td.status) IN ({placeholders})
                    GROUP BY COALESCE(t.status, td.status)
                    ORDER BY count DESC
                """, ACTIVE_STATUSES)
                status_breakdown = c.fetchall()
                
                # Comptage des erreurs avec m√™me logique
                if ERROR_STATUSES:
                    error_placeholders = ','.join('?' * len(ERROR_STATUSES))
                    c.execute(f"""
                        SELECT COUNT(DISTINCT t.id) 
                        FROM torrents t
                        LEFT JOIN torrent_details td ON t.id = td.id
                        WHERE t.status != 'deleted' 
                        AND COALESCE(t.status, td.status) IN ({error_placeholders})
                    """, ERROR_STATUSES)
                    error_count = c.fetchone()[0] or 0
                else:
                    error_count = 0
                
                # R√©cup√©rer quelques exemples avec statut unifi√©
                c.execute(f"""
                    SELECT t.id, t.filename, t.status as torrent_status, 
                           td.status as detail_status, td.progress, 
                           t.added_on, td.name,
                           COALESCE(t.status, td.status) as final_status
                    FROM torrents t
                    LEFT JOIN torrent_details td ON t.id = td.id
                    WHERE t.status != 'deleted' 
                    AND COALESCE(t.status, td.status) IN ({placeholders})
                    ORDER BY t.added_on DESC
                    LIMIT 10
                """, ACTIVE_STATUSES)
                
                examples = []
                for row in c.fetchall():
                    examples.append({
                        'id': row[0],
                        'filename': row[1],
                        'torrent_status': row[2],
                        'detail_status': row[3],
                        'progress': row[4] or 0,
                        'added_on': row[5],
                        'display_name': row[6] or row[1],
                        'final_status': row[7]
                    })
                
            else:
                processing_count = 0
                error_count = 0
                status_breakdown = []
                examples = []
            
            return jsonify({
                'success': True,
                'processing_count': processing_count,
                'error_count': error_count,
                'status_breakdown': [{'status': s[0], 'count': s[1]} for s in status_breakdown],
                'active_statuses': list(ACTIVE_STATUSES) if ACTIVE_STATUSES else [],
                'error_statuses': list(ERROR_STATUSES) if ERROR_STATUSES else [],
                'examples': examples,
                'timestamp': datetime.now().isoformat()
            })
            
    except Exception as e:
        print(f"‚ùå Erreur lors de la r√©cup√©ration des torrents en traitement: {e}")
        return jsonify({'success': False, 'error': str(e)})

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# ROUTES API SETTINGS
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

@app.route('/api/settings', methods=['GET'])
def get_settings():
    """API pour r√©cup√©rer les param√®tres actuels"""
    try:
        config = get_config()
        
        # R√©cup√©rer tous les param√®tres depuis la configuration centralis√©e
        settings = {
            'apiToken': '',  # Ne jamais renvoyer le token r√©el pour des raisons de s√©curit√©
            'mediaPath': config.get_media_path(),
            'workersCount': config.get('workers.count', 3),
            'sonarr': {
                'enabled': config.get('sonarr.enabled', False),
                'url': config.get('sonarr.url', ''),
                'apiKey': config.get('sonarr.api_key', '')
            },
            'radarr': {
                'enabled': config.get('radarr.enabled', False),
                'url': config.get('radarr.url', ''),
                'apiKey': config.get('radarr.api_key', '')
            },
            'autoSyncEnabled': config.get('automation.auto_sync_enabled', False),
            'syncInterval': config.get('automation.sync_interval', 300),
            'autoCleanupEnabled': config.get('automation.auto_cleanup_enabled', False)
        }
        
        return jsonify({'success': True, 'settings': settings})
        
    except Exception as e:
        print(f"‚ùå Erreur get_settings: {e}")
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/settings', methods=['POST'])
def save_settings():
    """API pour sauvegarder les param√®tres"""
    try:
        settings = request.get_json()
        if not settings:
            return jsonify({'success': False, 'error': 'Donn√©es manquantes'})
        
        config = get_config()
        
        # Mettre √† jour la configuration centralis√©e en utilisant update_config
        if 'apiToken' in settings and settings['apiToken']:
            config.update_config('realdebrid.token', settings['apiToken'])
        
        if 'mediaPath' in settings:
            if config.is_docker:
                config.update_config('paths.media', settings['mediaPath'])
            else:
                config.update_config('paths.media_dev', settings['mediaPath'])
        
        if 'workersCount' in settings:
            config.update_config('workers.count', settings['workersCount'])
        
        # Param√®tres Sonarr
        if 'sonarr' in settings:
            sonarr = settings['sonarr']
            config.update_config('sonarr.enabled', sonarr.get('enabled', False))
            config.update_config('sonarr.url', sonarr.get('url', ''))
            config.update_config('sonarr.api_key', sonarr.get('apiKey', ''))
        
        # Param√®tres Radarr
        if 'radarr' in settings:
            radarr = settings['radarr']
            config.update_config('radarr.enabled', radarr.get('enabled', False))
            config.update_config('radarr.url', radarr.get('url', ''))
            config.update_config('radarr.api_key', radarr.get('apiKey', ''))
        
        # Param√®tres d'automatisation
        if 'autoSyncEnabled' in settings:
            config.update_config('automation.auto_sync_enabled', settings['autoSyncEnabled'])
        if 'syncInterval' in settings:
            config.update_config('automation.sync_interval', settings['syncInterval'])
        if 'autoCleanupEnabled' in settings:
            config.update_config('automation.auto_cleanup_enabled', settings['autoCleanupEnabled'])
        
        return jsonify({'success': True, 'message': 'Param√®tres sauvegard√©s'})
        
    except Exception as e:
        print(f"‚ùå Erreur save_settings: {e}")
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/settings/reset', methods=['POST'])
def reset_settings():
    """API pour r√©initialiser les param√®tres"""
    try:
        config = get_config()
        
        # R√©initialiser la configuration avec les valeurs par d√©faut
        if config.reset_to_defaults():
            return jsonify({'success': True, 'message': 'Param√®tres r√©initialis√©s'})
        else:
            return jsonify({'success': False, 'error': 'Erreur lors de la r√©initialisation'})
        
    except Exception as e:
        print(f"‚ùå Erreur reset_settings: {e}")
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/settings/export')
def export_settings():
    """API pour exporter les param√®tres"""
    try:
        from flask import send_file
        import tempfile
        
        config = get_config()
        
        # R√©cup√©rer la configuration actuelle (sans le token pour s√©curit√©)
        export_config = config.get_full_config()
        
        # Cr√©er un fichier temporaire pour l'export
        with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.json') as f:
            json.dump(export_config, f, indent=2)
            temp_file = f.name
        
        return send_file(temp_file, as_attachment=True, 
                        download_name=f'redriva-settings-{datetime.now().strftime("%Y%m%d")}.json',
                        mimetype='application/json')
        
    except Exception as e:
        print(f"‚ùå Erreur export_settings: {e}")
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/settings/import', methods=['POST'])
def import_settings():
    """API pour importer les param√®tres"""
    try:
        settings = request.get_json()
        if not settings:
            return jsonify({'success': False, 'error': 'Donn√©es manquantes'})
        
        config = get_config()
        
        # Valider que les param√®tres import√©s ont une structure valide
        if not isinstance(settings, dict):
            return jsonify({'success': False, 'error': 'Format de configuration invalide'})
        
        # Merger avec la configuration existante pour pr√©server les donn√©es importantes
        current_config = config.config.copy()
        current_config.update(settings)
        
        # Sauvegarder la nouvelle configuration
        if config.set_full_config(current_config):
            return jsonify({'success': True, 'message': 'Param√®tres import√©s'})
        else:
            return jsonify({'success': False, 'error': 'Erreur lors de l\'import'})
        
    except Exception as e:
        print(f"‚ùå Erreur import_settings: {e}")
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/test-connection', methods=['POST'])
def test_api_connection():
    """API pour tester la connexion Real-Debrid"""
    try:
        data = request.get_json()
        token = data.get('token', '').strip()
        
        if not token:
            return jsonify({'success': False, 'error': 'Token manquant'})
        
        # Tester la connexion √† l'API Real-Debrid
        headers = {'Authorization': f'Bearer {token}'}
        response = requests.get('https://api.real-debrid.com/rest/1.0/user', 
                              headers=headers, timeout=10)
        
        if response.status_code == 200:
            user_data = response.json()
            return jsonify({
                'success': True, 
                'message': f'Connect√© en tant que {user_data.get("username", "utilisateur")}'
            })
        else:
            return jsonify({
                'success': False, 
                'error': f'Erreur API: {response.status_code}'
            })
            
    except requests.RequestException as e:
        return jsonify({'success': False, 'error': f'Erreur de connexion: {str(e)}'})
    except Exception as e:
        print(f"‚ùå Erreur test_api_connection: {e}")
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/proxy-rd', methods=['POST'])
def proxy_real_debrid():
    """Proxy pour les appels √† l'API Real-Debrid depuis le frontend"""
    try:
        # R√©cup√©rer les param√®tres depuis le body JSON ou les query parameters
        data = request.get_json() or {}
        
        # Priorit√© au body JSON, sinon query parameters (pour compatibilit√©)
        endpoint = data.get('endpoint') or request.args.get('endpoint', '')
        method = data.get('method') or request.args.get('method', 'GET')
        body = data.get('body')
        
        print(f"üîç Proxy RD - Endpoint: {endpoint}, Method: {method}")
        
        # Charger le token
        token = load_token()
        if not token:
            return jsonify({'error': 'Token Real-Debrid non configur√©'}), 401
        
        # Construire l'URL compl√®te
        base_url = 'https://api.real-debrid.com/rest/1.0'
        url = f"{base_url}{endpoint}"
        
        # Headers d'authentification
        headers = {
            'Authorization': f'Bearer {token}',
            'Content-Type': 'application/json'
        }
        
        # Faire l'appel API
        if method.upper() == 'GET':
            response = requests.get(url, headers=headers, timeout=30)
        elif method.upper() == 'POST':
            response = requests.post(url, headers=headers, json=body, timeout=30)
        elif method.upper() == 'PUT':
            response = requests.put(url, headers=headers, json=body, timeout=30)
        elif method.upper() == 'DELETE':
            response = requests.delete(url, headers=headers, timeout=30)
        else:
            return jsonify({'error': f'M√©thode HTTP non support√©e: {method}'}), 400
        
        # Retourner la r√©ponse
        try:
            return jsonify(response.json())
        except ValueError:
            # Si la r√©ponse n'est pas du JSON
            return jsonify({
                'status_code': response.status_code,
                'text': response.text,
                'success': response.status_code < 400
            })
            
    except requests.RequestException as e:
        return jsonify({'error': f'Erreur de connexion: {str(e)}'}), 500
    except Exception as e:
        print(f"‚ùå Erreur proxy_real_debrid: {e}")
        return jsonify({'error': str(e)}), 500

# ================== ENDPOINTS DE DIAGNOSTIC ==================

@app.route('/api/diagnostic/token', methods=['GET'])
def diagnostic_token():
    """Diagnostic du token Real-Debrid"""
    try:
        config_manager = get_config()
        token = config_manager.get_token()
        
        diagnostic = {
            'token_configured': bool(token),
            'token_length': len(token) if token else 0,
            'token_format': 'valid' if token and len(token) == 40 else 'invalid' if token else 'missing',
            'config_source': 'config_manager',
            'timestamp': datetime.now().isoformat()
        }
        
        if token:
            # Test de base de validit√© (sans appel API)
            diagnostic['token_sample'] = f"{token[:8]}...{token[-8:]}" if len(token) >= 16 else "too_short"
        
        return jsonify({
            'success': True,
            'diagnostic': diagnostic
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/diagnostic/database', methods=['GET'])
def diagnostic_database():
    """Diagnostic de la base de donn√©es"""
    try:
        config_manager = get_config()
        db_path = config_manager.get_db_path()
        
        diagnostic = {
            'db_path': db_path,
            'db_exists': os.path.exists(db_path),
            'db_readable': False,
            'db_writable': False,
            'db_size': 0,
            'tables_count': 0,
            'torrents_count': 0
        }
        
        if os.path.exists(db_path):
            diagnostic['db_readable'] = os.access(db_path, os.R_OK)
            diagnostic['db_writable'] = os.access(db_path, os.W_OK)
            diagnostic['db_size'] = os.path.getsize(db_path)
            
            try:
                conn = sqlite3.connect(db_path)
                cursor = conn.cursor()
                
                # Compter les tables
                cursor.execute("SELECT COUNT(*) FROM sqlite_master WHERE type='table'")
                diagnostic['tables_count'] = cursor.fetchone()[0]
                
                # Compter les torrents
                cursor.execute("SELECT COUNT(*) FROM torrents")
                diagnostic['torrents_count'] = cursor.fetchone()[0]
                
                conn.close()
            except Exception as db_error:
                diagnostic['db_error'] = str(db_error)
        
        return jsonify({
            'success': True,
            'diagnostic': diagnostic
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/diagnostic/config', methods=['GET'])
def diagnostic_config():
    """Diagnostic de la configuration"""
    try:
        config_manager = get_config()
        config_full = config_manager.get_full_config()
        
        diagnostic = {
            'config_file_exists': os.path.exists(os.path.join(os.path.dirname(__file__), '..', 'config', 'config.json')),
            'version': config_manager.get('version', 'unknown'),
            'setup_completed': config_manager.get('setup_completed', False),
            'sections': {
                'realdebrid': bool(config_full.get('realdebrid')),
                'sonarr': bool(config_full.get('sonarr')),
                'radarr': bool(config_full.get('radarr')),
                'symlink': bool(config_full.get('symlink')),
                'flask': bool(config_full.get('flask')),
                'app': bool(config_full.get('app'))
            },
            'services_status': {
                'sonarr_enabled': config_manager.get('sonarr.enabled', False),
                'radarr_enabled': config_manager.get('radarr.enabled', False),
                'symlink_enabled': config_manager.get('symlink.enabled', False)
            },
            'paths': {
                'db_path': config_manager.get_db_path(),
                'media_path': config_manager.get_media_path()
            }
        }
        
        return jsonify({
            'success': True,
            'diagnostic': diagnostic
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/diagnostic/paths', methods=['GET'])
def diagnostic_paths():
    """Diagnostic des chemins syst√®me"""
    try:
        config_manager = get_config()
        
        paths_to_check = {
            'db_path': config_manager.get_db_path(),
            'media_path': config_manager.get_media_path(),
            'config_dir': os.path.join(os.path.dirname(__file__), '..', 'config'),
            'data_dir': os.path.join(os.path.dirname(__file__), '..', 'data'),
            'current_dir': os.getcwd(),
            'src_dir': os.path.dirname(__file__)
        }
        
        diagnostic = {}
        for name, path in paths_to_check.items():
            diagnostic[name] = {
                'path': path,
                'exists': os.path.exists(path),
                'readable': os.access(path, os.R_OK) if os.path.exists(path) else False,
                'writable': os.access(path, os.W_OK) if os.path.exists(path) else False,
                'type': 'directory' if os.path.isdir(path) else 'file' if os.path.isfile(path) else 'missing'
            }
        
        return jsonify({
            'success': True,
            'diagnostic': diagnostic
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# ROUTES API ARR MONITOR
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

@app.route('/api/arr/monitor/status')
def arr_monitor_status():
    """API pour r√©cup√©rer le statut du moniteur Arr"""
    if not ARR_MONITOR_AVAILABLE:
        return jsonify({
            'success': False,
            'error': 'Module arr_monitor non disponible'
        }), 503
    
    try:
        config_manager = get_config()
        monitor = get_arr_monitor(config_manager)
        status = monitor.get_status()
        
        return jsonify({
            'success': True,
            'status': status
        })
    except Exception as e:
        logging.error(f"Erreur r√©cup√©ration statut arr monitor: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/arr/monitor/start', methods=['POST'])
def arr_monitor_start():
    """API pour d√©marrer la surveillance Arr"""
    if not ARR_MONITOR_AVAILABLE:
        return jsonify({
            'success': False,
            'error': 'Module arr_monitor non disponible'
        }), 503
    
    try:
        data = request.get_json() or {}
        interval = data.get('interval', 300)  # 5 minutes par d√©faut
        
        config_manager = get_config()
        monitor = get_arr_monitor(config_manager)
        
        if monitor.start_monitoring(interval):
            return jsonify({
                'success': True,
                'message': f'Surveillance Arr d√©marr√©e (intervalle: {interval}s)'
            })
        else:
            return jsonify({
                'success': False,
                'error': 'Surveillance d√©j√† en cours'
            })
    except Exception as e:
        logging.error(f"Erreur d√©marrage arr monitor: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/arr/monitor/stop', methods=['POST'])
def arr_monitor_stop():
    """API pour arr√™ter la surveillance Arr"""
    if not ARR_MONITOR_AVAILABLE:
        return jsonify({
            'success': False,
            'error': 'Module arr_monitor non disponible'
        }), 503
    
    try:
        config_manager = get_config()
        monitor = get_arr_monitor(config_manager)
        
        if monitor.stop_monitoring():
            return jsonify({
                'success': True,
                'message': 'Surveillance Arr arr√™t√©e'
            })
        else:
            return jsonify({
                'success': False,
                'error': 'Surveillance d√©j√† arr√™t√©e'
            })
    except Exception as e:
        logging.error(f"Erreur arr√™t arr monitor: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/arr/monitor/cycle', methods=['POST'])
def arr_monitor_cycle():
    """API pour lancer un cycle de surveillance manuel"""
    if not ARR_MONITOR_AVAILABLE:
        return jsonify({
            'success': False,
            'error': 'Module arr_monitor non disponible'
        }), 503
    
    try:
        config_manager = get_config()
        monitor = get_arr_monitor(config_manager)
        
        results = monitor.run_cycle()
        
        return jsonify({
            'success': True,
            'message': 'Cycle de surveillance termin√©',
            'results': results,
            'total_corrections': sum(results.values())
        })
    except Exception as e:
        logging.error(f"Erreur cycle arr monitor: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/arr/monitor/diagnose/<app_name>')
def arr_monitor_diagnose(app_name):
    """API pour diagnostiquer une application Arr"""
    if not ARR_MONITOR_AVAILABLE:
        return jsonify({
            'success': False,
            'error': 'Module arr_monitor non disponible'
        }), 503
    
    if app_name.lower() not in ['sonarr', 'radarr']:
        return jsonify({
            'success': False,
            'error': 'Application non support√©e (sonarr/radarr uniquement)'
        }), 400
    
    try:
        config_manager = get_config()
        monitor = get_arr_monitor(config_manager)
        
        diagnostic = monitor.diagnose_queue(app_name.lower())
        
        return jsonify({
            'success': True,
            'diagnostic': diagnostic
        })
    except Exception as e:
        logging.error(f"Erreur diagnostic arr monitor {app_name}: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/arr-monitor')
def arr_monitor_page():
    """Page de gestion du moniteur Arr"""
    if not ARR_MONITOR_AVAILABLE:
        flash('Module arr_monitor non disponible', 'error')
        return redirect(url_for('settings'))
    
    try:
        config_manager = get_config()
        monitor = get_arr_monitor(config_manager)
        status = monitor.get_status()
        
        return render_template('arr_monitor.html', 
                             monitor_status=status,
                             arr_available=ARR_MONITOR_AVAILABLE)
    except Exception as e:
        logging.error(f"Erreur page arr monitor: {e}")
        flash(f'Erreur: {e}', 'error')
        return redirect(url_for('settings'))

# === API GESTION TYPES D'ERREURS ===

@app.route('/api/arr/error-types')
def api_get_error_types():
    """R√©cup√®re la configuration des types d'erreurs"""
    if not ARR_MONITOR_AVAILABLE:
        return jsonify({
            'success': False,
            'error': 'Module arr_monitor non disponible'
        }), 500
    
    try:
        config_manager = get_config()
        monitor = get_arr_monitor(config_manager)
        error_types = monitor.get_error_types_config()
        
        return jsonify({
            'success': True,
            'error_types': error_types
        })
        
    except Exception as e:
        logging.error(f"Erreur r√©cup√©ration types erreurs: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/arr/error-types/<error_type_name>', methods=['PUT'])
def api_update_error_type(error_type_name):
    """Met √† jour la configuration d'un type d'erreur"""
    if not ARR_MONITOR_AVAILABLE:
        return jsonify({
            'success': False,
            'error': 'Module arr_monitor non disponible'
        }), 500
    
    try:
        config_data = request.get_json()
        if not config_data:
            return jsonify({
                'success': False,
                'error': 'Donn√©es de configuration manquantes'
            }), 400
        
        config_manager = get_config()
        monitor = get_arr_monitor(config_manager)
        result = monitor.update_error_type_config(error_type_name, config_data)
        
        return jsonify(result)
        
    except Exception as e:
        logging.error(f"Erreur mise √† jour type erreur {error_type_name}: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/arr/error-types', methods=['POST'])
def api_create_error_type():
    """Cr√©e un nouveau type d'erreur"""
    if not ARR_MONITOR_AVAILABLE:
        return jsonify({
            'success': False,
            'error': 'Module arr_monitor non disponible'
        }), 500
    
    try:
        config_data = request.get_json()
        if not config_data or not config_data.get('name'):
            return jsonify({
                'success': False,
                'error': 'Nom du type d\'erreur manquant'
            }), 400
        
        error_type_name = config_data.pop('name')
        
        config_manager = get_config()
        monitor = get_arr_monitor(config_manager)
        result = monitor.create_error_type(error_type_name, config_data)
        
        return jsonify(result)
        
    except Exception as e:
        logging.error(f"Erreur cr√©ation type erreur: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/arr/error-types/<error_type_name>', methods=['DELETE'])
def api_delete_error_type(error_type_name):
    """Supprime un type d'erreur"""
    if not ARR_MONITOR_AVAILABLE:
        return jsonify({
            'success': False,
            'error': 'Module arr_monitor non disponible'
        }), 500
    
    try:
        config_manager = get_config()
        monitor = get_arr_monitor(config_manager)
        result = monitor.delete_error_type(error_type_name)
        
        return jsonify(result)
        
    except Exception as e:
        logging.error(f"Erreur suppression type erreur {error_type_name}: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/arr/error-statistics')
def api_get_error_statistics():
    """R√©cup√®re les statistiques de d√©tection des erreurs"""
    if not ARR_MONITOR_AVAILABLE:
        return jsonify({
            'success': False,
            'error': 'Module arr_monitor non disponible'
        }), 500
    
    try:
        config_manager = get_config()
        monitor = get_arr_monitor(config_manager)
        statistics = monitor.get_detection_statistics()
        
        return jsonify({
            'success': True,
            'statistics': statistics
        })
        
    except Exception as e:
        logging.error(f"Erreur r√©cup√©ration statistiques: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/arr/available-actions')
def api_get_available_actions():
    """R√©cup√®re la liste des actions disponibles"""
    if not ARR_MONITOR_AVAILABLE:
        return jsonify({
            'success': False,
            'error': 'Module arr_monitor non disponible'
        }), 500
    
    try:
        config_manager = get_config()
        monitor = get_arr_monitor(config_manager)
        actions = monitor.get_available_actions()
        
        return jsonify({
            'success': True,
            'actions': actions
        })
        
    except Exception as e:
        logging.error(f"Erreur r√©cup√©ration actions: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/arr/test-error-detection', methods=['POST'])
def api_test_error_detection():
    """Teste la d√©tection d'erreur sur un √©l√©ment donn√©"""
    if not ARR_MONITOR_AVAILABLE:
        return jsonify({
            'success': False,
            'error': 'Module arr_monitor non disponible'
        }), 500
    
    try:
        data = request.get_json()
        if not data or not data.get('test_item'):
            return jsonify({
                'success': False,
                'error': '√âl√©ment de test manquant'
            }), 400
        
        config_manager = get_config()
        monitor = get_arr_monitor(config_manager)
        result = monitor.test_error_detection(data['test_item'])
        
        return jsonify({
            'success': True,
            'result': result
        })
        
    except Exception as e:
        logging.error(f"Erreur test d√©tection: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/arr/error-types/import', methods=['POST'])
def api_import_error_types():
    """Importe une configuration de types d'erreurs"""
    if not ARR_MONITOR_AVAILABLE:
        return jsonify({
            'success': False,
            'error': 'Module arr_monitor non disponible'
        }), 500
    
    try:
        data = request.get_json()
        if not data or not data.get('config'):
            return jsonify({
                'success': False,
                'error': 'Configuration d\'import manquante'
            }), 400
        
        config_manager = get_config()
        monitor = get_arr_monitor(config_manager)
        
        # Importer chaque type d'erreur
        imported_count = 0
        errors = []
        
        for error_type_name, config_data in data['config'].items():
            try:
                result = monitor.update_error_type_config(error_type_name, config_data)
                if result.get('success'):
                    imported_count += 1
                else:
                    errors.append(f"{error_type_name}: {result.get('error', 'Erreur inconnue')}")
            except Exception as e:
                errors.append(f"{error_type_name}: {str(e)}")
        
        if errors:
            return jsonify({
                'success': False,
                'error': f"Erreurs d'import: {'; '.join(errors)}",
                'imported_count': imported_count
            }), 400
        
        return jsonify({
            'success': True,
            'message': f'{imported_count} types d\'erreurs import√©s avec succ√®s',
            'imported_count': imported_count
        })
        
    except Exception as e:
        logging.error(f"Erreur import types erreurs: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/arr/test-connections', methods=['POST'])
def test_arr_connections():
    """API pour tester les connexions aux services *Arr"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({'success': False, 'error': 'Donn√©es manquantes'})
        
        results = {}
        
        # Test Sonarr
        if data.get('sonarr', {}).get('enabled', False):
            sonarr_url = data['sonarr'].get('url', '').strip()
            sonarr_api = data['sonarr'].get('apiKey', '').strip()
            
            if sonarr_url and sonarr_api:
                try:
                    import requests
                    # Test de connexion √† Sonarr
                    test_url = f"{sonarr_url.rstrip('/')}/api/v3/system/status"
                    headers = {'X-Api-Key': sonarr_api}
                    response = requests.get(test_url, headers=headers, timeout=10)
                    
                    if response.status_code == 200:
                        system_info = response.json()
                        results['sonarr'] = {
                            'success': True,
                            'message': f"‚úÖ Connect√© - Version: {system_info.get('version', 'Inconnue')}",
                            'version': system_info.get('version'),
                            'startTime': system_info.get('startTime')
                        }
                    else:
                        results['sonarr'] = {
                            'success': False,
                            'message': f"‚ùå Erreur HTTP {response.status_code}"
                        }
                except requests.exceptions.Timeout:
                    results['sonarr'] = {
                        'success': False,
                        'message': "‚ùå Timeout - V√©rifiez l'URL"
                    }
                except requests.exceptions.ConnectionError:
                    results['sonarr'] = {
                        'success': False,
                        'message': "‚ùå Connexion impossible - V√©rifiez l'URL et le service"
                    }
                except Exception as e:
                    results['sonarr'] = {
                        'success': False,
                        'message': f"‚ùå Erreur: {str(e)}"
                    }
            else:
                results['sonarr'] = {
                    'success': False,
                    'message': "‚ùå URL ou cl√© API manquante"
                }
        
        # Test Radarr
        if data.get('radarr', {}).get('enabled', False):
            radarr_url = data['radarr'].get('url', '').strip()
            radarr_api = data['radarr'].get('apiKey', '').strip()
            
            if radarr_url and radarr_api:
                try:
                    import requests
                    # Test de connexion √† Radarr
                    test_url = f"{radarr_url.rstrip('/')}/api/v3/system/status"
                    headers = {'X-Api-Key': radarr_api}
                    response = requests.get(test_url, headers=headers, timeout=10)
                    
                    if response.status_code == 200:
                        system_info = response.json()
                        results['radarr'] = {
                            'success': True,
                            'message': f"‚úÖ Connect√© - Version: {system_info.get('version', 'Inconnue')}",
                            'version': system_info.get('version'),
                            'startTime': system_info.get('startTime')
                        }
                    else:
                        results['radarr'] = {
                            'success': False,
                            'message': f"‚ùå Erreur HTTP {response.status_code}"
                        }
                except requests.exceptions.Timeout:
                    results['radarr'] = {
                        'success': False,
                        'message': "‚ùå Timeout - V√©rifiez l'URL"
                    }
                except requests.exceptions.ConnectionError:
                    results['radarr'] = {
                        'success': False,
                        'message': "‚ùå Connexion impossible - V√©rifiez l'URL et le service"
                    }
                except Exception as e:
                    results['radarr'] = {
                        'success': False,
                        'message': f"‚ùå Erreur: {str(e)}"
                    }
            else:
                results['radarr'] = {
                    'success': False,
                    'message': "‚ùå URL ou cl√© API manquante"
                }
        
        if not results:
            return jsonify({
                'success': False,
                'message': 'Aucun service activ√© pour le test'
            })
        
        return jsonify({
            'success': True,
            'results': results
        })
        
    except Exception as e:
        logging.error(f"Erreur test connexions *Arr: {e}")
        return jsonify({'success': False, 'error': str(e)})

if __name__ == '__main__':
    import signal
    import sys
    
    def signal_handler(sig, frame):
        print("\nüõë Interruption re√ßue, arr√™t du serveur...")
        sys.exit(0)
    
    # Gestionnaire de signal pour arr√™t propre
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    
    print("üåê D√©marrage de l'interface web Redriva...")
    print(f"üì± URL: http://{app.config['HOST']}:{app.config['PORT']}")
    print("üõë Utilisez Ctrl+C pour arr√™ter")
    
    try:
        app.run(host=app.config['HOST'], 
                port=app.config['PORT'], 
                debug=app.config['DEBUG'],
                threaded=True,
                use_reloader=False)
    except KeyboardInterrupt:
        print("\nüõë Arr√™t demand√© par l'utilisateur")
    except Exception as e:
        print(f"‚ùå Erreur du serveur: {e}")
    finally:
        print("üîÑ Serveur web arr√™t√©")

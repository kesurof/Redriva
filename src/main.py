#!/usr/bin/env python3
"""
Redriva - Synchroniseur Real-Debrid
====================================
Outil de synchronisation Python pour archiver vos torrents Real-Debrid 
dans une base de donnÃ©es SQLite locale.

Maintenu via Claude/Copilot - Architecture monolithique organisÃ©e

TABLE DES MATIÃˆRES:
==================
1. IMPORTS ET CONFIGURATION          (lignes 1-80)
2. UTILITAIRES ET HELPERS           (lignes 81-150)  
3. BASE DE DONNÃ‰ES                  (lignes 151-220)
4. API REAL-DEBRID                  (lignes 221-400)
5. SYNCHRONISATION                  (lignes 401-700)
6. STATISTIQUES ET ANALYTICS        (lignes 701-850)
7. DIAGNOSTIC ET MAINTENANCE        (lignes 851-950)
8. INTERFACE UTILISATEUR (MENU)     (lignes 951-1100)
9. POINT D'ENTRÃ‰E PRINCIPAL         (lignes 1100+)

FonctionnalitÃ©s principales:
- ğŸ”„ Synchronisation intelligente avec modes optimisÃ©s
- ğŸ“Š Statistiques complÃ¨tes et analytics avancÃ©es  
- ğŸ” Diagnostic automatique des erreurs
- ğŸ® Menu interactif convivial
- âš¡ Performance optimisÃ©e avec contrÃ´le dynamique
"""

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘                         SECTION 1: IMPORTS ET CONFIGURATION                â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import os
import sys
import argparse
import asyncio
import aiohttp
import sqlite3
import time
import signal
import logging
import json
import re
from pathlib import Path

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONSTANTES DE STATUTS POUR COHÃ‰RENCE DANS TOUT LE CODE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Statuts considÃ©rÃ©s comme "actifs" (torrents en cours de traitement)
ACTIVE_STATUSES = (
    'downloading',           # â¬‡ï¸ En cours de tÃ©lÃ©chargement
    'queued',               # ğŸ”„ En file d'attente
    'waiting_files_selection', # â³ En attente de sÃ©lection des fichiers
    'magnet_conversion',    # ğŸ§² Conversion magnet en cours
    'uploading',            # â¬†ï¸ Upload en cours
    'compressing',          # ğŸ—œï¸ Compression en cours
    'waiting'               # â³ En attente gÃ©nÃ©rique
)

# Statuts considÃ©rÃ©s comme "erreurs" (problÃ¨mes nÃ©cessitant intervention)
ERROR_STATUSES = (
    'error',                # âŒ Erreur gÃ©nÃ©rique
    'magnet_error',         # ğŸ§²âŒ Erreur de magnet
    'virus',                # ğŸ¦  Fichier infectÃ©
    'dead',                 # ğŸ’€ Torrent mort
    'timeout',              # â±ï¸ Timeout
    'hoster_unavailable'    # ğŸš« HÃ©bergeur indisponible
)

# Statuts considÃ©rÃ©s comme "terminÃ©s" (tÃ©lÃ©chargements rÃ©ussis)
COMPLETED_STATUSES = (
    'downloaded',           # âœ… TÃ©lÃ©chargÃ© avec succÃ¨s
    'finished'              # ğŸ TerminÃ©
)

# Tous les statuts connus (pour validation)
ALL_KNOWN_STATUSES = ACTIVE_STATUSES + ERROR_STATUSES + COMPLETED_STATUSES


# Configuration du logging avec format enrichi
logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] %(levelname)s: %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# LOGGING STRUCTURE : helper pour Ã©vÃ©nements parsables dans docker logs
# Convention : lignes commenÃ§ant par [SYNC_*] / [DETAILS_*] / [CLEAN_*]
# Format : [TAG key=value key2=value2 ...] (valeurs sans espaces, ou entre guillemets)
# Objectif : permettre grep/awk facile (ex: grep '^\[SYNC_END').
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def log_event(tag: str, **fields):
    """Ã‰met une ligne de log structurÃ©e parsable.

    Args:
        tag (str): Nom d'Ã©vÃ©nement (ex: SYNC_START, SYNC_END, DETAILS_PROGRESS)
        **fields: Paires clÃ©=valeur (sans transformation). Les valeurs contenant
                  des espaces ou '=' seront entourÃ©es de guillemets doubles.
    """
    parts = []
    for k, v in fields.items():
        if v is None:
            continue
        val = str(v)
        if ' ' in val or '=' in val:
            val = '"' + val.replace('"', "'") + '"'
        parts.append(f"{k}={val}")
    line = f"[{tag} {' '.join(parts)}]" if parts else f"[{tag}]"
    # Utilise logging.info pour rester homogÃ¨ne avec le reste
    logging.info(line)

# Gestion de l'interruption propre (CTRL+C)
stop_requested = False
def handle_sigint(signum, frame):
    """Gestionnaire d'interruption propre pour Ã©viter la corruption de donnÃ©es"""
    global stop_requested
    logging.warning("Interruption clavier reÃ§ue (CTRL+C), arrÃªt propre...")
    stop_requested = True

signal.signal(signal.SIGINT, handle_sigint)

# Configuration via gestionnaire centralisÃ©
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from config_manager import get_config

# Configuration avec nouvelles valeurs centralisÃ©es
RD_API_URL = "https://api.real-debrid.com/rest/1.0/torrents"

# Fonction pour obtenir le chemin de la base de donnÃ©es
def get_db_path():
    """RÃ©cupÃ¨re le chemin de la base de donnÃ©es via le gestionnaire de configuration"""
    config = get_config()
    return config.get_db_path()

# Utilisation du gestionnaire de configuration pour les paramÃ¨tres
config = get_config()
MAX_CONCURRENT = config.get('realdebrid.max_concurrent', 50)
BATCH_SIZE = config.get('realdebrid.batch_size', 250)
QUOTA_WAIT_TIME = config.get('realdebrid.quota_wait', 60)
TORRENT_QUOTA_WAIT = config.get('realdebrid.torrent_wait', 10)
PAGE_WAIT_TIME = config.get('realdebrid.page_wait', 1.0)

# DB_PATH sera initialisÃ© dynamiquement via get_db_path()
DB_PATH = get_db_path()

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘                         SECTION 2: UTILITAIRES ET HELPERS                 â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def format_size(bytes_size):
    """
    Convertit les bytes en format lisible (KB, MB, GB, TB)
    
    Args:
        bytes_size (int): Taille en bytes
        
    Returns:
        str: Taille formatÃ©e avec unitÃ© appropriÃ©e
        
    Example:
        >>> format_size(1536000000)
        '1.4 GB'
    """
    if bytes_size is None:
        return "N/A"
    
    for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
        if bytes_size < 1024.0:
            return f"{bytes_size:.1f} {unit}"
        bytes_size /= 1024.0
    return f"{bytes_size:.1f} PB"

def get_status_emoji(status):
    """
    Retourne un emoji reprÃ©sentatif selon le statut du torrent
    
    Args:
        status (str): Statut du torrent
        
    Returns:
        str: Emoji correspondant au statut
    """
    status_emojis = {
        'downloaded': 'âœ…',      # TÃ©lÃ©chargement terminÃ©
        'downloading': 'â¬‡ï¸',     # En cours de tÃ©lÃ©chargement
        'waiting': 'â³',         # En attente
        'queued': 'ğŸ”„',          # En file d'attente
        'error': 'âŒ',           # Erreur
        'magnet_error': 'ğŸ§²âŒ',   # Erreur magnet
        'magnet_conversion': 'ğŸ§²', # Conversion magnet
        'virus': 'ğŸ¦ ',           # Virus dÃ©tectÃ©
        'dead': 'ğŸ’€',            # Torrent mort
        'uploading': 'â¬†ï¸',       # Upload en cours
        'compressing': 'ğŸ—œï¸'      # Compression en cours
    }
    return status_emojis.get(status, 'â“')

def safe_int(value, default=0):
    """
    Conversion sÃ©curisÃ©e en entier
    
    Args:
        value: Valeur Ã  convertir
        default (int): Valeur par dÃ©faut si conversion impossible
        
    Returns:
        int: Valeur convertie ou valeur par dÃ©faut
    """
    try:
        return int(value) if value is not None else default
    except (ValueError, TypeError):
        return default

def safe_float(value, default=0.0):
    """
    Conversion sÃ©curisÃ©e en float
    
    Args:
        value: Valeur Ã  convertir
        default (float): Valeur par dÃ©faut si conversion impossible
        
    Returns:
        float: Valeur convertie ou valeur par dÃ©faut
    """
    try:
        return float(value) if value is not None else default
    except (ValueError, TypeError):
        return default

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘                           SECTION 3: BASE DE DONNÃ‰ES                      â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def create_tables():
    """
    Initialise la base de donnÃ©es SQLite avec les tables nÃ©cessaires
    
    Tables crÃ©Ã©es:
    - torrents: Informations de base des torrents
    - torrent_details: DÃ©tails complets des torrents
    - sync_progress: Progression des synchronisations (pour reprise)
    """
    db_path = get_db_path()
    os.makedirs(os.path.dirname(db_path), exist_ok=True)
    
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    
    # Table principale des torrents (informations de base)
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS torrents (
            id TEXT PRIMARY KEY,
            filename TEXT,
            status TEXT,
            bytes INTEGER,
            added_on TEXT
        )
    ''')
    
    # Table des dÃ©tails complets
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS torrent_details (
            id TEXT PRIMARY KEY,
            name TEXT,
            status TEXT,
            size INTEGER,
            files_count INTEGER,
            progress INTEGER,
            links TEXT,
            streaming_links TEXT,
            hash TEXT,
            host TEXT,
            error TEXT,
            added TEXT,
            FOREIGN KEY (id) REFERENCES torrents (id)
        )
    ''')
    
    # Table pour la reprise des synchronisations
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS sync_progress (
            id INTEGER PRIMARY KEY,
            operation TEXT,
            total_items INTEGER,
            processed_items INTEGER,
            last_processed_id TEXT,
            start_time TEXT,
            status TEXT
        )
    ''')
    
    # Ajouter la nouvelle colonne health_error si elle n'existe pas
    try:
        cursor.execute("ALTER TABLE torrent_details ADD COLUMN health_error TEXT")
        logging.info("âœ… Colonne health_error ajoutÃ©e Ã  torrent_details")
    except sqlite3.OperationalError:
        # La colonne existe dÃ©jÃ 
        pass
    
    # Index pour optimiser les performances
    cursor.execute('CREATE INDEX IF NOT EXISTS idx_torrents_status ON torrents(status)')
    cursor.execute('CREATE INDEX IF NOT EXISTS idx_torrents_added ON torrents(added_on)')
    cursor.execute('CREATE INDEX IF NOT EXISTS idx_details_status ON torrent_details(status)')
    
    conn.commit()
    conn.close()
    logging.info("Base de donnÃ©es initialisÃ©e avec succÃ¨s")

def get_db_stats():
    """
    RÃ©cupÃ¨re les statistiques de base de la base de donnÃ©es
    
    Returns:
        tuple: (total_torrents, total_details, coverage_percent)
    """
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    # Compte total des torrents
    cursor.execute("SELECT COUNT(*) FROM torrents")
    total_torrents = cursor.fetchone()[0]
    
    # Compte des dÃ©tails disponibles
    cursor.execute("SELECT COUNT(*) FROM torrent_details")
    total_details = cursor.fetchone()[0]
    
    conn.close()
    
    coverage = (total_details / total_torrents * 100) if total_torrents > 0 else 0
    return total_torrents, total_details, coverage

def clear_database():
    """
    Vide complÃ¨tement la base de donnÃ©es aprÃ¨s confirmation
    
    Supprime toutes les donnÃ©es des tables tout en conservant la structure.
    OpÃ©ration irrÃ©versible, demande confirmation explicite.
    """
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    cursor.execute("DELETE FROM torrent_details")
    cursor.execute("DELETE FROM torrents")
    
    # Reset des compteurs auto-increment seulement si la table existe
    cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='sqlite_sequence'")
    if cursor.fetchone():
        cursor.execute("DELETE FROM sqlite_sequence WHERE name IN ('torrents', 'torrent_details')")
    
    conn.commit()
    conn.close()
    
    logging.info("Base de donnÃ©es vidÃ©e avec succÃ¨s")
    print("âœ… Base de donnÃ©es complÃ¨tement vidÃ©e")

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘                           SECTION 4: API REAL-DEBRID                      â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def load_token():
    """
    RÃ©cupÃ¨re le token Real-Debrid depuis la configuration centralisÃ©e
    GÃ¨re tous les cas d'erreurs possibles pour Ã©viter Header Injection
    
    Source: Configuration centralisÃ©e (config.json) ou variables d'environnement
    
    Returns:
        str: Token Real-Debrid valide et nettoyÃ©
        
    Raises:
        SystemExit: Si aucun token valide trouvÃ©
    """
    import re
    
    def clean_token(raw_token):
        """Nettoie un token de tous les caractÃ¨res parasites"""
        if not raw_token:
            return None
            
        # Ã‰tape 1 : Conversion en string et suppression des espaces
        token = str(raw_token).strip()
        
        # Ã‰tape 2 : Suppression de tous les caractÃ¨res de contrÃ´le
        token = re.sub(r'[\r\n\t\f\v]', '', token)
        
        # Ã‰tape 3 : Suppression des espaces multiples
        token = re.sub(r'\s+', '', token)
        
        # Ã‰tape 4 : Validation format (seuls alphanumÃ©riques, tirets, underscores)
        if not re.match(r'^[A-Za-z0-9_-]+$', token):
            return None
            
        # Ã‰tape 5 : Validation longueur (tokens RD font gÃ©nÃ©ralement 40-60 caractÃ¨res)
        if len(token) < 30 or len(token) > 80:
            return None
            
        return token
    
    # PrioritÃ© 1: Variable d'environnement (Docker/SystÃ¨me)
    env_token = os.getenv('RD_TOKEN')
    if env_token:
        cleaned = clean_token(env_token)
        if cleaned:
            logging.info("ğŸ”‘ Token chargÃ© depuis variable d'environnement")
            return cleaned
        else:
            logging.warning("âš ï¸ Token d'environnement invalide")
    
    # PrioritÃ© 2: Configuration centralisÃ©e (config.json)
    config = get_config()
    config_token = config.get_token()
    if config_token:
        cleaned = clean_token(config_token)
        if cleaned:
            logging.info("ğŸ”‘ Token chargÃ© depuis configuration centralisÃ©e")
            return cleaned
        else:
            logging.warning("âš ï¸ Token de configuration invalide")
    
    # PrioritÃ© 3: Ancien fichier token pour compatibilitÃ©
    try:
        token_paths = [
            os.path.join(os.path.dirname(__file__), '../data/token'),
            os.path.join(os.path.dirname(__file__), '../config/token'),
            '/app/data/token'
        ]
        
        for token_path in token_paths:
            if os.path.exists(token_path):
                with open(token_path, 'r') as f:
                    file_token = f.read().strip()
                    cleaned = clean_token(file_token)
                    if cleaned:
                        logging.info(f"ğŸ”‘ Token chargÃ© depuis fichier: {token_path}")
                        # Migrer vers la configuration centralisÃ©e
                        config.update_config('realdebrid.token', cleaned)
                        logging.info("ğŸ”„ Token migrÃ© vers configuration centralisÃ©e")
                        return cleaned
                    else:
                        logging.warning(f"âš ï¸ Token du fichier {token_path} invalide")
                        
    except Exception as e:
        logging.warning(f"âš ï¸ Erreur lecture fichier token: {e}")
    
    # Aucun token valide trouvÃ©
    print("\nâŒ ERREUR: Aucun token Real-Debrid valide trouvÃ©")
    print("\nğŸ“‹ Solutions possibles:")
    print("   1. Variable d'environnement: export RD_TOKEN='votre_token'")
    print("   2. Configuration centralisÃ©e: modifier config/config.json")
    print("   3. Interface web: aller dans ParamÃ¨tres > Real-Debrid")
    print("\nğŸ”— Obtenir votre token: https://real-debrid.com/apitoken")
    
    sys.exit(1)

async def api_request(session, url, headers, params=None, max_retries=3):
    """
    Fonction gÃ©nÃ©rique pour les appels API Real-Debrid avec gestion d'erreurs complÃ¨te
    
    Features:
    - Retry automatique avec backoff exponentiel
    - Gestion des quotas API (429)
    - Gestion des erreurs d'authentification
    - Support interruption propre (CTRL+C)
    
    Args:
        session: Session aiohttp
        url (str): URL de l'API
        headers (dict): Headers incluant l'authentification
        params (dict, optional): ParamÃ¨tres de requÃªte
        max_retries (int): Nombre maximum de tentatives
        
    Returns:
        dict/None: RÃ©ponse JSON ou None en cas d'erreur
    """
    for attempt in range(max_retries):
        if stop_requested:
            return None
        try:
            async with session.get(url, headers=headers, params=params) as resp:
                # Gestion des erreurs d'authentification
                if resp.status == 401 or resp.status == 403:
                    logging.error("Token Real-Debrid invalide ou expirÃ©.")
                    sys.exit(1)
                
                # Torrent non trouvÃ© (normal dans certains cas)
                if resp.status == 404:
                    return None
                
                # Gestion du quota API
                if resp.status == 429:
                    wait_time = QUOTA_WAIT_TIME if params else TORRENT_QUOTA_WAIT
                    logging.warning(f"Quota API dÃ©passÃ©, attente {wait_time}s...")
                    await asyncio.sleep(wait_time)
                    continue
                
                resp.raise_for_status()
                return await resp.json()
                
        except Exception as e:
            if attempt == max_retries - 1:
                logging.error(f"Erreur API aprÃ¨s {max_retries} tentatives: {e}")
                return None
            # Backoff exponentiel
            await asyncio.sleep(2 ** attempt)
    return None

async def fetch_all_torrents(token):
    """
    RÃ©cupÃ¨re tous les torrents depuis l'API Real-Debrid avec temporisation adaptative
    
    Utilise la pagination pour rÃ©cupÃ©rer tous les torrents par batches de 2500.
    Sauvegarde directement en base pour Ã©viter la surcharge mÃ©moire.
    Temporisation adaptative selon les erreurs dÃ©tectÃ©es.
    
    Args:
        token (str): Token d'authentification Real-Debrid
        
    Returns:
        int: Nombre total de torrents rÃ©cupÃ©rÃ©s
    """
    headers = {"Authorization": f"Bearer {token}"}
    limit = 5000
    page = 1
    total = 0
    
    # Variables pour la temporisation adaptative
    page_wait = PAGE_WAIT_TIME  # Utilise la constante dÃ©finie
    consecutive_errors = 0
    
    async with aiohttp.ClientSession() as session:
        while True:
            if stop_requested:
                logging.info("ArrÃªt demandÃ©, interruption de la rÃ©cupÃ©ration des torrents.")
                break
                
            params = {"page": page, "limit": limit}
            
            try:
                # Appel API avec gestion d'erreurs
                torrents = await api_request(session, RD_API_URL, headers, params)
                
                if not torrents:
                    break
                
                # âœ… SuccÃ¨s - Reset du compteur d'erreurs
                consecutive_errors = 0
                
                # Sauvegarde immÃ©diate en base
                for t in torrents:
                    upsert_torrent(t)
                    
                total += len(torrents)
                logging.info(f"ğŸ“„ Page {page}: {len(torrents)} torrents ({total} total)")
                page += 1
                
                # ğŸ¯ TEMPORISATION ADAPTATIVE
                if len(torrents) == limit:  # S'il y a encore des pages
                    if consecutive_errors > 0:
                        # Pause plus longue si des erreurs ont Ã©tÃ© dÃ©tectÃ©es rÃ©cemment
                        adaptive_wait = page_wait * (1 + consecutive_errors * 0.5)
                        logging.info(f"â¸ï¸ Pause adaptative {adaptive_wait:.1f}s (aprÃ¨s {consecutive_errors} erreurs)")
                        await asyncio.sleep(adaptive_wait)
                        consecutive_errors = 0  # Reset aprÃ¨s pause adaptative
                    else:
                        # Pause normale
                        await asyncio.sleep(page_wait)
                        logging.info(f"â¸ï¸ Pause normale {page_wait}s")
                
            except Exception as e:
                # âŒ Erreur dÃ©tectÃ©e - IncrÃ©menter le compteur
                consecutive_errors += 1
                logging.warning(f"âš ï¸ Erreur page {page} (tentative {consecutive_errors}): {e}")
                
                # Pause immÃ©diate adaptative en cas d'erreur
                error_wait = page_wait * (1 + consecutive_errors * 0.5)
                logging.info(f"â¸ï¸ Pause d'erreur {error_wait:.1f}s...")
                await asyncio.sleep(error_wait)
                
                # Ne pas incrÃ©menter page - retry la mÃªme page
                continue
                
    return total

async def fetch_torrent_detail(session, token, torrent_id):
    """
    RÃ©cupÃ¨re les dÃ©tails complets d'un torrent spÃ©cifique
    
    Args:
        session: Session aiohttp
        token (str): Token d'authentification
        torrent_id (str): ID du torrent
        
    Returns:
        dict/None: DÃ©tails du torrent ou None si erreur
    """
    url = f"https://api.real-debrid.com/rest/1.0/torrents/info/{torrent_id}"
    headers = {"Authorization": f"Bearer {token}"}
    
    detail = await api_request(session, url, headers)
    if detail:
        logging.debug(f"DÃ©tail rÃ©cupÃ©rÃ© pour {torrent_id}")
        upsert_torrent_detail(detail)
    return detail

def upsert_torrent(t):
    """
    Insert ou met Ã  jour un torrent dans la table torrents
    
    Args:
        t (dict): DonnÃ©es du torrent depuis l'API
    """
    with sqlite3.connect(DB_PATH) as conn:
        c = conn.cursor()
        c.execute('''INSERT OR REPLACE INTO torrents (id, filename, status, bytes, added_on)
            VALUES (?, ?, ?, ?, ?)''',
            (t.get('id'), t.get('filename'), t.get('status'), t.get('bytes'), t.get('added'))
        )
        conn.commit()

def upsert_torrent_detail(detail):
    """
    Insert ou met Ã  jour les dÃ©tails d'un torrent dans la table torrent_details
    
    Args:
        detail (dict): DÃ©tails du torrent depuis l'API
    """
    if not detail or not detail.get('id'):
        return
        
    # Extraire les liens de tÃ©lÃ©chargement et de streaming
    download_links = []
    streaming_links = []
    
    # Parcourir les fichiers du torrent
    files = detail.get('files', [])
    for file_info in files:
        # Lien de tÃ©lÃ©chargement
        download_link = file_info.get('link', '')
        if download_link:
            download_links.append(download_link)
        
        # Lien de streaming - plusieurs champs possibles selon l'API Real-Debrid
        streaming_link = (
            file_info.get('streamable_link') or 
            file_info.get('streaming_link') or 
            file_info.get('stream_link') or
            file_info.get('alternative_link') or
            ''
        )
        streaming_links.append(streaming_link)
    
    # Si pas de fichiers, utiliser l'ancien format (liste de liens directe)
    if not files and detail.get('links'):
        download_links = detail.get('links', [])
        # Pour l'ancien format, on ne peut pas deviner les liens de streaming
        streaming_links = [''] * len(download_links)
        
    with sqlite3.connect(DB_PATH) as conn:
        c = conn.cursor()
        
        # RÃ©cupÃ©rer le health_error existant pour le prÃ©server
        c.execute('SELECT health_error FROM torrent_details WHERE id = ?', (detail.get('id'),))
        existing_health_error = c.fetchone()
        preserved_health_error = existing_health_error[0] if existing_health_error else None
        
        c.execute('''INSERT OR REPLACE INTO torrent_details
            (id, name, status, size, files_count, progress, links, streaming_links, hash, host, error, added, health_error)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)''',
            (
                detail.get('id'),
                detail.get('filename') or detail.get('name'),
                detail.get('status'),
                detail.get('bytes'),
                len(detail.get('files', [])),
                detail.get('progress'),
                ",".join(download_links) if download_links else None,
                ",".join(streaming_links) if streaming_links else None,
                detail.get('hash'),
                detail.get('host'),
                detail.get('error'),
                detail.get('added'),
                preserved_health_error  # PrÃ©server le health_error existant
            )
        )
        conn.commit()

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘                         SECTION 5: SYNCHRONISATION                        â•‘  
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class DynamicRateLimiter:
    """
    ContrÃ´leur dynamique de concurrence pour optimiser les performances API
    
    Ajuste automatiquement le nombre de requÃªtes simultanÃ©es selon:
    - Taux de succÃ¨s/Ã©chec
    - Performance gÃ©nÃ©rale
    - Respect des quotas API
    
    Attributes:
        concurrent (int): Nombre actuel de requÃªtes simultanÃ©es
        max_concurrent (int): Limite maximale
        success_count (int): Compteur de succÃ¨s
        error_count (int): Compteur d'erreurs
    """
    
    def __init__(self, initial_concurrent=20, max_concurrent=80):
        self.concurrent = initial_concurrent
        self.max_concurrent = max_concurrent
        self.success_count = 0
        self.error_count = 0
        self.last_adjustment = time.time()
        
    def adjust_concurrency(self, success=True):
        """
        Ajuste la concurrence selon les rÃ©sultats
        
        Args:
            success (bool): True si la derniÃ¨re requÃªte a rÃ©ussi
        """
        if success:
            self.success_count += 1
        else:
            self.error_count += 1
            
        # Ajustement pÃ©riodique ou aprÃ¨s un seuil
        if (self.success_count + self.error_count) % 50 == 0 or time.time() - self.last_adjustment > 30:
            error_rate = self.error_count / max(1, self.success_count + self.error_count)
            
            # Augmenter si peu d'erreurs
            if error_rate < 0.05:
                self.concurrent = min(self.max_concurrent, int(self.concurrent * 1.2))
                logging.info(f"ğŸ“ˆ Concurrence augmentÃ©e Ã  {self.concurrent}")
            # RÃ©duire si trop d'erreurs
            elif error_rate > 0.15:
                self.concurrent = max(5, int(self.concurrent * 0.7))
                logging.info(f"ğŸ“‰ Concurrence rÃ©duite Ã  {self.concurrent}")
                
            self.last_adjustment = time.time()
            self.success_count = self.error_count = 0
            
    def get_semaphore(self):
        """Retourne un semaphore avec la concurrence actuelle"""
        return asyncio.Semaphore(self.concurrent)

def save_progress(processed_ids, filename="data/sync_progress.json"):
    """
    Sauvegarde la progression d'une synchronisation pour reprise ultÃ©rieure
    
    Args:
        processed_ids (set): IDs des torrents dÃ©jÃ  traitÃ©s
        filename (str): Chemin du fichier de sauvegarde
    """
    os.makedirs(os.path.dirname(filename), exist_ok=True)
    with open(filename, 'w') as f:
        json.dump({
            'processed_ids': list(processed_ids),
            'timestamp': time.time()
        }, f)

def load_progress(filename="data/sync_progress.json"):
    """
    Charge la progression d'une synchronisation prÃ©cÃ©dente
    
    Args:
        filename (str): Chemin du fichier de sauvegarde
        
    Returns:
        set: IDs des torrents dÃ©jÃ  traitÃ©s (max 6h d'anciennetÃ©)
    """
    try:
        with open(filename, 'r') as f:
            data = json.load(f)
            # Ignorer si plus de 6 heures
            if time.time() - data['timestamp'] < 21600:
                return set(data['processed_ids'])
    except:
        pass
    return set()

async def fetch_all_torrent_details_v2(token, torrent_ids, resumable=False):
    """
    Version optimisÃ©e pour rÃ©cupÃ©rer les dÃ©tails de torrents (sync-fast et sync-smart)
    
    Features:
    - ContrÃ´le dynamique de la concurrence
    - Reprise possible des synchronisations interrompues
    - Pool de connexions optimisÃ©
    - Statistiques temps rÃ©el
    - Sauvegarde progressive
    
    Args:
        token (str): Token Real-Debrid
        torrent_ids (list): Liste des IDs Ã  traiter
        resumable (bool): Si True, permet la reprise
        
    Returns:
        int: Nombre de dÃ©tails traitÃ©s avec succÃ¨s
    """
    # Gestion de la reprise
    if resumable:
        processed_ids = load_progress()
        remaining_ids = [tid for tid in torrent_ids if tid not in processed_ids]
        if processed_ids:
            logging.info(f"ğŸ“‚ Reprise: {len(processed_ids)} dÃ©jÃ  traitÃ©s, {len(remaining_ids)} restants")
    else:
        remaining_ids = torrent_ids
        processed_ids = set()
    
    if not remaining_ids:
        logging.info("âœ… Tous les dÃ©tails sont Ã  jour !")
        return len(processed_ids)
    
    rate_limiter = DynamicRateLimiter()
    total_processed = len(processed_ids)
    start_time = time.time()
    
    # Pool de connexions optimisÃ©
    connector = aiohttp.TCPConnector(limit=100, limit_per_host=50, keepalive_timeout=30)
    timeout = aiohttp.ClientTimeout(total=15, connect=5)
    
    async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:
        
        async def process_torrent_optimized(tid):
            """Traite un torrent avec contrÃ´le de concurrence dynamique"""
            semaphore = rate_limiter.get_semaphore()
            async with semaphore:
                result = await fetch_torrent_detail(session, token, tid)
                success = result is not None
                rate_limiter.adjust_concurrency(success)
                
                if success:
                    nonlocal total_processed
                    total_processed += 1
                    processed_ids.add(tid)
                    
                    # Stats temps rÃ©el + sauvegarde pÃ©riodique
                    if total_processed % 100 == 0:
                        elapsed = time.time() - start_time
                        rate = (total_processed - len(processed_ids)) / elapsed if elapsed > 0 else 0
                        remaining = len(torrent_ids) - total_processed
                        eta = remaining / rate if rate > 0 else 0
                        
                        logging.info(f"ğŸ“Š {total_processed}/{len(torrent_ids)} | "
                                   f"{rate:.1f}/s | ETA: {eta/60:.1f}min | "
                                   f"Concurrence: {rate_limiter.concurrent}")
                        
                        if resumable:
                            save_progress(processed_ids)
                
                return result
        
        # Traitement par chunks adaptatifs
        chunk_size = min(300, len(remaining_ids))
        for i in range(0, len(remaining_ids), chunk_size):
            if stop_requested:
                break
                
            chunk_ids = remaining_ids[i:i+chunk_size]
            tasks = [process_torrent_optimized(tid) for tid in chunk_ids]
            
            await asyncio.gather(*tasks, return_exceptions=True)
            
            # Pause adaptative entre chunks
            if i + chunk_size < len(remaining_ids):
                pause = max(3, 20 - rate_limiter.concurrent * 0.2)
                logging.info(f"â¸ï¸  Pause {pause:.1f}s...")
                await asyncio.sleep(pause)
    
    elapsed = time.time() - start_time
    processed_new = total_processed - len(set(processed_ids) - processed_ids)
    logging.info(f"ğŸ‰ TerminÃ© ! {processed_new} nouveaux dÃ©tails en {elapsed/60:.1f}min "
                 f"({processed_new/elapsed:.1f} torrents/s)")
    
    # Nettoyer le fichier de progression si terminÃ©
    if resumable and os.path.exists("data/sync_progress.json"):
        os.remove("data/sync_progress.json")
    
    return total_processed

def get_smart_update_summary():
    """
    Analyse intelligente des torrents nÃ©cessitant une mise Ã  jour
    
    CatÃ©gories analysÃ©es:
    - Nouveaux torrents sans dÃ©tails
    - TÃ©lÃ©chargements actifs
    - Torrents en erreur (retry)
    - Torrents anciens (>7 jours)
    
    Returns:
        dict: RÃ©sumÃ© des changements dÃ©tectÃ©s
    """
    with sqlite3.connect(DB_PATH) as conn:
        c = conn.cursor()
        
        # Nouveaux torrents (pas de dÃ©tails)
        c.execute('''
            SELECT COUNT(*) FROM torrents t
            LEFT JOIN torrent_details td ON t.id = td.id
            WHERE td.id IS NULL
        ''')
        new_count = c.fetchone()[0]
        
        # TÃ©lÃ©chargements actifs (utilisation des constantes)
        placeholders = ','.join('?' * len(ACTIVE_STATUSES))
        c.execute(f'''
            SELECT COUNT(*) FROM torrent_details
            WHERE status IN ({placeholders})
        ''', ACTIVE_STATUSES)
        active_count = c.fetchone()[0]
        
        # Torrents en erreur (pour retry) - utilisation des constantes d'erreur
        placeholders = ','.join('?' * len(ERROR_STATUSES))
        c.execute(f'''
            SELECT COUNT(*) FROM torrent_details
            WHERE status IN ({placeholders}) OR error IS NOT NULL
        ''', ERROR_STATUSES)
        error_count = c.fetchone()[0]
        
        # Torrents anciens (plus de 7 jours sans mise Ã  jour)
        c.execute('''
            SELECT COUNT(*) FROM torrents t
            LEFT JOIN torrent_details td ON t.id = td.id
            WHERE datetime('now') - datetime(t.added_on) > 7
        ''')
        old_count = c.fetchone()[0]
        
        return {
            'new_torrents': new_count,
            'active_downloads': active_count,
            'error_retry': error_count,
            'old_updates': old_count
        }

def get_torrents_needing_update():
    """
    Identifie les torrents nÃ©cessitant une mise Ã  jour pour sync-smart
    
    CritÃ¨res:
    - Nouveaux torrents sans dÃ©tails
    - TÃ©lÃ©chargements actifs (downloading, queued, etc.)
    - Torrents en erreur (retry automatique)
    - Torrents anciens (>7 jours)
    
    Returns:
        list: Liste des IDs de torrents Ã  mettre Ã  jour
    """
    with sqlite3.connect(DB_PATH) as conn:
        c = conn.cursor()
        c.execute('''
            SELECT t.id FROM torrents t
            LEFT JOIN torrent_details td ON t.id = td.id
            WHERE td.id IS NULL 
               OR (td.status IN ('downloading', 'queued', 'waiting_files_selection'))
               OR (td.status = 'error' OR td.error IS NOT NULL)
               OR datetime('now') - datetime(t.added_on) > 7
        ''')
        return [row[0] for row in c.fetchall()]

def sync_smart(token):
    """
    Synchronisation intelligente optimisÃ©e - Mode recommandÃ© pour usage quotidien
    
    Logique en 3 phases optimisÃ©es :
    1. ğŸš€ PHASE 1 : Mise Ã  jour ultra-rapide des statuts via torrents_only (10-30s)
    2. ğŸ¯ PHASE 2 : Analyse intelligente des changements dÃ©tectÃ©s
    3. ğŸ” PHASE 3 : RÃ©cupÃ©ration ciblÃ©e des dÃ©tails par IDs (seulement les modifiÃ©s)
    
    FonctionnalitÃ©s:
    - âœ… Statuts Ã  jour en 30s maximum (phase 1)
    - âœ… DÃ©tection prÃ©cise des changements (phase 2)
    - âœ… RÃ©cupÃ©ration ciblÃ©e par IDs (phase 3)
    - âœ… Performance optimisÃ©e (15-50 torrents/s)
    - âœ… RÃ©sumÃ© post-sync avec recommandations
    
    Usage: python src/main.py --sync-smart
    Temps typique: 30s - 2 minutes
    """
    start_overall = time.time()
    logging.info("ğŸ§  Synchronisation intelligente optimisÃ©e dÃ©marrÃ©e...")
    log_event('SYNC_START', mode='smart')
    
    # ==========================================
    # ğŸš€ PHASE 1 : Mise Ã  jour rapide des statuts
    # ==========================================
    logging.info("ğŸš€ [PHASE 1] Mise Ã  jour ultra-rapide des statuts...")
    log_event('SYNC_PHASE_START', mode='smart', phase=1, name='status_refresh')
    
    # Sauvegarder les anciens statuts pour comparaison
    old_statuses = {}
    with sqlite3.connect(DB_PATH) as conn:
        c = conn.cursor()
        c.execute("SELECT id, status FROM torrents")
        old_statuses = dict(c.fetchall())
    
    # Utiliser torrents_only() pour mise Ã  jour rapide des statuts
    total_torrents = asyncio.run(fetch_all_torrents(token))
    
    if total_torrents > 0:
        logging.info(f"âœ… Statuts mis Ã  jour : {total_torrents} torrents (phase 1 terminÃ©e)")
        log_event('SYNC_PHASE_END', mode='smart', phase=1, torrents=total_torrents, status='success')
    else:
        logging.info("âŒ Aucun torrent rÃ©cupÃ©rÃ©, arrÃªt de la synchronisation")
        log_event('SYNC_ABORT', mode='smart', reason='no_torrents')
        return
    
    # ==========================================
    # ğŸ¯ PHASE 2 : Analyse des changements
    # ==========================================
    logging.info("ğŸ¯ [PHASE 2] Analyse intelligente des changements...")
    log_event('SYNC_PHASE_START', mode='smart', phase=2, name='change_analysis')
    
    # RÃ©cupÃ©rer les nouveaux statuts aprÃ¨s torrents_only()
    new_statuses = {}
    torrents_needing_details = set()
    
    with sqlite3.connect(DB_PATH) as conn:
        c = conn.cursor()
        
        # RÃ©cupÃ©rer les nouveaux statuts
        c.execute("SELECT id, status FROM torrents")
        new_statuses = dict(c.fetchall())
        
        # 1. Nouveaux torrents (pas dans torrent_details)
        c.execute("""
            SELECT t.id FROM torrents t 
            LEFT JOIN torrent_details td ON t.id = td.id 
            WHERE td.id IS NULL
        """)
        new_torrents = [row[0] for row in c.fetchall()]
        
        # 2. Torrents avec changement de statut
        status_changed = []
        for torrent_id, new_status in new_statuses.items():
            old_status = old_statuses.get(torrent_id)
            if old_status != new_status:
                status_changed.append(torrent_id)
        
        # 3. TÃ©lÃ©chargements actifs (toujours Ã  jour)
        c.execute("""
            SELECT id FROM torrents 
            WHERE status IN ('downloading', 'queued', 'magnet_conversion')
        """)
        active_downloads = [row[0] for row in c.fetchall()]
        
        # 4. Torrents en erreur (retry)
        c.execute("""
            SELECT id FROM torrent_details 
            WHERE status = 'error'
        """)
        error_torrents = [row[0] for row in c.fetchall()]
        
        # Fusionner toutes les listes (Ã©viter doublons)
        torrents_needing_details.update(new_torrents)
        torrents_needing_details.update(status_changed)
        torrents_needing_details.update(active_downloads)
        torrents_needing_details.update(error_torrents)
    
    # Affichage du rÃ©sumÃ© des changements dÃ©tectÃ©s
    logging.info("ğŸ“Š Changements dÃ©tectÃ©s :")
    log_event('SYNC_ANALYSIS', new=len(new_torrents), status_changed=len(status_changed), active=len(active_downloads), errors=len(error_torrents))
    logging.info(f"   ğŸ†• Nouveaux torrents sans dÃ©tails : {len(new_torrents)}")
    logging.info(f"   ğŸ”„ Changements de statut : {len(status_changed)}")
    logging.info(f"   â¬‡ï¸  TÃ©lÃ©chargements actifs : {len(active_downloads)}")
    logging.info(f"   âŒ Torrents en erreur (retry) : {len(error_torrents)}")
    
    torrent_ids_list = list(torrents_needing_details)
    
    if not torrent_ids_list:
        logging.info("âœ… Aucun changement dÃ©tectÃ©, tous les dÃ©tails sont Ã  jour !")
        log_event('SYNC_PHASE_END', mode='smart', phase=2, status='no_changes')
        log_event('SYNC_END', mode='smart', status='success', changes=0, duration=f"{time.time()-start_overall:.2f}s")
        return
    
    total_changes = len(torrent_ids_list)
    logging.info(f"ğŸ¯ Total : {total_changes} torrents nÃ©cessitent une mise Ã  jour des dÃ©tails")
    
    # ==========================================
    # ğŸ” PHASE 3 : RÃ©cupÃ©ration ciblÃ©e des dÃ©tails par IDs
    # ==========================================
    logging.info("ğŸ” [PHASE 3] RÃ©cupÃ©ration ciblÃ©e des dÃ©tails par IDs...")
    log_event('SYNC_PHASE_START', mode='smart', phase=3, name='details_fetch', targets=len(torrent_ids_list))
    
    # Traiter les mises Ã  jour avec mesure du temps
    start_time = time.time()
    processed = asyncio.run(fetch_all_torrent_details_v2(token, torrent_ids_list))
    end_time = time.time()
    
    # Statistiques finales
    duration = end_time - start_time
    rate = processed / duration if duration > 0 else 0
    
    logging.info(f"âœ… Synchronisation intelligente terminÃ©e !")
    logging.info(f"   ğŸ“Š Phase 1 : {total_torrents} statuts mis Ã  jour")
    logging.info(f"   ğŸ“Š Phase 3 : {processed} dÃ©tails mis Ã  jour en {duration:.1f}s ({rate:.1f}/s)")
    log_event('SYNC_PHASE_END', mode='smart', phase=3, processed=processed, duration=f"{duration:.2f}s", rate=f"{rate:.2f}/s")
    
    # Ã‰tape 4: Nettoyage des torrents obsolÃ¨tes
    logging.info("ğŸ§¹ [PHASE 4] Nettoyage des torrents obsolÃ¨tes...")
    log_event('SYNC_PHASE_START', mode='smart', phase=4, name='cleanup')
    cleaned_count = clean_obsolete_torrents(token)
    if cleaned_count > 0:
        logging.info(f"ğŸ—‘ï¸ SupprimÃ© {cleaned_count} torrents obsolÃ¨tes de la base locale")
        print(f"ğŸ§¹ Nettoyage terminÃ©: {cleaned_count} torrents obsolÃ¨tes supprimÃ©s")
    else:
        logging.info("âœ… Aucun torrent obsolÃ¨te trouvÃ©")
    log_event('SYNC_PHASE_END', mode='smart', phase=4, cleaned=cleaned_count, status='success')

    total_duration = time.time() - start_overall
    log_event('SYNC_END', mode='smart', status='success', torrents=total_torrents, details=processed, cleaned=cleaned_count, duration=f"{total_duration:.2f}s", rate=f"{processed/ (duration if duration>0 else 1):.2f}/s")
    
    # Afficher un rÃ©sumÃ© final
    display_final_summary()

def sync_resume(token):
    """
    Reprendre une synchronisation interrompue Ã  partir du point d'arrÃªt
    
    Utilise les fichiers de progression sauvegardÃ©s pour reprendre
    exactement lÃ  oÃ¹ la synchronisation s'Ã©tait arrÃªtÃ©e.
    
    Usage: python src/main.py --resume
    """
    start_time = time.time()
    logging.info("â®ï¸  Reprise de synchronisation...")
    log_event('SYNC_START', mode='resume')
    
    with sqlite3.connect(DB_PATH) as conn:
        c = conn.cursor()
        c.execute("SELECT id FROM torrents")
        all_ids = [row[0] for row in c.fetchall()]
    
    processed = asyncio.run(fetch_all_torrent_details_v2(token, all_ids, resumable=True))
    logging.info(f"âœ… Reprise terminÃ©e ! {processed} dÃ©tails traitÃ©s")
    log_event('SYNC_PART', mode='resume', details_processed=processed)
    
    # Nettoyage des torrents obsolÃ¨tes
    logging.info("ğŸ§¹ Nettoyage des torrents obsolÃ¨tes...")
    cleaned_count = clean_obsolete_torrents(token)
    if cleaned_count > 0:
        logging.info(f"ğŸ—‘ï¸ SupprimÃ© {cleaned_count} torrents obsolÃ¨tes de la base locale")
        print(f"ğŸ§¹ Nettoyage terminÃ©: {cleaned_count} torrents obsolÃ¨tes supprimÃ©s")
    else:
        logging.info("âœ… Aucun torrent obsolÃ¨te trouvÃ©")
    duration = time.time() - start_time
    log_event('SYNC_END', mode='resume', status='success', details=processed, cleaned=cleaned_count, duration=f"{duration:.2f}s")

def sync_details_only(token, status_filter=None):
    """
    Synchronise uniquement les dÃ©tails des torrents existants en base
    
    Args:
        token (str): Token Real-Debrid
        status_filter (str, optional): Filtre par statut (error, downloading, etc.)
        
    Usage:
        - python src/main.py --details-only
        - python src/main.py --details-only --status error
    """
    with sqlite3.connect(DB_PATH) as conn:
        c = conn.cursor()
        query = "SELECT id FROM torrents"
        params = ()
        if status_filter:
            query += " WHERE status = ?"
            params = (status_filter,)
        c.execute(query, params)
        torrent_ids = [row[0] for row in c.fetchall()]
    
    if not torrent_ids:
        logging.info("Aucun torrent trouvÃ© pour synchronisation des dÃ©tails.")
        log_event('SYNC_ABORT', mode='details_only', reason='no_torrents')
        return
        
    start_time = time.time()
    logging.info(f"ğŸ”„ Synchronisation des dÃ©tails pour {len(torrent_ids)} torrents...")
    log_event('SYNC_START', mode='details_only', targets=len(torrent_ids), status_filter=status_filter or 'all')
    processed = asyncio.run(fetch_all_torrent_details(token, torrent_ids))
    logging.info(f"âœ… DÃ©tails synchronisÃ©s pour {processed} torrents.")
    log_event('SYNC_PART', mode='details_only', processed=processed)
    
    # Nettoyage des torrents obsolÃ¨tes
    logging.info("ğŸ§¹ Nettoyage des torrents obsolÃ¨tes...")
    cleaned_count = clean_obsolete_torrents(token)
    if cleaned_count > 0:
        logging.info(f"ğŸ—‘ï¸ SupprimÃ© {cleaned_count} torrents obsolÃ¨tes de la base locale")
        print(f"ğŸ§¹ Nettoyage terminÃ©: {cleaned_count} torrents obsolÃ¨tes supprimÃ©s")
    else:
        logging.info("âœ… Aucun torrent obsolÃ¨te trouvÃ©")
    duration = time.time() - start_time
    log_event('SYNC_END', mode='details_only', status='success', processed=processed, cleaned=cleaned_count, duration=f"{duration:.2f}s")

def sync_torrents_only(token):
    """
    Synchronisation ultra-rapide des torrents de base uniquement (sans dÃ©tails)
    
    Parfait pour:
    - Vue d'ensemble rapide de la collection
    - PremiÃ¨re dÃ©couverte avant sync complet
    - Monitoring des nouveaux ajouts
    
    Usage: python src/main.py --torrents-only
    Temps typique: 10-30 secondes
    """
    start_time = time.time()
    logging.info("ğŸ“‹ Synchronisation des torrents de base uniquement...")
    log_event('SYNC_START', mode='torrents_only')
    
    total = asyncio.run(fetch_all_torrents(token))
    
    if total > 0:
        logging.info(f"âœ… Synchronisation terminÃ©e ! {total} torrents enregistrÃ©s dans la table 'torrents'")
        log_event('SYNC_PART', mode='torrents_only', torrents=total)
        
        # Nettoyage des torrents obsolÃ¨tes
        logging.info("ğŸ§¹ Nettoyage des torrents obsolÃ¨tes...")
        cleaned_count = clean_obsolete_torrents(token)
        if cleaned_count > 0:
            logging.info(f"ğŸ—‘ï¸ SupprimÃ© {cleaned_count} torrents obsolÃ¨tes de la base locale")
            print(f"ğŸ§¹ Nettoyage terminÃ©: {cleaned_count} torrents obsolÃ¨tes supprimÃ©s")
        else:
            logging.info("âœ… Aucun torrent obsolÃ¨te trouvÃ©")
        duration = time.time() - start_time
        log_event('SYNC_END', mode='torrents_only', status='success', torrents=total, cleaned=cleaned_count, duration=f"{duration:.2f}s")
        
        # Afficher un petit rÃ©sumÃ©
        with sqlite3.connect(DB_PATH) as conn:
            c = conn.cursor()
            c.execute("SELECT status, COUNT(*) FROM torrents GROUP BY status")
            status_counts = dict(c.fetchall())
            
            print(f"\nğŸ“Š RÃ©sumÃ© des torrents synchronisÃ©s:")
            for status, count in status_counts.items():
                emoji = get_status_emoji(status)
                print(f"   {emoji} {status}: {count}")
    else:
        logging.info("â„¹ï¸  Aucun torrent trouvÃ© ou synchronisÃ©")
        log_event('SYNC_ABORT', mode='torrents_only', reason='no_torrents')

def clean_obsolete_torrents(token):
    """
    Nettoie les torrents qui existent localement mais qui ne sont plus prÃ©sents cÃ´tÃ© Real-Debrid
    
    Cette fonction rÃ©cupÃ¨re la liste actuelle des torrents depuis Real-Debrid et supprime
    de la base locale tous les torrents qui n'y figurent plus.
    
    Args:
        token (str): Token d'authentification Real-Debrid
        
    Returns:
        int: Nombre de torrents supprimÃ©s
    """
    logging.info("ğŸ” RÃ©cupÃ©ration de la liste actuelle des torrents Real-Debrid...")
    
    # RÃ©cupÃ©rer tous les IDs de torrents actuels cÃ´tÃ© Real-Debrid
    current_rd_ids = set()
    headers = {"Authorization": f"Bearer {token}"}
    limit = 5000
    
    try:
        import aiohttp
        import asyncio
        
        async def get_current_torrent_ids():
            page = 1
            async with aiohttp.ClientSession() as session:
                while True:
                    params = {"page": page, "limit": limit}
                    try:
                        torrents = await api_request(session, RD_API_URL, headers, params)
                        if not torrents:
                            break
                        
                        for t in torrents:
                            current_rd_ids.add(t['id'])
                        
                        if len(torrents) < limit:
                            break
                            
                        page += 1
                        await asyncio.sleep(1)  # Pause entre pages
                        
                    except Exception as e:
                        logging.error(f"Erreur lors de la rÃ©cupÃ©ration des IDs Real-Debrid: {e}")
                        break
        
        # ExÃ©cuter la rÃ©cupÃ©ration
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        loop.run_until_complete(get_current_torrent_ids())
        loop.close()
        
        if not current_rd_ids:
            logging.warning("âš ï¸ Aucun torrent trouvÃ© cÃ´tÃ© Real-Debrid, nettoyage annulÃ© par sÃ©curitÃ©")
            return 0
        
        logging.info(f"âœ… {len(current_rd_ids)} torrents trouvÃ©s cÃ´tÃ© Real-Debrid")
        
        # RÃ©cupÃ©rer tous les IDs locaux
        with sqlite3.connect(DB_PATH) as conn:
            c = conn.cursor()
            c.execute("SELECT id FROM torrents")
            local_ids = {row[0] for row in c.fetchall()}
        
        # Identifier les torrents obsolÃ¨tes (prÃ©sents localement mais pas cÃ´tÃ© Real-Debrid)
        obsolete_ids = local_ids - current_rd_ids
        
        if not obsolete_ids:
            logging.info("âœ… Aucun torrent obsolÃ¨te trouvÃ©")
            return 0
        
        logging.info(f"ğŸ—‘ï¸ {len(obsolete_ids)} torrents obsolÃ¨tes dÃ©tectÃ©s")
        
        # Supprimer les torrents obsolÃ¨tes des deux tables
        with sqlite3.connect(DB_PATH) as conn:
            c = conn.cursor()
            
            # Supprimer de torrents
            placeholders = ','.join('?' * len(obsolete_ids))
            c.execute(f"DELETE FROM torrents WHERE id IN ({placeholders})", list(obsolete_ids))
            torrents_deleted = c.rowcount
            
            # Supprimer de torrent_details
            c.execute(f"DELETE FROM torrent_details WHERE id IN ({placeholders})", list(obsolete_ids))
            details_deleted = c.rowcount
            
            conn.commit()
        
        logging.info(f"ğŸ—‘ï¸ SupprimÃ© {torrents_deleted} entrÃ©es de 'torrents' et {details_deleted} entrÃ©es de 'torrent_details'")
        return len(obsolete_ids)
        
    except Exception as e:
        logging.error(f"âŒ Erreur lors du nettoyage des torrents obsolÃ¨tes: {e}")
        return 0

def sync_all_v2(token):
    """
    Synchronisation complÃ¨te optimisÃ©e (SYNC RAPIDE)
    
    Effectue une synchronisation complÃ¨te des torrents et dÃ©tails avec optimisations:
    - RÃ©cupÃ©ration de tous les torrents de base
    - RÃ©cupÃ©ration de tous les dÃ©tails manquants
    - OptimisÃ© pour premiÃ¨re utilisation ou sync complet
    
    Usage: python src/main.py --sync-fast
    Temps typique: 7-10 minutes
    """
    start_time = time.time()
    logging.info("ğŸš€ Synchronisation complÃ¨te optimisÃ©e en cours...")
    log_event('SYNC_START', mode='fast')
    
    # Ã‰tape 1: Synchroniser tous les torrents de base
    logging.info("ğŸ“¥ Ã‰tape 1/2: RÃ©cupÃ©ration des torrents de base...")
    total_torrents = asyncio.run(fetch_all_torrents(token))
    
    if total_torrents == 0:
        logging.warning("âš ï¸ Aucun torrent trouvÃ©")
        print("âš ï¸ Aucun torrent trouvÃ© dans votre compte Real-Debrid")
        log_event('SYNC_ABORT', mode='fast', reason='no_torrents')
        return
    
    logging.info(f"âœ… {total_torrents} torrents de base rÃ©cupÃ©rÃ©s")
    
    # Ã‰tape 2: RÃ©cupÃ©rer tous les dÃ©tails manquants
    logging.info("ğŸ“‹ Ã‰tape 2/2: RÃ©cupÃ©ration des dÃ©tails...")
    
    with sqlite3.connect(DB_PATH) as conn:
        c = conn.cursor()
        c.execute("SELECT id FROM torrents WHERE id NOT IN (SELECT id FROM torrent_details)")
        missing_ids = [row[0] for row in c.fetchall()]
    
    if missing_ids:
        logging.info(f"ğŸ”„ RÃ©cupÃ©ration des dÃ©tails pour {len(missing_ids)} torrents...")
        log_event('SYNC_PART', mode='fast', missing_details=len(missing_ids))
        processed = asyncio.run(fetch_all_torrent_details_v2(token, missing_ids))
        logging.info(f"âœ… DÃ©tails rÃ©cupÃ©rÃ©s pour {processed} torrents")
        print(f"ğŸš€ Synchronisation complÃ¨te terminÃ©e: {total_torrents} torrents, {processed} dÃ©tails")
        log_event('SYNC_PART', mode='fast', details_processed=processed)
    else:
        logging.info("âœ… Tous les dÃ©tails sont dÃ©jÃ  Ã  jour")
        print(f"ğŸš€ Synchronisation complÃ¨te terminÃ©e: {total_torrents} torrents, tous les dÃ©tails Ã  jour")
        log_event('SYNC_PART', mode='fast', missing_details=0)
    
    # Ã‰tape 3: Nettoyage des torrents obsolÃ¨tes
    logging.info("ğŸ§¹ Ã‰tape 3/3: Nettoyage des torrents obsolÃ¨tes...")
    cleaned_count = clean_obsolete_torrents(token)
    if cleaned_count > 0:
        logging.info(f"ğŸ—‘ï¸ SupprimÃ© {cleaned_count} torrents obsolÃ¨tes de la base locale")
        print(f"ğŸ§¹ Nettoyage terminÃ©: {cleaned_count} torrents obsolÃ¨tes supprimÃ©s")
    else:
        logging.info("âœ… Aucun torrent obsolÃ¨te trouvÃ©")
    duration = time.time() - start_time
    log_event('SYNC_END', mode='fast', status='success', torrents=total_torrents, cleaned=cleaned_count, duration=f"{duration:.2f}s")
    
    display_final_summary()

async def fetch_all_torrent_details(token, torrent_ids, max_concurrent=MAX_CONCURRENT):
    """
    Version classique de rÃ©cupÃ©ration des dÃ©tails (pour compatibilitÃ©)
    
    Args:
        token (str): Token Real-Debrid
        torrent_ids (list): IDs des torrents Ã  traiter
        max_concurrent (int): Nombre de requÃªtes simultanÃ©es
        
    Returns:
        int: Nombre de dÃ©tails traitÃ©s
    """
    semaphore = asyncio.Semaphore(max_concurrent)
    total_processed = 0
    
    async with aiohttp.ClientSession() as session:
        async def process_torrent(tid):
            async with semaphore:
                return await fetch_torrent_detail(session, token, tid)
        
        # Traitement par batch pour respecter les quotas
        for i in range(0, len(torrent_ids), BATCH_SIZE):
            if stop_requested:
                logging.info("ArrÃªt demandÃ©, interruption de la rÃ©cupÃ©ration des dÃ©tails.")
                break
                
            batch_ids = torrent_ids[i:i+BATCH_SIZE]
            tasks = [process_torrent(tid) for tid in batch_ids]
            batch_results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # Compter les succÃ¨s
            successful = sum(1 for r in batch_results if r and not isinstance(r, Exception))
            total_processed += successful
            
            logging.info(f"Batch {i//BATCH_SIZE + 1}: {successful}/{len(batch_ids)} dÃ©tails rÃ©cupÃ©rÃ©s")
            
            # Pause entre les batches sauf pour le dernier
            if i + BATCH_SIZE < len(torrent_ids):
                logging.info(f"Pause {QUOTA_WAIT_TIME}s avant le prochain batch...")
                await asyncio.sleep(QUOTA_WAIT_TIME)
    
    return total_processed

def display_final_summary():
    """
    Affiche un rÃ©sumÃ© final aprÃ¨s synchronisation avec recommandations
    
    Informations affichÃ©es:
    - Statistiques gÃ©nÃ©rales
    - RÃ©partition par statut
    - ActivitÃ© rÃ©cente
    - Recommandations d'actions
    """
    try:
        with sqlite3.connect(DB_PATH) as conn:
            c = conn.cursor()
            
            # Statistiques gÃ©nÃ©rales
            c.execute("SELECT COUNT(*) FROM torrents")
            total_torrents = c.fetchone()[0]
            
            c.execute("SELECT COUNT(*) FROM torrent_details")
            total_details = c.fetchone()[0]
            
            # RÃ©partition par statut (top 5) - CORRIGER: utiliser seulement torrent_details
            c.execute("""
                SELECT td.status, COUNT(*) as count
                FROM torrent_details td
                WHERE td.status IS NOT NULL
                GROUP BY td.status
                ORDER BY count DESC
                LIMIT 5
            """)
            status_counts = c.fetchall()
            
            # Torrents rÃ©cents (derniÃ¨res 24h)
            c.execute("""
                SELECT COUNT(*) FROM torrents 
                WHERE datetime('now') - datetime(added_on) < 1
            """)
            recent_count = c.fetchone()[0]
            
            print(f"\nğŸ“Š RÃ©sumÃ© de la base de donnÃ©es :")
            print(f"   ğŸ“‚ Total torrents : {total_torrents}")
            print(f"   ğŸ“ Avec dÃ©tails : {total_details} ({100*total_details/total_torrents:.1f}%)")
            print(f"   ğŸ†• AjoutÃ©s rÃ©cemment (24h) : {recent_count}")
            
            if status_counts:
                print(f"\nğŸ“ˆ Top 5 des statuts :")
                for status, count in status_counts:
                    percentage = 100 * count / total_torrents if total_torrents > 0 else 0
                    emoji = get_status_emoji(status)
                    print(f"   {emoji} {status} : {count} ({percentage:.1f}%)")
                    
    except Exception as e:
        logging.warning(f"Impossible d'afficher le rÃ©sumÃ© : {e}")

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘                      SECTION 6: STATISTIQUES ET ANALYTICS                 â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def show_stats():
    """
    Affiche des statistiques complÃ¨tes et dÃ©taillÃ©es de votre collection
    
    Sections d'analyse:
    - ğŸ—‚ï¸ Vue d'ensemble gÃ©nÃ©rale
    - ğŸ’¾ Volumes de donnÃ©es  
    - â° ActivitÃ© rÃ©cente
    - ğŸ”„ Ã‰tat des tÃ©lÃ©chargements
    - ğŸ“ˆ RÃ©partition par statut
    - ğŸŒ Top hÃ©bergeurs
    - ğŸ† Plus gros torrents
    - ğŸ’¡ Recommandations automatiques
    
    Usage: python src/main.py --stats
    """
    with sqlite3.connect(DB_PATH) as conn:
        c = conn.cursor()
        
        # === STATISTIQUES GÃ‰NÃ‰RALES ===
        c.execute("SELECT COUNT(*) FROM torrents")
        total_torrents = c.fetchone()[0]
        
        c.execute("SELECT COUNT(*) FROM torrent_details")
        total_details = c.fetchone()[0]
        
        coverage_percent = (total_details / total_torrents * 100) if total_torrents > 0 else 0
        
        # === RÃ‰PARTITION PAR STATUT ===
        c.execute("SELECT status, COUNT(*) FROM torrent_details WHERE status IS NOT NULL GROUP BY status ORDER BY COUNT(*) DESC")
        torrent_status = c.fetchall()
        
        c.execute("SELECT status, COUNT(*) FROM torrent_details GROUP BY status ORDER BY COUNT(*) DESC")
        detail_status = c.fetchall()
        
        # === TAILLES ET VOLUMES ===
        c.execute("SELECT SUM(bytes), MIN(bytes), MAX(bytes) FROM torrents WHERE bytes > 0")
        size_stats = c.fetchone()
        total_size, min_size, max_size = size_stats if size_stats and size_stats[0] else (0, 0, 0)
        
        # === ACTIVITÃ‰ RÃ‰CENTE ===
        c.execute("""
            SELECT COUNT(*) FROM torrents 
            WHERE datetime(added_on) >= datetime('now', '-24 hours')
        """)
        recent_24h = c.fetchone()[0] or 0
        
        c.execute("""
            SELECT COUNT(*) FROM torrents 
            WHERE datetime(added_on) >= datetime('now', '-7 days')
        """)
        recent_7d = c.fetchone()[0] or 0
        
        # === TORRENTS PROBLÃ‰MATIQUES ===
        c.execute("SELECT COUNT(*) FROM torrent_details WHERE status = 'error' OR error IS NOT NULL")
        error_count = c.fetchone()[0] or 0
        
        c.execute("SELECT COUNT(*) FROM torrent_details WHERE status IN ('downloading', 'queued', 'waiting_files_selection')")
        active_count = c.fetchone()[0] or 0
        
        # === TORRENTS SANS DÃ‰TAILS ===
        c.execute("""
            SELECT COUNT(*) FROM torrents t 
            LEFT JOIN torrent_details td ON t.id = td.id 
            WHERE td.id IS NULL
        """)
        missing_details = c.fetchone()[0] or 0
        
        # === TOP HÃ‰BERGEURS ===
        c.execute("""
            SELECT host, COUNT(*) as count 
            FROM torrent_details 
            WHERE host IS NOT NULL AND host != ''
            GROUP BY host 
            ORDER BY count DESC 
            LIMIT 5
        """)
        top_hosts = c.fetchall()
        
        # === TORRENTS LES PLUS GROS ===
        c.execute("""
            SELECT name, size, status 
            FROM torrent_details 
            WHERE size > 0 AND name IS NOT NULL
            ORDER BY size DESC 
            LIMIT 5
        """)
        biggest_torrents = c.fetchall()
        
        # === PROGRESSION MOYENNE ===
        c.execute("SELECT AVG(progress) FROM torrent_details WHERE progress IS NOT NULL")
        avg_progress = c.fetchone()[0] or 0
        
        # === AFFICHAGE FORMATÃ‰ ===
        print("\n" + "="*60)
        print("ğŸ“Š STATISTIQUES COMPLÃˆTES REDRIVA")
        print("="*60)
        
        # Vue d'ensemble
        print(f"\nğŸ—‚ï¸  VUE D'ENSEMBLE")
        print(f"   ğŸ“ Total torrents     : {total_torrents:,}")
        print(f"   ğŸ“‹ DÃ©tails disponibles: {total_details:,}")
        print(f"   ğŸ“Š Couverture         : {coverage_percent:.1f}%")
        print(f"   âŒ DÃ©tails manquants  : {missing_details:,}")
        
        # Volumes de donnÃ©es
        if total_size and total_size > 0:
            print(f"\nğŸ’¾ VOLUMES DE DONNÃ‰ES")
            print(f"   ğŸ“¦ Volume total       : {format_size(total_size)}")
            print(f"    Plus petit         : {format_size(min_size) if min_size else 'N/A'}")
            print(f"   ğŸ”º Plus gros          : {format_size(max_size) if max_size else 'N/A'}")
        
        # ActivitÃ© rÃ©cente
        print(f"\nâ° ACTIVITÃ‰ RÃ‰CENTE")
        print(f"   ğŸ†• DerniÃ¨res 24h      : {recent_24h:,} torrents")
        print(f"   ğŸ“… Derniers 7 jours   : {recent_7d:,} torrents")
        
        # Ã‰tat des tÃ©lÃ©chargements
        print(f"\nğŸ”„ Ã‰TAT DES TÃ‰LÃ‰CHARGEMENTS")
        print(f"   âœ… Progression moyenne: {avg_progress:.1f}%")
        print(f"   â¬‡ï¸  TÃ©lÃ©chargements    : {active_count:,}")
        print(f"   âŒ Erreurs            : {error_count:,}")
        
        # RÃ©partition par statut (torrents)
        if torrent_status:
            print(f"\nğŸ“ˆ RÃ‰PARTITION PAR STATUT")
            for status, count in torrent_status[:8]:  # Top 8
                percent = (count / total_torrents * 100) if total_torrents > 0 else 0
                status_emoji = get_status_emoji(status)
                print(f"   {status_emoji} {status:<15} : {count:,} ({percent:.1f}%)")
        
        # Top hÃ©bergeurs
        if top_hosts:
            print(f"\nğŸŒ TOP HÃ‰BERGEURS")
            for host, count in top_hosts:
                percent = (count / total_details * 100) if total_details > 0 else 0
                print(f"   ğŸ”— {host:<15} : {count:,} ({percent:.1f}%)")
        
        # Plus gros torrents
        if biggest_torrents:
            print(f"\nğŸ† TOP 5 PLUS GROS TORRENTS")
            for i, (name, size, status) in enumerate(biggest_torrents, 1):
                status_emoji = get_status_emoji(status)
                truncated_name = (name[:45] + "...") if len(name) > 48 else name
                print(f"   {i}. {status_emoji} {format_size(size)} - {truncated_name}")
        
        # Recommandations automatiques
        print(f"\nğŸ’¡ RECOMMANDATIONS")
        if missing_details > 0:
            print(f"   ğŸ”§ ExÃ©cuter: python src/main.py --sync-smart")
            print(f"      (pour rÃ©cupÃ©rer {missing_details:,} dÃ©tails manquants)")
        
        if error_count > 0:
            print(f"   ğŸ”„ ExÃ©cuter: python src/main.py --details-only --status error")
            print(f"      (pour retry {error_count:,} torrents en erreur)")
        
        if active_count > 0:
            print(f"   â¬‡ï¸  {active_count:,} tÃ©lÃ©chargements en cours")
            print(f"      (utilisez --sync-smart pour les suivre)")
        
        if missing_details == 0 and error_count == 0:
            print(f"   âœ… Votre base est complÃ¨te et Ã  jour !")
        
        print("\n" + "="*60)

def show_stats_compact():
    """
    Version compacte des statistiques sur une ligne pour usage frÃ©quent
    
    Parfait pour:
    - Monitoring quotidien rapide
    - Scripts automatisÃ©s
    - Check rapide avant sync
    
    Usage: python src/main.py --stats --compact
    Exemple: ğŸ“Š 4,233 torrents | 4,232 dÃ©tails (100.0%) | â¬‡ï¸ 0 en cours | âŒ 2 erreurs
    """
    with sqlite3.connect(DB_PATH) as conn:
        c = conn.cursor()
        
        c.execute("SELECT COUNT(*) FROM torrents")
        total = c.fetchone()[0]
        
        c.execute("SELECT COUNT(*) FROM torrent_details")
        details = c.fetchone()[0]
        
        # Utilisation des constantes pour les torrents actifs
        placeholders = ','.join('?' * len(ACTIVE_STATUSES))
        c.execute(f"SELECT COUNT(*) FROM torrent_details WHERE status IN ({placeholders})", ACTIVE_STATUSES)
        active = c.fetchone()[0] or 0
        
        # Utilisation des constantes pour les erreurs
        placeholders = ','.join('?' * len(ERROR_STATUSES))
        c.execute(f"SELECT COUNT(*) FROM torrent_details WHERE status IN ({placeholders})", ERROR_STATUSES)
        errors = c.fetchone()[0] or 0
        
        coverage = (details / total * 100) if total > 0 else 0
        
        print(f"ğŸ“Š {total:,} torrents | {details:,} dÃ©tails ({coverage:.1f}%) | "
              f"â¬‡ï¸ {active} actifs | âŒ {errors} erreurs")

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘                     SECTION 7: DIAGNOSTIC ET MAINTENANCE                  â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def analyze_error_type(error_msg, status):
    """
    Analyse automatique du type d'erreur basÃ© sur le message d'erreur
    
    Types d'erreurs dÃ©tectÃ©s:
    - â±ï¸ Timeout rÃ©seau (temporaire)
    - ğŸ” Torrent introuvable (supprimÃ© de RD)
    - ğŸš« AccÃ¨s refusÃ© (problÃ¨me d'autorisation)
    - ğŸ–¥ï¸ Erreur serveur Real-Debrid
    - ğŸ“Š Quota API dÃ©passÃ©
    - ğŸŒ ProblÃ¨me de connexion
    - ğŸ“‹ DonnÃ©es malformÃ©es
    
    Args:
        error_msg (str): Message d'erreur
        status (str): Statut du torrent
        
    Returns:
        str: Type d'erreur avec emoji et description
    """
    if not error_msg:
        return "â“ Erreur inconnue (pas de message)"
    
    error_lower = error_msg.lower()
    
    if "timeout" in error_lower or "time out" in error_lower:
        return "â±ï¸ Timeout rÃ©seau (temporaire)"
    elif "404" in error_lower or "not found" in error_lower:
        return "ğŸ” Torrent introuvable (supprimÃ© de RD)"
    elif "403" in error_lower or "forbidden" in error_lower:
        return "ğŸš« AccÃ¨s refusÃ© (problÃ¨me d'autorisation)"
    elif "500" in error_lower or "502" in error_lower or "503" in error_lower:
        return "ğŸ–¥ï¸ Erreur serveur Real-Debrid (temporaire)"
    elif "quota" in error_lower or "limit" in error_lower:
        return "ğŸ“Š Quota API dÃ©passÃ© (temporaire)"
    elif "connection" in error_lower:
        return "ğŸŒ ProblÃ¨me de connexion (temporaire)"
    elif "json" in error_lower or "parse" in error_lower:
        return "ğŸ“‹ DonnÃ©es malformÃ©es (temporaire)"
    else:
        return f"â“ Erreur spÃ©cifique : {error_msg[:50]}..."

def get_error_suggestion(error_msg, status):
    """
    Propose une solution spÃ©cifique basÃ©e sur le type d'erreur dÃ©tectÃ©
    
    Args:
        error_msg (str): Message d'erreur
        status (str): Statut du torrent
        
    Returns:
        str: Suggestion d'action corrective avec emoji
    """
    if not error_msg:
        return "ğŸ”„ Retry avec --sync-smart"
    
    error_lower = error_msg.lower()
    
    if "timeout" in error_lower or "connection" in error_lower:
        return "ğŸ”„ Retry automatique recommandÃ© (erreur rÃ©seau temporaire)"
    elif "404" in error_lower or "not found" in error_lower:
        return "ğŸ—‘ï¸ Torrent probablement supprimÃ© - considÃ©rer suppression de la base"
    elif "403" in error_lower:
        return "ğŸ”‘ VÃ©rifier la validitÃ© du token Real-Debrid"
    elif "500" in error_lower or "502" in error_lower:
        return "â³ Attendre et retry plus tard (problÃ¨me serveur RD)"
    elif "quota" in error_lower:
        return "â° Attendre la rÃ©initialisation du quota (1 heure max)"
    else:
        return "ğŸ”„ Retry avec --sync-smart ou --details-only --status error"

def diagnose_errors():
    """
    Diagnostique dÃ©taillÃ© des torrents en erreur avec analyse automatique
    
    FonctionnalitÃ©s:
    - ğŸ“‹ Informations complÃ¨tes de chaque erreur
    - ğŸ”¬ Analyse automatique du type d'erreur
    - ğŸ’¡ Suggestions d'actions correctives
    - ğŸ“Š RÃ©sumÃ© statistique par type d'erreur
    - ğŸ› ï¸ Commandes exactes pour rÃ©soudre
    
    Usage: python src/main.py --diagnose-errors
    """
    with sqlite3.connect(DB_PATH) as conn:
        c = conn.cursor()
        
        # RÃ©cupÃ©rer tous les torrents en erreur avec leurs dÃ©tails
        c.execute("""
            SELECT td.id, td.name, td.status, td.error, td.progress, 
                   t.filename, t.added_on, t.bytes
            FROM torrent_details td
            LEFT JOIN torrents t ON td.id = t.id
            WHERE td.status = 'error' OR td.error IS NOT NULL
            ORDER BY t.added_on DESC
        """)
        
        errors = c.fetchall()
        
        if not errors:
            print("âœ… Aucun torrent en erreur trouvÃ© !")
            return
        
        print(f"\nğŸ” DIAGNOSTIC DES ERREURS ({len(errors)} torrents)")
        print("="*80)
        
        # Analyse dÃ©taillÃ©e de chaque erreur
        for i, (torrent_id, name, status, error, progress, filename, added_on, bytes_size) in enumerate(errors, 1):
            print(f"\nâŒ ERREUR #{i}")
            print(f"   ğŸ†” ID             : {torrent_id}")
            print(f"   ğŸ“ Nom            : {name or filename or 'N/A'}")
            print(f"   ğŸ“Š Statut         : {status}")
            print(f"   âš ï¸  Message d'erreur: {error or 'Aucun message spÃ©cifique'}")
            print(f"   ğŸ“ˆ Progression    : {progress or 0}%")
            print(f"   ğŸ“… AjoutÃ© le      : {added_on}")
            print(f"   ğŸ’¾ Taille         : {format_size(bytes_size) if bytes_size else 'N/A'}")
            
            # Analyse automatique du type d'erreur
            error_type = analyze_error_type(error, status)
            print(f"   ğŸ”¬ Type d'erreur  : {error_type}")
            
            # Suggestion de correction personnalisÃ©e
            suggestion = get_error_suggestion(error, status)
            print(f"   ğŸ’¡ Suggestion     : {suggestion}")
            print("-" * 80)
        
        # RÃ©sumÃ© statistique des types d'erreurs
        print(f"\nğŸ“Š RÃ‰SUMÃ‰ DES TYPES D'ERREURS")
        error_types = {}
        for _, _, _, error, _, _, _, _ in errors:
            error_type = analyze_error_type(error, None)
            error_types[error_type] = error_types.get(error_type, 0) + 1
        
        for error_type, count in sorted(error_types.items(), key=lambda x: x[1], reverse=True):
            print(f"   â€¢ {error_type} : {count}")
        
        # Actions recommandÃ©es avec commandes exactes
        print(f"\nğŸ’¡ ACTIONS RECOMMANDÃ‰ES :")
        print(f"   ğŸ”„ Retry automatique    : python src/main.py --sync-smart")
        print(f"   ğŸ¯ Retry forcÃ©          : python src/main.py --details-only --status error")
        print(f"   ğŸ“Š VÃ©rifier l'Ã©tat      : python src/main.py --stats")



# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘                    SECTION 8: INTERFACE UTILISATEUR (MENU)                â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def show_interactive_menu():
    """
    Menu interactif principal pour faciliter l'utilisation de Redriva
    
    FonctionnalitÃ©s:
    - ğŸ¯ Interface guidÃ©e avec choix numÃ©rotÃ©s
    - âš¡ AccÃ¨s direct aux fonctions principales
    - ğŸ’¡ Guide intÃ©grÃ© avec recommandations
    - ğŸ”„ Navigation fluide avec retour automatique
    - ğŸƒ Mode hybride vers ligne de commande
    
    Categories du menu:
    - ğŸ“Š Informations & Diagnostic  
    - ğŸ”„ Synchronisation
    - ğŸ”§ Maintenance
    - â“ Aide & Sortie
    
    Returns:
        bool: True si le programme doit se terminer, False pour continuer en CLI
    """
    import os
    
    while True:
        # Effacer l'Ã©cran (compatible Linux/Mac/Windows)
        os.system('clear' if os.name == 'posix' else 'cls')
        
        print("â•”" + "â•" * 58 + "â•—")
        print("â•‘" + " " * 20 + "ğŸš€ MENU REDRIVA" + " " * 20 + "â•‘")
        print("â• " + "â•" * 58 + "â•£")
        print("â•‘ Outil de synchronisation Real-Debrid                  â•‘")
        print("â•š" + "â•" * 58 + "â•")
        
        print("\nğŸ“Š INFORMATIONS & DIAGNOSTIC")
        print("  1. ğŸ“ˆ Statistiques complÃ¨tes")
        print("  2. ğŸ“‹ Statistiques compactes")
        print("  3. ğŸ” Diagnostiquer les erreurs")
        
        print("\nğŸ”„ SYNCHRONISATION")
        print("  4. ğŸ§  Sync intelligent (recommandÃ©)")
        print("  5. ğŸš€ Sync complet")
        print("  6. ğŸ“‹ Vue d'ensemble (ultra-rapide)")
        print("  7. â®ï¸  Reprendre sync interrompu")
        
        print("\nğŸ”§ MAINTENANCE")
        print("  8. ğŸ”„ DÃ©tails uniquement")
        print("  9. ğŸ—‘ï¸  Vider la base de donnÃ©es")
        print(" 10. ğŸ” Diagnostic du token")
        
        print("\nâ“ AIDE & SORTIE")
        print(" 11. ğŸ’¡ Guide de choix rapide")
        print(" 12. ğŸƒ Mode commande (passer aux arguments)")
        print("  0. ğŸšª Quitter")
        
        print("\n" + "â”€" * 60)
        
        try:
            choice = input("ğŸ‘‰ Votre choix (0-12) : ").strip()
            
            if choice == "0":
                print("\nğŸ‘‹ Au revoir ! Merci d'utiliser Redriva.")
                break
                
            elif choice == "1":
                print("\nğŸ”„ Chargement des statistiques complÃ¨tes...")
                show_stats()
                input("\nğŸ“Š Appuyez sur EntrÃ©e pour continuer...")
                
            elif choice == "2":
                print("\nğŸ“Š Statistiques compactes :")
                show_stats_compact()
                input("\nğŸ“‹ Appuyez sur EntrÃ©e pour continuer...")
                
            elif choice == "3":
                print("\nğŸ” Diagnostic des erreurs en cours...")
                diagnose_errors()
                input("\nğŸ”§ Appuyez sur EntrÃ©e pour continuer...")
                
            elif choice == "4":
                token = get_token()
                if token:
                    print("\nğŸ§  Synchronisation intelligente en cours...")
                    sync_smart(token)
                    input("\nâœ… Appuyez sur EntrÃ©e pour continuer...")
                else:
                    input("\nâŒ Token manquant. Appuyez sur EntrÃ©e pour continuer...")
                    
            elif choice == "5":
                token = get_token()
                if token:
                    print("\nğŸš€ Synchronisation rapide en cours...")
                    sync_all_v2(token)
                    input("\nâœ… Appuyez sur EntrÃ©e pour continuer...")
                else:
                    input("\nâŒ Token manquant. Appuyez sur EntrÃ©e pour continuer...")
                    
            elif choice == "6":
                token = get_token()
                if token:
                    print("\nğŸ“‹ Synchronisation des torrents uniquement...")
                    sync_torrents_only(token)
                    input("\nğŸ“‹ Appuyez sur EntrÃ©e pour continuer...")
                else:
                    input("\nâŒ Token manquant. Appuyez sur EntrÃ©e pour continuer...")
                    
            elif choice == "7":
                token = get_token()
                if token:
                    print("\nâ®ï¸  Reprise de la synchronisation...")
                    sync_resume(token)
                    input("\nâœ… Appuyez sur EntrÃ©e pour continuer...")
                else:
                    input("\nâŒ Token manquant. Appuyez sur EntrÃ©e pour continuer...")
                    
            elif choice == "8":
                token = get_token()
                if token:
                    print("\nğŸ”„ Mise Ã  jour des dÃ©tails uniquement...")
                    sync_details_only(token)
                    input("\nâœ… Appuyez sur EntrÃ©e pour continuer...")
                else:
                    input("\nâŒ Token manquant. Appuyez sur EntrÃ©e pour continuer...")
                    
            elif choice == "9":
                confirm = input("\nâš ï¸  ATTENTION : Vider complÃ¨tement la base de donnÃ©es ? (tapez 'SUPPRIMER'): ")
                if confirm == "SUPPRIMER":
                    clear_database()
                    input("\nğŸ—‘ï¸  Base vidÃ©e. Appuyez sur EntrÃ©e pour continuer...")
                else:
                    print("âŒ AnnulÃ©.")
                    input("ğŸ“‹ Appuyez sur EntrÃ©e pour continuer...")
                    
            elif choice == "10":
                print("\nâŒ Option non disponible")
                input("ï¿½ Appuyez sur EntrÃ©e pour continuer...")
                
            elif choice == "11":
                print("\nâŒ Option non disponible")
                input("ï¿½ Appuyez sur EntrÃ©e pour continuer...")
                
            elif choice == "12":
                print("\nğŸƒ Passage en mode commande...")
                print("ğŸ’¡ Utilisez: python src/main.py --help pour voir toutes les options")
                print("ğŸ“‹ Exemple: python src/main.py --sync-smart")
                return False  # Retourne False pour continuer avec les arguments CLI
                
            else:
                input("\nâŒ Choix invalide. Appuyez sur EntrÃ©e pour continuer...")
                
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ Interruption dÃ©tectÃ©e. Au revoir !")
            break
        except Exception as e:
            print(f"\nâŒ Erreur : {e}")
            input("ğŸ”§ Appuyez sur EntrÃ©e pour continuer...")
    
    return True  # Retourne True si le programme doit se terminer



def get_token():
    """
    RÃ©cupÃ¨re le token Real-Debrid depuis la configuration centralisÃ©e
    Returns:
        str/None: Token valide ou None si non trouvÃ©
    """
    try:
        return load_token()
    except SystemExit:
        print("\nâŒ ERREUR : Token Real-Debrid non trouvÃ© !")
        print("ğŸ”§ Veuillez configurer votre token via l'interface web de Redriva.")
        return None

# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
# â•‘                        SECTION 9: POINT D'ENTRÃ‰E PRINCIPAL                â•‘
# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    """
    Point d'entrÃ©e principal avec support menu interactif et arguments CLI
    
    Logique:
    - Si aucun argument : lance le menu interactif
    - Sinon : traite les arguments de ligne de commande
    
    Arguments supportÃ©s:
    - Synchronisation : --sync-all, --sync-fast, --sync-smart, --resume, etc.
    - Statistiques : --stats, --stats --compact  
    - Diagnostic : --diagnose-errors
    - Maintenance : --details-only, --clear, --torrents-only
    """
    
    parser = argparse.ArgumentParser(description="Redriva - Synchroniseur Real-Debrid vers SQLite")
    
    # Si aucun argument n'est fourni, lancer le menu interactif
    if len(sys.argv) == 1:
        try:
            should_exit = show_interactive_menu()
            if should_exit:
                return
        except KeyboardInterrupt:
            print("\nğŸ‘‹ Au revoir !")
            return
    
    # === ARGUMENTS DE LIGNE DE COMMANDE ===
    
    # Arguments de base
    parser.add_argument('--details-only', action='store_true', 
                       help="ğŸ“ Synchroniser uniquement les dÃ©tails des torrents existants")
    parser.add_argument('--status', 
                       help="ğŸ” Filtrer par status (downloaded, error, downloading, etc.)")
    parser.add_argument('--stats', action='store_true', 
                       help="ğŸ“Š Afficher les statistiques de la base")
    parser.add_argument('--compact', action='store_true', 
                       help="ğŸ“‹ Affichage compact des statistiques")
    parser.add_argument('--clear', action='store_true', 
                       help="ğŸ—‘ï¸ Vider complÃ¨tement la base de donnÃ©es")
    
    # Arguments de synchronisation (architecture simplifiÃ©e)
    parser.add_argument('--sync-smart', action='store_true', 
                       help="ğŸ§  Sync intelligent - Mode recommandÃ© (30s-2min)")
    parser.add_argument('--sync-fast', action='store_true', 
                       help="ğŸš€ Sync complet - Synchronisation complÃ¨te optimisÃ©e (7-10min)")
    parser.add_argument('--torrents-only', action='store_true', 
                       help="ğŸ“‹ Vue d'ensemble - Liste des torrents uniquement (10-30s)")
    parser.add_argument('--resume', action='store_true', 
                       help="â®ï¸  Reprendre une synchronisation interrompue")
    
    # Arguments de diagnostic
    parser.add_argument('--diagnose-errors', action='store_true', 
                       help="ğŸ” Diagnostic dÃ©taillÃ© des torrents en erreur avec suggestions")
    parser.add_argument('--menu', action='store_true', 
                       help="ğŸ® Afficher le menu interactif")
    
    args = parser.parse_args()

    # Initialisation
    token = load_token()
    create_tables()

    try:
        # === TRAITEMENT DES ARGUMENTS ===
        
        if args.menu:
            show_interactive_menu()
            
        elif args.clear:
            # Demander confirmation avant de vider
            response = input("âš ï¸  ÃŠtes-vous sÃ»r de vouloir vider la base de donnÃ©es ? (oui/non): ")
            if response.lower() in ['oui', 'o', 'yes', 'y']:
                clear_database()
            else:
                print("âŒ OpÃ©ration annulÃ©e.")
                
        elif args.stats:
            if args.compact:
                show_stats_compact()
            else:
                show_stats()
                
        elif args.diagnose_errors:
            diagnose_errors()
            
        elif args.torrents_only:
            sync_torrents_only(token)
            
        elif args.sync_fast:
            sync_all_v2(token)
            
        elif args.sync_smart:
            sync_smart(token)
            
        elif args.resume:
            sync_resume(token)
            
        elif args.details_only:
            sync_details_only(token, args.status)
            
        else:
            # Aucun argument reconnu, afficher l'aide
            parser.print_help()
            print(f"\nğŸ’¡ Astuce : Lancez simplement 'python src/main.py' pour le menu interactif !")
            
    except KeyboardInterrupt:
        logging.warning("ArrÃªt manuel par l'utilisateur.")
    except Exception as e:
        logging.error(f"Erreur inattendue : {e}")

if __name__ == "__main__":
    main()
